<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>KenCochrane.net</title>
    <link>http://www.kencochrane.net/</link>
    <description>Recent content on KenCochrane.net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 15 Feb 2015 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://www.kencochrane.net/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Introducing Django Defender</title>
      <link>http://www.kencochrane.net/blog/2015/02/introducing-django-defender/</link>
      <pubDate>Sun, 15 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2015/02/introducing-django-defender/</guid>
      <description>

&lt;p&gt;Normally websites do very few logins, someone logs in once and their
session is good for a bunch of hours. Since it&amp;rsquo;s a one time thing, it
doesn&amp;rsquo;t matter if it isn&amp;rsquo;t very fast. At
&lt;a href=&#34;https://www.docker.com&#34;&gt;Docker&lt;/a&gt; our authentication system handles
requests for both the &lt;a href=&#34;https://hub.docker.com&#34;&gt;Docker Hub&lt;/a&gt;, as well as
all Docker Engine commands that interact with the Docker Hub (docker
push, pull, etc). This Authentication system handles thousands of login
attempts every minute, so any slow down in the login process has a large
impact on our system.&lt;/p&gt;

&lt;p&gt;We are always looking at ways to improve the security of our systems,
and one of the things we looked at implementing was a way to prevent
brute force login attempts. The first thing we did was look to see if
there was an open source solution available that would do what we
needed. The Docker Hub along with the authentication system is written
in Python using &lt;a href=&#34;http://www.djangoproject.com&#34;&gt;Django&lt;/a&gt; . So we did some
research to see what was the best solution available to us. We quickly
came to &lt;a href=&#34;https://github.com/django-pci/django-axes&#34;&gt;django-axes&lt;/a&gt;, which
is a great library, and had everything we were looking for. Best of all,
it wasn&amp;rsquo;t that hard to add to our system.&lt;/p&gt;

&lt;p&gt;When we started using django-axes our traffic was pretty normal, but
with the explosive growth of Docker we have seen a huge increases in
traffic. As the traffic increased, we started noticing that login times
were slowing down. Upon further inspection we noticed that with
django-axes turned on it was adding a 200 to 300ms overheard compared to
when it was turned off. We did some more digging to see what was causing
all of the delay, and we found out the reason is because django-axes
stores all of its information in the database and in order to determine
if someone is blocked you need to do a bunch of queries, and the more
login attempts, the larger the axes database tables get, and thus the
queries get slower, and in turn slows down the login process.&lt;/p&gt;

&lt;p&gt;Our first attempts to speed things up was to add more database indexes,
and to run a script that kept the axes database tables small. This
worked for a little while, but as the traffic increased, it stopped
working. It was quickly determined that we would need to replace
django-axes. We looked around at other brute force libraries, and there
was nothing that offered what we needed for features, was fast, and well
maintained.&lt;/p&gt;

&lt;p&gt;Since we couldn&amp;rsquo;t find anything, I started working on a replacement. On
one of my many cross country flights, I started working on a
replacement. In order to make the process quicker, it started as a fork
of django-axes, where I removed the stuff we didn&amp;rsquo;t need, and then
replaced the slow parts with faster ones. The main goal was to avoid
hitting the database in order to determine if the user was blocked.
Since we are big fans of &lt;a href=&#34;http://redis.io&#34;&gt;Redis&lt;/a&gt;, and we were using it
in other places already, we decided to use Redis as our backend for
storing all of our data for determining if someone is blocked. We also
allow the logging of login attempts to the database, but to speed things
up, we defer this to a background celery task.&lt;/p&gt;

&lt;p&gt;After a few cross country flights, and some help from some of my
co-workers, we now have a library, that we are using on the Docker Hub.
We have been using it for about a month now, and the results have been
great. With this new library we are seeing under a 10ms impact on our
logins, which is really great. We are able to have the features we need
without the overhead.&lt;/p&gt;

&lt;p&gt;Now that we have proven the project to be successful, we have decided to
open source the library, so that others can also use it, and contribute
back any features or improvements they might find important.&lt;/p&gt;

&lt;p&gt;So without further ado, I&amp;rsquo;m proud to introduce &lt;a href=&#34;https://github.com/kencochrane/django-defender&#34;&gt;Django
Defender&lt;/a&gt;, a brute force
login preventions library built for speed.&lt;/p&gt;

&lt;p&gt;We have labeled the first version 0.1, but it is very stable and already
production ready. We have very good code coverage (95%+) and we have
tests and support for a number of different Python and Django versions.&lt;/p&gt;

&lt;p&gt;We also have django admin pages that can be used to manage the blocked
users and IP addresses.&lt;/p&gt;

&lt;p&gt;Please try it out, and let us know if you have any questions.&lt;/p&gt;

&lt;h1 id=&#34;links:2832a4aab293d94e3010f852c52d8570&#34;&gt;Links:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Source code&lt;/strong&gt;: &lt;a href=&#34;https://github.com/kencochrane/django-defender&#34;&gt;https://github.com/kencochrane/django-defender&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyPi&lt;/strong&gt;: &lt;a href=&#34;https://pypi.python.org/pypi/django-defender&#34;&gt;https://pypi.python.org/pypi/django-defender&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;version-support:2832a4aab293d94e3010f852c52d8570&#34;&gt;Version Support:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt;: 2.6.x, 2.7.x, 3.3.x, 3.4.x, PyPy&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Django&lt;/strong&gt;: 1.6.x, 1.7.x&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;what-s-in-0-1:2832a4aab293d94e3010f852c52d8570&#34;&gt;What&amp;rsquo;s in 0.1:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Configurable: When to block, What to do when blocked.&lt;/li&gt;
&lt;li&gt;Uses Redis for data store.&lt;/li&gt;
&lt;li&gt;Blocking IP and usernames when too many login attempts&lt;/li&gt;
&lt;li&gt;Logging of access attempts to database.&lt;/li&gt;
&lt;li&gt;Celery for writing access attempt logs to the database in the
background&lt;/li&gt;
&lt;li&gt;Admin pages (integrated with Django admin), to manage the blocked
IP&amp;rsquo;s and usernames.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;how-to-install:2832a4aab293d94e3010f852c52d8570&#34;&gt;How to install:&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;$ pip install django-defender
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;admin-screen-shots:2832a4aab293d94e3010f852c52d8570&#34;&gt;Admin Screen shots:&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/261601/5950540/8895b570-a729-11e4-9dc3-6b00e46c8043.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/261601/5950541/88a35194-a729-11e4-981b-3a55b44ef9d5.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Uploading a Video to Facebook from AWS S3 using python</title>
      <link>http://www.kencochrane.net/blog/2015/02/upload-video-to-facebook-from-s3-using-python/</link>
      <pubDate>Sat, 14 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2015/02/upload-video-to-facebook-from-s3-using-python/</guid>
      <description>

&lt;p&gt;If you have some video files stored in Amazon S3 and you want to upload
those videos to a Facebook page, using their video API here is some
python code that I used recently.&lt;/p&gt;

&lt;p&gt;I spent a good chunk of a day trying to get this too work, so I&amp;rsquo;m
posting this here to help anyone else who is trying to do the same.&lt;/p&gt;

&lt;p&gt;This code isn&amp;rsquo;t using any special facebook libraries it is just using
normal python along with the requests library. It should be a good
enough example to figure out how to do most things.&lt;/p&gt;

&lt;p&gt;It is important to note that you will need a valid access token with
correct permissions in order to get this to work, and that isn&amp;rsquo;t covered
in this blog post.&lt;/p&gt;

&lt;p&gt;Another thing that is important to note, that this uses a different API
host then the rest of the facebook API. Instead of &lt;code&gt;graph.facebook.com&lt;/code&gt;
it uses &lt;code&gt;graph-video.facebook.com&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Facebook Video API&lt;/strong&gt;:
&lt;a href=&#34;https://developers.facebook.com/docs/graph-api/reference/v2.2/user/videos/&#34;&gt;https://developers.facebook.com/docs/graph-api/reference/v2.2/user/videos/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Facebook Access Tokens&lt;/strong&gt;:
&lt;a href=&#34;https://developers.facebook.com/docs/facebook-login/access-tokens&#34;&gt;https://developers.facebook.com/docs/facebook-login/access-tokens&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;requirements:68da97ef1a847aab7a13405352cba049&#34;&gt;Requirements:&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ pip install requests requests-toolbelt
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;code:68da97ef1a847aab7a13405352cba049&#34;&gt;Code:&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;import os
import base64
import requests
from requests_toolbelt import MultipartEncoder
import uuid
import logging


log = logging.getLogger(__name__)


def download_file_to_tmp(source_url):
    &amp;quot;&amp;quot;&amp;quot;
    download `source_url` to /tmp return the full path, doing it in chunks so
    that we don&#39;t have to store everything in memory.
    &amp;quot;&amp;quot;&amp;quot;
    log.debug(&amp;quot;download {0}&amp;quot;.format(source_url))
    tmp_location = &amp;quot;/tmp/s3_downloads&amp;quot;

    # come up with a random name to avoid clashes.
    rand_name = str(uuid.uuid4().get_hex().lower()[0:6])

    local_filename = source_url.split(&#39;/&#39;)[-1]

    # get the extension if it has one
    if local_filename.count(&amp;quot;.&amp;quot;) &amp;gt; 0:
        ext = local_filename.split(&#39;.&#39;)[-1]
        tmp_filename = u&amp;quot;{0}.{1}&amp;quot;.format(rand_name, ext)
    else:
        tmp_filename = u&amp;quot;{0}.mp4&amp;quot;.format(local_filename)

    temp_media_location = os.path.join(tmp_location, tmp_filename)
    # make the temp directory
    if not os.path.exists(tmp_location):
        os.makedirs(tmp_location)

    r = requests.get(source_url, stream=True)
    log.debug(&amp;quot;headers = {0}&amp;quot;.format(r.headers))
    with open(temp_media_location, &#39;wb&#39;) as f:
        for chunk in r.iter_content(chunk_size=1024):
            if chunk:  # filter out keep-alive new chunks
                f.write(chunk)
                f.flush()
                os.fsync(f.fileno())
    log.debug(&amp;quot;finished download to {0}&amp;quot;.format(temp_media_location))
    return temp_media_location


def remove_file(temp_file):
    &amp;quot;&amp;quot;&amp;quot; Given a valid file path remove it &amp;quot;&amp;quot;&amp;quot;
    if os.path.exists(temp_file):
        os.remove(temp_file)


def upload_file(video_url, page_id, poster_url, access_token,
                description, title):
    &amp;quot;&amp;quot;&amp;quot;
    ``video_url``: this is where the video is in s3.
    ``page_id``:  me or a page_id for the page you want to post too.
    ``poster_url``:  the url to the poster (thumbnail) for this video
    ``access_token``: your facebook access token with permissions to upload
        to the page you want to post too.
    ``description``:  the description of the video you are posting.
    ``title``:  the title of the video you are posting
    &amp;quot;&amp;quot;&amp;quot;

    # download to data
    local_video_file = download_file_to_tmp(video_url)
    video_file_name = local_video_file.split(&amp;quot;/&amp;quot;)[-1]

    if video_file_name and video_file_name.count(&amp;quot;.&amp;quot;) == 0:
        log.debug(&amp;quot;video_file_name has no ext {0}&amp;quot;.format(video_file_name))
        # if it doesn&#39;t have an extension add one to it.
        video_file_name = &amp;quot;{0}.mp4&amp;quot;.format(video_file_name)
        log.debug(&amp;quot;video_file_name converted to {0}&amp;quot;.format(video_file_name))

    # download to data
    local_poster_file = download_file_to_tmp(poster_url)

    # need to encode it.
    with open(local_poster_file, &amp;quot;rb&amp;quot;) as image_file:
        poster_encoded_string = base64.b64encode(image_file.read())

    # need binary rep of this, not sure if this would do it

    # put it all together to post to facebook
    if page_id or page_id == &#39;me&#39;:
        path = &#39;me/videos&#39;
    else:
        path = &amp;quot;{0}/videos&amp;quot;.format(page_id)

    fb_url = &amp;quot;https://graph-video.facebook.com/{0}?access_token={1}&amp;quot;.format(
             path, access_token)

    log.debug(&amp;quot;video_file = {0}&amp;quot;.format(local_video_file))
    log.debug(&amp;quot;thumb_file = {0}&amp;quot;.format(local_poster_file))
    log.debug(&amp;quot;start upload to facebook&amp;quot;)

    # multipart chunked uploads
    m = MultipartEncoder(
        fields={&#39;description&#39;: description,
                &#39;title&#39;: title,
                &#39;thumb&#39;: poster_encoded_string,
                &#39;source&#39;: (video_file_name, open(local_video_file, &#39;rb&#39;))}
    )

    r = requests.post(fb_url, headers={&#39;Content-Type&#39;: m.content_type}, data=m)

    if r.status_code == 200:
        j_res = r.json()
        facebook_video_id = j_res.get(&#39;id&#39;)
        log.debug(&amp;quot;facebook_video_id = {0}&amp;quot;.format(facebook_video_id))
    else:
        log.error(&amp;quot;Facebook upload error: {0}&amp;quot;.format(r.text))

    # delete the tmp files
    remove_file(local_video_file)
    remove_file(local_poster_file)

    return facebook_video_id
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>The Docker Guidebook</title>
      <link>http://www.kencochrane.net/blog/2013/08/the-docker-guidebook/</link>
      <pubDate>Fri, 23 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2013/08/the-docker-guidebook/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/docker_logo.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;introduction:7906d5806871be907588a3a390328f7d&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;The goal of this tutorial is to introduce you to
&lt;a href=&#34;http://docker.io&#34;&gt;Docker&lt;/a&gt;, show you what it can do, and how to get it
up and running on your system, and how to use it to make your life
better.&lt;/p&gt;

&lt;p&gt;This guide is open source and available on
&lt;a href=&#34;https://github.com/kencochrane/docker-guidebook&#34;&gt;github.com&lt;/a&gt;. If you
would like to add to it or fix something, please &lt;a href=&#34;https://github.com/kencochrane/docker-guidebook&#34;&gt;fork
it&lt;/a&gt; and submit a pull
request.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;what-is-docker:7906d5806871be907588a3a390328f7d&#34;&gt;What is Docker?&lt;/h1&gt;

&lt;p&gt;Docker is a tool created by the folks at &lt;a href=&#34;http://dotcloud.com&#34;&gt;dotCloud&lt;/a&gt;
to make using LinuX Containers (&lt;a href=&#34;http://lxc.sourceforge.net/&#34;&gt;LXC&lt;/a&gt;)
easier to use. Linux Containers are basically light weight Virtual
Machines (&lt;a href=&#34;http://en.wikipedia.org/wiki/Virtual_machine&#34;&gt;VM&lt;/a&gt;). A linux
container runs Unix processes with strong guarantees of isolation across
servers. Your software runs repeatably everywhere because its Container
includes all of its dependencies.&lt;/p&gt;

&lt;p&gt;If you still don&amp;rsquo;t understand what Docker is, and what it can do for
you, don&amp;rsquo;t worry, keep reading and it will become clear soon enough.&lt;/p&gt;

&lt;h2 id=&#34;how-are-docker-s-containers-different-from-virtual-machines:7906d5806871be907588a3a390328f7d&#34;&gt;How are Docker&amp;rsquo;s Containers Different from Virtual Machines?&lt;/h2&gt;

&lt;p&gt;Docker, which uses LinuX Containers (LXC) run in the same kernel as it&amp;rsquo;s
host. This allows it to share a lot of the host&amp;rsquo;s resources. It also
uses &lt;a href=&#34;http://aufs.sourceforge.net&#34;&gt;AuFS&lt;/a&gt; for the file system. It also
manages the networking for you as well.&lt;/p&gt;

&lt;p&gt;AuFS is a layered file system, so you can have a read only part, and a
write part, and it merges those together. So you could have the common
parts of the file system as read only, which are shared amongst all of
your containers, and then give each container it&amp;rsquo;s own mount for
writing.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s say you have a container image that is 1GB in size. If you
wanted to use a Full VM, you would need to have 1GB times x number of
VMs you want. With LXC and AuFS you can share the bulk of the 1GB and if
you have 1000 containers you still might only have a little over 1GB of
space for the containers OS, assuming they are all running the same OS
image.&lt;/p&gt;

&lt;p&gt;A full virtualized system gets it&amp;rsquo;s own set of resources allocated to
it, and does minimal sharing. You get more isolation, but it is much
heavier (requires more resources).&lt;/p&gt;

&lt;p&gt;With LXC you get less isolation, but they are more lightweight and
require less resources. So you could easily run 1000&amp;rsquo;s on a host, and it
doesn&amp;rsquo;t even blink. Try doing that with Xen, and unless you have a
really big host, I don&amp;rsquo;t think it is possible.&lt;/p&gt;

&lt;p&gt;A full virtualized system usually takes minutes to start, LXC containers
take seconds, and most times less then a second.&lt;/p&gt;

&lt;p&gt;There are pros and cons for each type of virtualized system. If you want
full isolation with guaranteed resources then a full VM is the way to
go. If you just want to isolate processes from each other and want to
run a ton of them on a reasonably sized host, then LXC might be the way
to go.&lt;/p&gt;

&lt;p&gt;For more information check out these set of blog posts which do a good
job of explaining now LXC works:
&lt;a href=&#34;http://blog.dotcloud.com/under-the-hood-linux-kernels-on-dotcloud-part&#34;&gt;http://blog.dotcloud.com/under-the-hood-linux-kernels-on-dotcloud-part&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;installing-docker:7906d5806871be907588a3a390328f7d&#34;&gt;Installing Docker&lt;/h1&gt;

&lt;p&gt;Before you can install Docker you need to decide how you want to install
it. There are three ways to install it, you can install from source,
download a compiled binary, or install via your systems package manager.&lt;/p&gt;

&lt;p&gt;For detailed instructions on how to install Docker on your system for
each of the following steps, check out the official Docker documentation
&lt;a href=&#34;http://docs.docker.io/en/latest/installation/&#34;&gt;http://docs.docker.io/en/latest/installation/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;requirements:7906d5806871be907588a3a390328f7d&#34;&gt;Requirements&lt;/h2&gt;

&lt;p&gt;In order for Docker to run correctly on your server, you need to have a
few things. For more details on the kernel requirements see this page:
see &lt;a href=&#34;http://docs.docker.io/en/latest/installation/kernel/&#34;&gt;http://docs.docker.io/en/latest/installation/kernel/&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kernel version greater then 3.8 and Cgroups and namespaces must
be enabled.&lt;/li&gt;
&lt;li&gt;AUFS : AUFS is included in the kernels built by the Debian and
Ubuntu distributions, but not built into the standard kernel, so if
you are using another distribution you will need to add it to
your kernel.&lt;/li&gt;
&lt;li&gt;LXC : This is most likely already installed on your system and
kernel, you might just need to install a system package or two. See
the install instructions for your distribution to get a list
of packages.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;kernel-version:7906d5806871be907588a3a390328f7d&#34;&gt;Kernel version&lt;/h3&gt;

&lt;p&gt;The reason why Docker needs to run in a kernel version of 3.8 or greater
is because there are some kernel bugs that are in the older versions
that cause problems in some cases. Some people have ran Docker fine on
lower kernels, so if you can&amp;rsquo;t run on 3.8, do so at your own risk. There
is talk about an effort to back port the bug fixes to the older kernel
trees, so that in the future they will be available on the older kernel
versions. For more information about this see.
&lt;a href=&#34;https://github.com/dotcloud/docker/pull/1062&#34;&gt;https://github.com/dotcloud/docker/pull/1062&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;aufs:7906d5806871be907588a3a390328f7d&#34;&gt;AUFS&lt;/h3&gt;

&lt;p&gt;Currently AUFS is the standard file system for Docker, but there is an
effort underway to make the filesystem more pluggable, so that we can
use different file systems with Docker. AUFS will most likely not be
available in future Ubuntu releases, and UnionFS doesn&amp;rsquo;t look like it
will be getting added to the kernel anytime soon, so we can&amp;rsquo;t add that
as a replacement. The current replacement looks like
&lt;a href=&#34;https://github.com/dotcloud/docker/issues/443&#34;&gt;BTRFS&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;package-manager:7906d5806871be907588a3a390328f7d&#34;&gt;Package Manager&lt;/h2&gt;

&lt;p&gt;The most common way to install Docker is via your server&amp;rsquo;s package
manager. On Ubuntu that is as simple as running the following command
&lt;code&gt;sudo apt-get install lxc-docker&lt;/code&gt;. This is an easy way to install
docker, and keep it up to date.&lt;/p&gt;

&lt;p&gt;The package will also install an init script so that the docker daemon
will start up automatically.&lt;/p&gt;

&lt;p&gt;If you are installing on a production server, this is the recommended
way to install.&lt;/p&gt;

&lt;h3 id=&#34;upgrading:7906d5806871be907588a3a390328f7d&#34;&gt;Upgrading:&lt;/h3&gt;

&lt;p&gt;To upgrade you would upgrade the same way you upgrade any other package
for your system. On Ubuntu you would run &amp;lsquo;sudo apt-get upgrade&amp;rsquo;&lt;/p&gt;

&lt;h2 id=&#34;binaries:7906d5806871be907588a3a390328f7d&#34;&gt;Binaries&lt;/h2&gt;

&lt;p&gt;If a docker package isn&amp;rsquo;t available for your package manager, you can
download the binaries directly. When a new version of docker is released
the binaries are uploaded to &lt;a href=&#34;http://get.docker.io&#34;&gt;http://get.docker.io&lt;/a&gt;, so that you can
download directly from there. Here is an example on how to download the
latest docker release.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget http://get.docker.io/builds/Linux/x86_64/docker-latest.tgz
tar -xf docker-latest.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This just downloads the docker binary, to get it to run you would still
need to put the binary in a good location, and create an init script so
that it will start on system reboots.&lt;/p&gt;

&lt;h3 id=&#34;init-script-examples:7906d5806871be907588a3a390328f7d&#34;&gt;Init script examples:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Debian init:
&lt;a href=&#34;https://github.com/dotcloud/docker/blob/master/packaging/debian/lxc-docker.init&#34;&gt;https://github.com/dotcloud/docker/blob/master/packaging/debian/lxc-docker.init&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ubuntu Upstart:
&lt;a href=&#34;https://github.com/dotcloud/docker/blob/master/packaging/ubuntu/docker.upstart&#34;&gt;https://github.com/dotcloud/docker/blob/master/packaging/ubuntu/docker.upstart&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;upgrading-1:7906d5806871be907588a3a390328f7d&#34;&gt;Upgrading:&lt;/h3&gt;

&lt;p&gt;To upgrade you would need to download the latest version, make a backup
of the current docker binary, replace the current one with the new one,
and restart your daemon. The init script should be able to stay the
same.&lt;/p&gt;

&lt;h3 id=&#34;more-information:7906d5806871be907588a3a390328f7d&#34;&gt;More information:&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.docker.io/en/latest/installation/binaries/&#34;&gt;http://docs.docker.io/en/latest/installation/binaries/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;from-source:7906d5806871be907588a3a390328f7d&#34;&gt;From Source&lt;/h2&gt;

&lt;p&gt;Installing from a package manager or from a binary is fine if you want
to only install released versions. But if you want to be on the cutting
edge and install some features that are either on a feature branch, or
something that isn&amp;rsquo;t released yet, you will need to compile from source.&lt;/p&gt;

&lt;p&gt;Compiling from source is a little more complicated because you will need
to have GO 1.1 and all other dependences install on your system, but it
isn&amp;rsquo;t too bad.&lt;/p&gt;

&lt;p&gt;Here is what you need to do to get it up and running on Ubuntu:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install python-software-properties
sudo add-apt-repository ppa:gophers/go
sudo apt-get update
sudo apt-get -y install lxc xz-utils curl golang-stable git aufs-tools

export GOPATH=~/go/
export PATH=$GOPATH/bin:$PATH

mkdir -p $GOPATH/src/github.com/dotcloud
cd $GOPATH/src/github.com/dotcloud
git clone git://github.com/dotcloud/docker.git
cd docker

go get -v github.com/dotcloud/docker/...
go install -v github.com/dotcloud/docker/...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then run the docker daemon:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo $GOPATH/bin/docker -d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you make any changes to the code, run the &lt;code&gt;go install&lt;/code&gt; command
(above) to recompile docker. Feel free to change the git clone command
above to your own fork, to make pull request&amp;rsquo;s easier.&lt;/p&gt;

&lt;p&gt;Docker requires Go 1.1, if you have an older version it will not compile
correctly.&lt;/p&gt;

&lt;h1 id=&#34;docker-daemon:7906d5806871be907588a3a390328f7d&#34;&gt;Docker Daemon&lt;/h1&gt;

&lt;p&gt;The Docker daemon needs to be running on your system to control the
containers. The daemon needs to be run as Root so that it can have
access to everything it needs.&lt;/p&gt;

&lt;h2 id=&#34;starting-the-daemon:7906d5806871be907588a3a390328f7d&#34;&gt;Starting the daemon&lt;/h2&gt;

&lt;p&gt;There are two ways to start the daemon, you can start it using an init
script so that it starts on system boot, and manually starting the
daemon and sending to the background. The init script is the preferred
way of doing this. If you install Docker via a package manager you
already have the init script on your system.&lt;/p&gt;

&lt;p&gt;To start it manually you need to use a command like this.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo &amp;lt;path to&amp;gt;/docker -d &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When Docker starts, it will listen on 127.0.0.1:4243 to allow only local
connections but you can set it to 0.0.0.0:4243 or a specific host ip to
give access to everybody.&lt;/p&gt;

&lt;p&gt;To change the host and port that docker listens to you will need to use
the &lt;code&gt;-H&lt;/code&gt; flag when starting docker.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;-H&lt;/code&gt; accepts host and port assignment in the following format:
tcp://[host][:port] or unix://path For example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;tcp://host -&amp;gt; tcp connection on host:4243&lt;/li&gt;
&lt;li&gt;tcp://host:port -&amp;gt; tcp connection on host:port&lt;/li&gt;
&lt;li&gt;tcp://:port -&amp;gt; tcp connection on 127.0.0.1:port&lt;/li&gt;
&lt;li&gt;unix://path/to/socket -&amp;gt; unix socket located at path/to/socket&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When you do this, you need to also let the docker client know what
daemon you want to connect too. To do that you have to also pass in the
-H flag to with the ip:port of the daemon to connect too.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Run docker in daemon mode on port 5555
sudo &amp;lt;path to&amp;gt;/docker -H 0.0.0.0:5555 &amp;amp;

# Download a base image using the daemon on port 5555
docker -H :5555 pull base
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can use multiple -H, for example, if you want to listen on both tcp
and a unix socket&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Run docker in daemon mode on 127.0.0.1:4243 and unix socket unix:///var/run/docker.sock
sudo &amp;lt;path to&amp;gt;/docker -H tcp://127.0.0.1:4243 -H unix:///var/run/docker.sock

# Download a base image (no need to put the -H since it is listen on default port :4243)
docker pull base

# OR (pull via the unix socket)
docker -H unix:///var/run/docker.sock pull base
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuration:7906d5806871be907588a3a390328f7d&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;Currently if you want to configure the docker daemon, you can either
pass in command switches to the docker daemon on startup, or you can set
ENV variables that the docker daemon will pick up. I have proposed a
better approach for configuring docker, the idea is to use a
&lt;code&gt;docker.conf&lt;/code&gt; file so that it is easier to set and is more obvious.
Details can be found here:
&lt;a href=&#34;https://github.com/dotcloud/docker/issues/937&#34;&gt;https://github.com/dotcloud/docker/issues/937&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There are two ENV variables that you can set today, there maybe more
added in the future.&lt;/p&gt;

&lt;h3 id=&#34;debug:7906d5806871be907588a3a390328f7d&#34;&gt;DEBUG&lt;/h3&gt;

&lt;p&gt;This tells the Docker daemon that you want more debug information in
your logs.&lt;/p&gt;

&lt;p&gt;defaults to DEBUG=0, set to DEBUG=1 to enable.&lt;/p&gt;

&lt;h3 id=&#34;docker-index-url:7906d5806871be907588a3a390328f7d&#34;&gt;DOCKER_INDEX_URL&lt;/h3&gt;

&lt;p&gt;This tells Docker which Docker index to use. You will most likely not
use this setting, it is mostly used for Docker developer when they want
to try things out with the test index before they release the code.&lt;/p&gt;

&lt;p&gt;defaults to DOCKER_INDEX_URL=&lt;a href=&#34;https://index.docker.io&#34;&gt;https://index.docker.io&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;example:7906d5806871be907588a3a390328f7d&#34;&gt;Example&lt;/h3&gt;

&lt;p&gt;This is how you would set it if it was in an init file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# /etc/init/docker.conf
env LC_ALL=&amp;quot;en_US.UTF-8&amp;quot;
env DOCKER_INDEX_URL=&amp;quot;https://index.docker.io&amp;quot;
env DEBUG=1
exec /usr/local/bin/docker -d
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;logs:7906d5806871be907588a3a390328f7d&#34;&gt;Logs&lt;/h2&gt;

&lt;p&gt;There is no official Docker log file right now, I have opened an issue
and requested one: &lt;a href=&#34;https://github.com/dotcloud/docker/issues/936&#34;&gt;https://github.com/dotcloud/docker/issues/936&lt;/a&gt; but
in the meantime if you are using upstart you can use
&lt;code&gt;/var/log/upstart/docker.log&lt;/code&gt; which has some information, but not as
much as I would like.&lt;/p&gt;

&lt;h1 id=&#34;testing-docker-install:7906d5806871be907588a3a390328f7d&#34;&gt;Testing Docker install&lt;/h1&gt;

&lt;p&gt;Now that you have Docker running, you can start to issue some Docker
commands to see how things are working. The very first commands that I
always run are &lt;code&gt;Docker version&lt;/code&gt; and &lt;code&gt;Docker info&lt;/code&gt;. These tell me quickly
if I have everything working correctly. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker version
Client version: 0.4.8
Server version: 0.4.8
Go version: go1.1

$ docker info
Containers: 0
Images: 0
WARNING: No memory limit support
WARNING: No swap limit support
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that I have two warnings for my docker info. If you use Debian or
Ubuntu kernels, and want to enable memory and swap accounting, you must
add the following command-line parameters to your kernel:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cgroup_enable=memory swapaccount=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On Debian or Ubuntu systems, if you use the default GRUB bootloader, you
can add those parameters by editing &lt;code&gt;/etc/default/grub&lt;/code&gt; and extending
GRUB_CMDLINE_LINUX. Look for the following line:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GRUB_CMDLINE_LINUX=&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And replace it by the following one:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GRUB_CMDLINE_LINUX=&amp;quot;cgroup_enable=memory swapaccount=1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then run &lt;code&gt;update-grub&lt;/code&gt;, and reboot the server.&lt;/p&gt;

&lt;h1 id=&#34;terminology:7906d5806871be907588a3a390328f7d&#34;&gt;Terminology&lt;/h1&gt;

&lt;p&gt;There are going to be some terms that you hear throughout this tutorial,
to make sure you understand what we are talking about, I&amp;rsquo;ll explain a
few of them here.&lt;/p&gt;

&lt;h2 id=&#34;image:7906d5806871be907588a3a390328f7d&#34;&gt;Image&lt;/h2&gt;

&lt;p&gt;An image is a read only layer used to build a container. They do not
change.&lt;/p&gt;

&lt;h2 id=&#34;container:7906d5806871be907588a3a390328f7d&#34;&gt;Container&lt;/h2&gt;

&lt;p&gt;Is basically a self contained runtime environment that is built using
one or more images. You can commit your changes to a container and
create an image.&lt;/p&gt;

&lt;h2 id=&#34;index-registry:7906d5806871be907588a3a390328f7d&#34;&gt;index / registry&lt;/h2&gt;

&lt;p&gt;These are public or private servers where people can upload their
repositories so they can easily share what they made.&lt;/p&gt;

&lt;h2 id=&#34;repository:7906d5806871be907588a3a390328f7d&#34;&gt;Repository&lt;/h2&gt;

&lt;p&gt;A repository is a group of images located in the docker registry. There
are two types of repositories, Top level and user repositories. Top
level repositories don&amp;rsquo;t have a &amp;lsquo;/&amp;rsquo; in the name and they are usually
reserved for base images. These Top level repositories is what most
people build their repositories on top of. They are controlled by the
maintainers of Docker. User repositories are repositories that anyone
can upload into the registry and share with other people.&lt;/p&gt;

&lt;h1 id=&#34;getting-help-with-docker:7906d5806871be907588a3a390328f7d&#34;&gt;Getting Help with Docker&lt;/h1&gt;

&lt;p&gt;If you have a question or problem when using Docker, there are a number
of different ways to help you. Here is a list of the ways, pick the one
that works best for you.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;IRC: #docker on freenode, There are a bunch (250+) people normally
in this channel, come on in, and ask your question, we are very
friendly and we don&amp;rsquo;t bite. Also newbie questions are welcome.&lt;/li&gt;
&lt;li&gt;Email: There is a google group called docker-club. Join the list,
and ask any questions you might have.
&lt;a href=&#34;https://groups.google.com/d/forum/docker-club&#34;&gt;https://groups.google.com/d/forum/docker-club&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Twitter: &lt;a href=&#34;http://twitter.com/getdocker/&#34;&gt;http://twitter.com/getdocker/&lt;/a&gt; Follow along, if you aren&amp;rsquo;t
already, lots of great info posted every day.&lt;/li&gt;
&lt;li&gt;StackOverflow: We love Stack Overflow, if you also enjoy it, feel
free to post a question using the docker tag, and one of the many
Docker fans will get back to you quickly. If you love getting
points, feel free to answer questions as well.&lt;/li&gt;
&lt;li&gt;Bugs and feature requests: If you have a bug or feature request,
submit them to GitHub. &lt;a href=&#34;http://www.github.com/dotcloud/docker&#34;&gt;http://www.github.com/dotcloud/docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;part-1-getting-started:7906d5806871be907588a3a390328f7d&#34;&gt;Part 1. Getting Started&lt;/h1&gt;

&lt;p&gt;Now that we have the boring stuff out of the way lets start playing with
Docker. The very first example we are going to do is a very simple one,
we will spin up a container and print &lt;code&gt;hello world&lt;/code&gt; to the screen. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#run a simple echo command, that will echo hello world back to the console over standard out.
$ docker run base /bin/echo hello world
hello world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If this was your first docker command you will notice that it will need
to download the base image first. It only needs to do this once, and it
caches it locally so you don&amp;rsquo;t need to do this again. We could have
broken these out into two commands &lt;code&gt;docker pull base&lt;/code&gt; and then the
docker run command, but I was lazy and put them together, and Docker is
smart enough to know what I want to do, and do it for me.&lt;/p&gt;

&lt;p&gt;Now you might be wondering what is Docker doing here exactly. It doesn&amp;rsquo;t
look like much because we picked such a simple example, but here is what
is happening.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Generated a new LXC container&lt;/li&gt;
&lt;li&gt;Created a new file system&lt;/li&gt;
&lt;li&gt;Mounted a read/write layer&lt;/li&gt;
&lt;li&gt;Allocated network interface&lt;/li&gt;
&lt;li&gt;Setup IP&lt;/li&gt;
&lt;li&gt;Setup NATing&lt;/li&gt;
&lt;li&gt;Executed the process in the container&lt;/li&gt;
&lt;li&gt;Captured it&amp;rsquo;s output&lt;/li&gt;
&lt;li&gt;Printed to screen&lt;/li&gt;
&lt;li&gt;Stopped the container&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;All in under a second!&lt;/p&gt;

&lt;p&gt;If we run the &lt;code&gt;docker images&lt;/code&gt; command we should see the base image in
our list. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker images
REPOSITORY          TAG                 ID                  CREATED             SIZE
base                latest              b750fe79269d        3 months ago        24.65 kB (virtual 180.1 MB)
base                ubuntu-12.10        b750fe79269d        3 months ago        24.65 kB (virtual 180.1 MB)
base                ubuntu-quantal      b750fe79269d        3 months ago        24.65 kB (virtual 180.1 MB)
base                ubuntu-quantl       b750fe79269d        3 months ago        24.65 kB (virtual 180.1 MB)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice how you see the same image more then once, that is because there
are more then one tag for the same image.&lt;/p&gt;

&lt;p&gt;If we want to see the container we just ran we can run the &lt;code&gt;docker ps&lt;/code&gt;
command. Since it isn&amp;rsquo;t running anymore we need to use the &lt;code&gt;-a&lt;/code&gt; flag to
show us all of the image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps -a
ID                  IMAGE               COMMAND                CREATED             STATUS              PORTS
861361e27501        base:latest         /bin/echo hello world  1 minutes ago       Exit 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lets do something a little more complicated. We are going to do the same
thing, but instead of having the container exit right after we start, we
want it to keep running in the background, and print hello world every
second:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ CONTAINER_ID=$(docker run -d base /bin/sh -c &amp;quot;while true; do echo hello world; sleep 1; done&amp;quot;)
$ echo $CONTAINER_ID
f684fc88aec3

$ docker ps
ID                  IMAGE               COMMAND                CREATED             STATUS              PORTS
f684fc88aec3        base:latest         /bin/sh -c while tru   33 seconds ago      Up 33 seconds
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There we go, now lets see what the container is doing by looking at the
logs for the container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker logs f684fc88aec3
hello world
hello world
hello world
hello world
hello world
.. (trimmed)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now lets attach to the container and see the results in realtime:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker attach f684fc88aec3
hello world
hello world
hello world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, enough fun for this container, lets stop it.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;\$ docker stop f684fc88aec3 f684fc88aec3&lt;/p&gt;

&lt;p&gt;\$ docker ps ID IMAGE COMMAND CREATED STATUS PORTS&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Another thing we could have done to look at the container was inspect
the container, we can do this while it is running or after it stopped:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker inspect f684fc88aec3
[{
    &amp;quot;ID&amp;quot;: &amp;quot;f684fc88aec3bf5b74df2fe03da1fe7cebf07a89d308b6ac7e8a6f14d9c9a3dd&amp;quot;,
    &amp;quot;Created&amp;quot;: &amp;quot;2013-07-05T21:23:31.27766521Z&amp;quot;,
    &amp;quot;Path&amp;quot;: &amp;quot;/bin/sh&amp;quot;,
    &amp;quot;Args&amp;quot;: [
        &amp;quot;-c&amp;quot;,
        &amp;quot;while true; do echo hello world; sleep 1; done&amp;quot;
    ],
    &amp;quot;Config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;f684fc88aec3&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: false,
        &amp;quot;AttachStdout&amp;quot;: false,
        &amp;quot;AttachStderr&amp;quot;: false,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: false,
        &amp;quot;OpenStdin&amp;quot;: false,
        &amp;quot;StdinOnce&amp;quot;: false,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: [
            &amp;quot;/bin/sh&amp;quot;,
            &amp;quot;-c&amp;quot;,
            &amp;quot;while true; do echo hello world; sleep 1; done&amp;quot;
        ],
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;base&amp;quot;,
        &amp;quot;Volumes&amp;quot;: {},
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: []
    },
    &amp;quot;State&amp;quot;: {
        &amp;quot;Running&amp;quot;: false,
        &amp;quot;Pid&amp;quot;: 0,
        &amp;quot;ExitCode&amp;quot;: 137,
        &amp;quot;StartedAt&amp;quot;: &amp;quot;2013-07-05T21:23:31.298200635Z&amp;quot;,
        &amp;quot;Ghost&amp;quot;: false
    },
    &amp;quot;Image&amp;quot;: &amp;quot;b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc&amp;quot;,
    &amp;quot;NetworkSettings&amp;quot;: {
        &amp;quot;IPAddress&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;IPPrefixLen&amp;quot;: 0,
        &amp;quot;Gateway&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Bridge&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;PortMapping&amp;quot;: null
    },
    &amp;quot;SysInitPath&amp;quot;: &amp;quot;/usr/bin/docker&amp;quot;,
    &amp;quot;ResolvConfPath&amp;quot;: &amp;quot;/etc/resolv.conf&amp;quot;,
    &amp;quot;Volumes&amp;quot;: {},
    &amp;quot;VolumesRW&amp;quot;: {}
}]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is a lot of information there, you might not need it now, but you
may need it in the future, so it is nice to have it available.&lt;/p&gt;

&lt;p&gt;Now that you know the basics go to part 2, and learn how to build an
image.&lt;/p&gt;

&lt;h1 id=&#34;part-2-building-an-image:7906d5806871be907588a3a390328f7d&#34;&gt;Part 2. Building an image&lt;/h1&gt;

&lt;p&gt;Our goal for this part is to create our own Redis server container. The
first thing we will need to do is decide which image we want to build
on. I usually pick the ubuntu image, but sometimes it is nice to start
from something a little higher so that I don&amp;rsquo;t have to recreate steps,
and I can build on the shoulders of others.&lt;/p&gt;

&lt;p&gt;We are going to run /bin/bash with the &lt;code&gt;-i&lt;/code&gt; and the &lt;code&gt;-t&lt;/code&gt; flags. &lt;code&gt;-i&lt;/code&gt;
tells Docker to keep stdin open even if not attached, and &lt;code&gt;-t&lt;/code&gt; is to
allocate a pseudo-tty. Once we run the command, we will be connected
into the container, and all commands at this point are running from
inside the container. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -i -t ubuntu /bin/bash
root@dda8bfc22397:/# hostname
dda8bfc22397
root@dda8bfc22397:/# ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0  18060  1940 ?        S    21:40   0:00 /bin/bash
root        11  0.0  0.0  15532  1136 ?        R+   21:41   0:00 ps aux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OK, it looks like we are in, and things are working well, now lets get
to work.&lt;/p&gt;

&lt;p&gt;We are going to update apt and then install redis:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apt-get update
$ apt-get install redis-server
$ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0  18060  1944 ?        S    22:21   0:00 /bin/bash
redis      116  0.0  0.0  36628  1656 ?        Ssl  22:22   0:00 /usr/bin/redis-server /etc/redis/redis.conf
root       125  0.0  0.0  15532  1140 ?        R+   22:23   0:00 ps aux
$ exit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have a container with redis installed. Less see what we did to
the container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker diff dda8bfc22397
A /.bash_history
C /dev
A /dev/kmsg
C /etc
C /etc/bash_completion.d
A /etc/bash_completion.d/redis-cli
C /etc/default
A /etc/default/redis-server
.. (trimmed)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It should show you what files have changed &amp;copy; and which ones were added
(A). Lets save our work so we can reuse this in the future. To do this
we need to &lt;code&gt;docker commit&lt;/code&gt; the container to create an image. In order to
commit changes you need your container_id. If you don&amp;rsquo;t remember it
don&amp;rsquo;tw worry you can get it from &lt;code&gt;docker ps -a&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps -a  # grab the container id (this will be the first one in the list)
$ docker commit &amp;lt;container_id&amp;gt; &amp;lt;your username&amp;gt;/redis
82ebf04d9385
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It returns an image id. if we run &lt;code&gt;docker images&lt;/code&gt; we should see it
listed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker images
REPOSITORY          TAG                 ID                  CREATED              SIZE
base                latest              b750fe79269d        3 months ago         24.65 kB (virtual 180.1 MB)
base                ubuntu-12.10        b750fe79269d        3 months ago         24.65 kB (virtual 180.1 MB)
base                ubuntu-quantal      b750fe79269d        3 months ago         24.65 kB (virtual 180.1 MB)
base                ubuntu-quantl       b750fe79269d        3 months ago         24.65 kB (virtual 180.1 MB)
kencochrane/redis   latest              82ebf04d9385        About a minute ago   98.46 MB (virtual 278.6 MB)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lets run our new image and see if it works:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d -p 6379 kencochrane/redis /usr/bin/redis-server
4cbaae2f67d0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;-d&lt;/code&gt; tell docker to run it in the background, just like our Hello
World daemon from the last part. &lt;code&gt;-p 6379&lt;/code&gt; says to use 6379 as the port
for this container.&lt;/p&gt;

&lt;p&gt;Test 1 Connect to the container with the redis-cli. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps  # grab the new container id
$ docker inspect &amp;lt;container_id&amp;gt; | grep IPAddress   # grab the ipaddress of the container
&amp;quot;IPAddress&amp;quot;: &amp;quot;172.16.42.5&amp;quot;,
redis-cli -h 172.16.42.5 -p 6379
redis 10.0.3.32:6379&amp;gt; set docker awesome
OK
redis 10.0.3.32:6379&amp;gt; get docker
&amp;quot;awesome&amp;quot;
redis 10.0.3.32:6379&amp;gt; exit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Connect to the public IP with the redis-cli. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps  # grab the new container id
$ docker port &amp;lt;container_id&amp;gt; 6379  # grab the external port
49153
ip addr show   # grab the host ip address
redis-cli -h &amp;lt;host ipaddress&amp;gt; -p 49153
redis 192.168.0.1:49153&amp;gt; set docker awesome
OK
redis 192.168.0.1:49153&amp;gt; get docker
&amp;quot;awesome&amp;quot;
redis 192.168.0.1:49153&amp;gt; exit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We just proved that it is working as it should, we can now stop the
container using &lt;code&gt;docker stop&lt;/code&gt;. You have now created your first Docker
image. Continue on to the next part to learn how to use that image on
another host, and share it with the world.&lt;/p&gt;

&lt;h1 id=&#34;part-3-docker-index-registry:7906d5806871be907588a3a390328f7d&#34;&gt;Part 3: Docker Index/registry&lt;/h1&gt;

&lt;p&gt;When you create an image it is only available on that server. In the
past, if you wanted to use the same image on another server, you would
need to recreate the image, which isn&amp;rsquo;t ideal because there is no way to
guarantee that the two images are the same. To make moving images
around, and sharing them easier, the Docker team created the &lt;a href=&#34;https://index.docker.io&#34;&gt;Docker
index&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The Docker Index is a public Registry where people can upload their
custom images and share them with others. This is also where the base
images are located and where you pull from when doing a &lt;code&gt;docker pull&lt;/code&gt;.
There are two parts to the Docker Index. There is a web component that
makes it easier for you to mange your images and account with a
graphical interface. There is also the API which is what the Docker
client uses to interact with the index. This allows you to do some of
the tasks from the command line or the web UI.&lt;/p&gt;

&lt;p&gt;The Docker Registry is server that stores all of the images and
repositories. The Index just has the metadata about the images,
repositories and the user accounts, but all of the images and
repositories are stored in the Docker Registry.&lt;/p&gt;

&lt;h2 id=&#34;creating-an-account-on-the-docker-index:7906d5806871be907588a3a390328f7d&#34;&gt;Creating an Account on the Docker Index&lt;/h2&gt;

&lt;p&gt;There are two ways to create an account on the Docker Index. Either way
requires that you enter a valid email address and that the email address
is confirmed before you can activate the account. So make sure you enter
a valid email address, and then check you email after registering so
that you can click the confirmation link and confirm the account.&lt;/p&gt;

&lt;h3 id=&#34;command-line:7906d5806871be907588a3a390328f7d&#34;&gt;Command Line&lt;/h3&gt;

&lt;p&gt;If you want to register for an account from the command line you can use
the &lt;code&gt;docker login&lt;/code&gt; command. The Docker login command will either
register an account for you, or if you already have an account it will
log you into the Index.&lt;/p&gt;

&lt;p&gt;When you register via the command line, it will register you and login
you in a the same time. Remember to click on the activation link in the
confirmation email, or else your account isn&amp;rsquo;t fully active. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker login
Username (): myusername
Password:
Email (): myusername@example.com
Login Succeeded
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;web-site:7906d5806871be907588a3a390328f7d&#34;&gt;Web site&lt;/h3&gt;

&lt;p&gt;If you prefer to register from a web browser, then go to
&lt;a href=&#34;https://index.docker.io/account/signup/&#34;&gt;https://index.docker.io/account/signup/&lt;/a&gt; and then fill out the form,
and then click on the activation link sent in the confirmation email.&lt;/p&gt;

&lt;p&gt;Once you are activated, you will still need to login to the Docker Index
from your Docker client on your server, so that you can link the two. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker login
Username (): myusername
Password:
Email (): myusername@example.com
Login Succeeded
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;credentials:7906d5806871be907588a3a390328f7d&#34;&gt;Credentials&lt;/h3&gt;

&lt;p&gt;When you login to the Docker Index from the Docker client, it will store
your login information, so you don&amp;rsquo;t have to enter it again. Depending
on what Docker client version you are using it will either be located at
&lt;code&gt;~/.dockercfg&lt;/code&gt; or &lt;code&gt;/var/lib/docker/.dockercfg&lt;/code&gt;. If you are having issues
logging in you, can delete this file, and it will re-prompt you for your
username and password the next time you login. Running Docker login
should do the same thing, so do that first, and use this for a last
resort.&lt;/p&gt;

&lt;h2 id=&#34;search:7906d5806871be907588a3a390328f7d&#34;&gt;Search&lt;/h2&gt;

&lt;p&gt;There are a lot of Docker images in the Index, with more getting added
everyday. Before you go ahead and create your own, you should see if
someone has already created what you wanted. The best way to find images
is via the &lt;code&gt;docker search&lt;/code&gt; command on the command line, or via the
Docker Index website. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker search memcache
Found 5 results matching your query (&amp;quot;memcache&amp;quot;)
NAME                     DESCRIPTION
ehazlett/memcached       Memcached 1.4.15.  Specify the following e...
jbarbier/memcached       memcached
checkraiser/memcached
arcus/memcached
bacongobbler/memcached
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pulling:7906d5806871be907588a3a390328f7d&#34;&gt;Pulling&lt;/h2&gt;

&lt;p&gt;When you found an image that you want to pull down and try out, you
would use the &lt;code&gt;docker pull&lt;/code&gt; command. It will then connect to the Docker
Index find the repository that you want, and it will let the Docker
client know where in the Docker Registry it can download it. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull jbarbier/memcached
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pushing:7906d5806871be907588a3a390328f7d&#34;&gt;Pushing&lt;/h2&gt;

&lt;p&gt;If you have a repository that you want to share with someone then you
would need to push it into the Docker Index/Registry using the
&lt;code&gt;docker push&lt;/code&gt; command. When you do a push, it will contact the Docker
Index, and make sure you are logged in, have permission to push, and
that the same repository doesn&amp;rsquo;t already exist. If everything looks
good, it will then return a special authorization token that the Docker
client will use when push up the repository to the Docker Registry.&lt;/p&gt;

&lt;p&gt;Since the Docker Register doesn&amp;rsquo;t have any concept of authorization, or
user accounts, it relies on Authorization tokens to manage permissions.
The nice thing about this, is that Docker hides this all from you, and
you don&amp;rsquo;t even need to worry about it, it will just work assuming you
have permission to push.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s push the repository that we created in the last part, so that
others can use it. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker push kencochrane/redis
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that it is up on the registry we can use it on any Docker host, and
we just need to do a &lt;code&gt;Docker pull&lt;/code&gt; to get it on the host, and I&amp;rsquo;ll know
it is going to be the same every time.&lt;/p&gt;

&lt;h2 id=&#34;repository-description:7906d5806871be907588a3a390328f7d&#34;&gt;Repository Description&lt;/h2&gt;

&lt;p&gt;If you want to add a description to your repository so that it lets
people know what it does, you can login to the website and edit the
description there. There are two descriptions, a short one, which is
what shows up in search results, and is plain text. There is also a full
description which allows MarkDown and is used to give more detailed
information.&lt;/p&gt;

&lt;h2 id=&#34;deleting-a-repository:7906d5806871be907588a3a390328f7d&#34;&gt;Deleting a Repository&lt;/h2&gt;

&lt;p&gt;If you made a mistake and need to delete a repository, you can do this
by logging into the Docker Index website, and clicking on the repository
settings and clicking the delete button. Make sure this is what you want
to do, because there is no turning back once you do this.&lt;/p&gt;

&lt;h1 id=&#34;part-4-docker-buildfiles:7906d5806871be907588a3a390328f7d&#34;&gt;Part 4: Docker Buildfiles&lt;/h1&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Go over what a Docker Buildfile is, and how to make their own.&lt;/li&gt;
&lt;li&gt;With examples&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;part-5-advanced-usage:7906d5806871be907588a3a390328f7d&#34;&gt;Part 5: Advanced Usage&lt;/h1&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;docker run&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   limiting memory, cpu

&lt;ul&gt;
&lt;li&gt;detached vs attached&lt;/li&gt;
&lt;li&gt;volume/bind mounting&lt;/li&gt;
&lt;/ul&gt;&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;More?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;part-6-using-a-private-registry:7906d5806871be907588a3a390328f7d&#34;&gt;Part 6: Using a Private Registry&lt;/h1&gt;

&lt;p&gt;One of the things that makes Docker so useful is how easy it is to pull
ready-to-use images from a central location, Docker&amp;rsquo;s Central Registry.
It is just as easy to push your own image (or collection of tagged
images as a repository) to the same public registry so that everyone can
benefit from your newly Dockerized service.&lt;/p&gt;

&lt;p&gt;But sometimes you can&amp;rsquo;t share your repository with the world because it
contains proprietary code or confidential information. Today we are
introducing an easy way to share repositories on your own registry so
that you can control access to them and still share them among multiple
Docker daemons. You can decide if your registry is public or private.&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;ll need the &lt;a href=&#34;http://docs.docker.io/en/latest/installation/upgrading/&#34;&gt;latest version of
Docker&lt;/a&gt;
(&amp;gt;=0.5.0) to use this new feature, and you must run this version as
both the daemon and the client. You&amp;rsquo;ll also need the &lt;a href=&#34;https://github.com/dotcloud/docker-registry&#34;&gt;Docker registry
code&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;using-push-and-pull-with-a-private-registry:7906d5806871be907588a3a390328f7d&#34;&gt;Using Push and Pull with a Private Registry&lt;/h2&gt;

&lt;p&gt;You&amp;rsquo;ve already seen how to push and pull from the Central Registry. To
push to or pull from your &lt;em&gt;own&lt;/em&gt; registry, you just need to add the
registry&amp;rsquo;s location to the repository name. It will look like
&lt;code&gt;my.registry.address:port/repositoryname.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s say I want to push the repository &amp;ldquo;ubuntu&amp;rdquo; to my local registry,
which runs on my local machine, on the port 5000: :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# First, make sure you have the &amp;quot;ubuntu&amp;quot; repository:
docker pull ubuntu

# Then, find the image id that corresponds to the ubuntu repository
docker images | grep ubuntu | grep latest
ubuntu  latest  8dbd9e392a96  12 weeks ago  263 MB (virtual 263 MB)

# Almost there!
# Tag to create a repository with the full registry location.
# The location becomes a permanent part of the repository name.
docker tag 8dbd9e392a96 localhost.localdomain:5000/ubuntu

# Finally, push the new repository to its home location.
docker push localhost.localdomain:5000/ubuntu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Obviously, the push will fail if no registry server answer locally on
the port 5000. We&amp;rsquo;ll briefly show how to start your own registry server
in the next subsection.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;note&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The punctuation in the repository name is important! Docker looks for
either a &amp;ldquo;.&amp;rdquo; (domain separator) or &amp;ldquo;:&amp;rdquo; (port separator) to learn that
the first part of the repository name is a location and not a user
name. If you just had localhost without either &lt;code&gt;.localdomain&lt;/code&gt; or
&lt;code&gt;:5000&lt;/code&gt; (either one would do) then Docker would believe that localhost
is a username, as in &lt;code&gt;localhost/ubuntu&lt;/code&gt; or &lt;code&gt;samalba/hipache&lt;/code&gt;. It would
then try to push to the default Central Registry. Having a dot or
colon in the first part tells Docker that this name contains a
hostname and that it should push to your specified location instead.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;installing-your-own-registry:7906d5806871be907588a3a390328f7d&#34;&gt;Installing Your Own Registry&lt;/h2&gt;

&lt;p&gt;Docker-Registry is a an Open Source Python application available on
Github: &lt;a href=&#34;https://github.com/dotcloud/docker-registry&#34;&gt;https://github.com/dotcloud/docker-registry&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can use the Docker-Registry to provide a private or public registry
service for Docker repositories. Since it is your host, you can control
access to it by putting it on a private network or otherwise protecting
its service port. You&amp;rsquo;ll want to choose the DNS name of the host
carefully, since that name will become a permanent part of each
repository&amp;rsquo;s name (e.g. &lt;code&gt;my.registry.name/myrepository&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;You can test out the Docker-Registry first on your local machine
(presuming you have a Python environment set up). :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/dotcloud/docker-registry.git
cd docker-registry
cp config_sample.yml config.yml
pip install -r requirements.txt
gunicorn --access-logfile - --log-level debug --debug \
    -b 0.0.0.0:5000 -w 1 wsgi:application
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That sets up the Docker-Registry to listen on all your network
interfaces on port 5000. You&amp;rsquo;re using the &lt;code&gt;dev&lt;/code&gt; flavor configuration by
default, which uses local storage for the repositories. The
configuration file (&lt;code&gt;config.yml&lt;/code&gt;) also allows you to specify other
flavors, like production, and to use other storage backends, like S3.&lt;/p&gt;

&lt;p&gt;There is currently no authentication built into the Docker-Registry, so
if you want to keep this private, you&amp;rsquo;ll need to keep the host on a
private network. We&amp;rsquo;d recommend running a production Docker-Registry
behind an Nginx server which sipplies chunked transfer encoding.&lt;/p&gt;

&lt;h1 id=&#34;part-7-automating-docker:7906d5806871be907588a3a390328f7d&#34;&gt;Part 7: Automating Docker&lt;/h1&gt;

&lt;p&gt;Running docker commands on the command line are a good way to start, but
if you need to automate what you are doing, it isn&amp;rsquo;t ideal. To make this
better Docker provides a REST based remote API. The remote API allows
you to do everything that the command line does. In fact the command
line is just a client for the REST API.&lt;/p&gt;

&lt;h2 id=&#34;remote-api:7906d5806871be907588a3a390328f7d&#34;&gt;Remote API&lt;/h2&gt;

&lt;p&gt;Docker provides a remote API for the docker daemon so that you can
control it programmatically, for documentation on how it works check out
the &lt;a href=&#34;http://docs.docker.io/en/latest/api/docker_remote_api/&#34;&gt;Docker Remote API
Docs&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;docker-web-ui-s:7906d5806871be907588a3a390328f7d&#34;&gt;Docker Web UI&amp;rsquo;s&lt;/h2&gt;

&lt;p&gt;Docker is a completly command line experience, which is fine for
hackers, but some people prefer a more graphical experience, and for
those folks I would recommend checking out these projects that people
have started.&lt;/p&gt;

&lt;h3 id=&#34;dockland:7906d5806871be907588a3a390328f7d&#34;&gt;Dockland&lt;/h3&gt;

&lt;p&gt;A ruby based Docker web UI&lt;/p&gt;

&lt;p&gt;Code: &lt;a href=&#34;https://github.com/dynport/dockland&#34;&gt;https://github.com/dynport/dockland&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;shipyard:7906d5806871be907588a3a390328f7d&#34;&gt;Shipyard&lt;/h3&gt;

&lt;p&gt;A python/django based Docker web UI&lt;/p&gt;

&lt;p&gt;Code: &lt;a href=&#34;https://github.com/ehazlett/shipyard&#34;&gt;https://github.com/ehazlett/shipyard&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;dockerui:7906d5806871be907588a3a390328f7d&#34;&gt;DockerUI&lt;/h3&gt;

&lt;p&gt;An Angular.js based Docker web UI&lt;/p&gt;

&lt;p&gt;Code: &lt;a href=&#34;https://github.com/crosbymichael/dockerui&#34;&gt;https://github.com/crosbymichael/dockerui&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;docker-libraries:7906d5806871be907588a3a390328f7d&#34;&gt;Docker Libraries&lt;/h2&gt;

&lt;p&gt;If you want to write some code to interact with Docker, there is most
likely already a binding for your programming language. Check out the
link in the documentation to find what is available. If there isn&amp;rsquo;t one
available for your language of choice, feel free to create your own, and
let us know so we can update the documentation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.docker.io/en/latest/api/docker_remote_api/#id15&#34;&gt;Docker Library list in the Docker
Docs&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;what-can-i-do-to-help:7906d5806871be907588a3a390328f7d&#34;&gt;What can I do to help?&lt;/h1&gt;

&lt;p&gt;If you are a big fan of Docker, and want to know how to help out, then
look at the list below, and see if any of them are things that you can
do.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Contribute to Docker, it could be as small as a bug fix,
documentation update, or a new feature. Look through the &lt;a href=&#34;https://github.com/dotcloud/docker/issues?state=open&#34;&gt;docker
issues&lt;/a&gt;, and
see if anything tickles your fancy.&lt;/li&gt;
&lt;li&gt;Tweet about how much you love Docker&lt;/li&gt;
&lt;li&gt;Write a blog post about how you use Docker, and how others can do
what you have done.&lt;/li&gt;
&lt;li&gt;Talk at a conference or meetup. This is a good way to introduce
docker to a new set of potential Docker lovers.&lt;/li&gt;
&lt;li&gt;Create a product that uses Docker, and let everyone know how Docker
made your life easier.&lt;/li&gt;
&lt;li&gt;Make a video showing how you use Docker, and upload
to YouTube/Vimeo.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Answer questions on&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   Stack Overflow

&lt;ul&gt;
&lt;li&gt;IRC&lt;/li&gt;
&lt;li&gt;Mailing list&lt;/li&gt;
&lt;/ul&gt;&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Attend the Docker hack days and meet other Docker users, and let us
know how we can make Docker even better.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Get a Docker sticker, and display it proudly.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Wear your Docker shirt around town all day.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;tips-and-tricks:7906d5806871be907588a3a390328f7d&#34;&gt;Tips and Tricks&lt;/h1&gt;

&lt;p&gt;This section includes some helpful tips and tricks that will make using
Docker even more easier and fun.&lt;/p&gt;

&lt;h2 id=&#34;remove-all-docker-images:7906d5806871be907588a3a390328f7d&#34;&gt;Remove all Docker images&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ docker rmi `docker images -a -q`
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;remove-all-docker-containers:7906d5806871be907588a3a390328f7d&#34;&gt;Remove all Docker containers&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ docker rm `docker ps -a -q`
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;docker-commands:7906d5806871be907588a3a390328f7d&#34;&gt;Docker Commands&lt;/h1&gt;

&lt;p&gt;Here is a list of all of the current Docker commands, the different
parameters they might have, as well as an example or two on how to use
them.&lt;/p&gt;

&lt;h2 id=&#34;attach:7906d5806871be907588a3a390328f7d&#34;&gt;attach&lt;/h2&gt;

&lt;p&gt;Attach to a running container. To disconnect press Ctrl+P, Ctrl+Q.&lt;/p&gt;

&lt;h3 id=&#34;parameters:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER_ID: The ID for the container you want to attach too.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker attach CONTAINER_ID
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;example-1:7906d5806871be907588a3a390328f7d&#34;&gt;Example&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker attach afs232ybh2123d
# To disconnect press Ctrl+P, Ctrl+Q.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;build:7906d5806871be907588a3a390328f7d&#34;&gt;build&lt;/h2&gt;

&lt;p&gt;Build a container from a Dockerfile&lt;/p&gt;

&lt;h3 id=&#34;parameters-1:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;PATH: Build a new container image from the source code at PATH&lt;/li&gt;
&lt;li&gt;URL: When a single Dockerfile is given as URL, then no context
is set. When a git repository is set as URL, the repository is used
as context&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   -t=&amp;ldquo;&amp;rdquo; : Tag to be applied to the resulting image in case
    of success.&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-1:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker build [OPTIONS] PATH | URL | -
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;read-the-dockerfile-from-the-current-directory:7906d5806871be907588a3a390328f7d&#34;&gt;Read the Dockerfile from the current directory&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker build .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will read the Dockerfile from the current directory. It will also
send any other files and directories found in the current directory to
the docker daemon. The contents of this directory would be used by ADD
commands found within the Dockerfile. This will send a lot of data to
the docker daemon if the current directory contains a lot of data. If
the absolute path is provided instead of ., only the files and
directories required by the ADD commands from the Dockerfile will be
added to the context and transferred to the docker daemon.&lt;/p&gt;

&lt;h4 id=&#34;read-a-dockerfile-from-standard-in-stdin-without-context:7906d5806871be907588a3a390328f7d&#34;&gt;Read a Dockerfile from standard in (stdin) without context&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker build - &amp;lt; Dockerfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will read a Dockerfile from Stdin without context. Due to the lack
of a context, no contents of any local directory will be sent to the
docker daemon. ADD doesnt work when running in this mode due to the
absence of the context, thus having no source files to copy to the
container.&lt;/p&gt;

&lt;h4 id=&#34;build-from-a-git-repo:7906d5806871be907588a3a390328f7d&#34;&gt;Build from a git repo&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker build github.com/creack/docker-firefox
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will clone the github repository and use it as context. The
Dockerfile at the root of the repository is used as Dockerfile. Note
that you can specify an arbitrary git repository by using the &lt;a href=&#34;git://&#34;&gt;git://&lt;/a&gt;
schema.&lt;/p&gt;

&lt;h2 id=&#34;commit:7906d5806871be907588a3a390328f7d&#34;&gt;commit&lt;/h2&gt;

&lt;p&gt;Save your containers state to a container image, so the state can be
re-used.&lt;/p&gt;

&lt;p&gt;When you commit your container only the differences between the image
the container was created from and the current state of the container
will be stored (as a diff). See which images you already have using
docker images&lt;/p&gt;

&lt;p&gt;In order to commit to the repository it is required to have committed
your container to an image with your namespace.&lt;/p&gt;

&lt;h3 id=&#34;parameters-2:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER_ID: The container ID for the container you want to commit&lt;/li&gt;
&lt;li&gt;REPOSITORY: The name for your image that you will save to the
repository &amp;lt;your username&amp;gt;/&amp;lt;image name&amp;gt;&lt;/li&gt;
&lt;li&gt;TAG: The tag you want to give to the commit.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   -m=&amp;ldquo;&amp;rdquo;: Commit message

&lt;ul&gt;
&lt;li&gt;-author=&amp;ldquo;&amp;rdquo;: Author (eg. &amp;ldquo;John Hannibal Smith
&amp;lt;&lt;a href=&#34;mailto:hannibal@a-team.com&#34;&gt;hannibal@a-team.com&lt;/a&gt;&amp;gt;&amp;ldquo;&lt;/li&gt;
&lt;li&gt;-run=&amp;ldquo;&amp;rdquo;: Config automatically applied when the image is run.
&amp;ldquo;+`(ex: {&amp;ldquo;Cmd&amp;rdquo;: [&amp;ldquo;cat&amp;rdquo;, &amp;ldquo;/world&amp;rdquo;],
&amp;ldquo;PortSpecs&amp;rdquo;: [&amp;ldquo;22&amp;rdquo;]}&amp;lsquo;)&lt;/li&gt;
&lt;/ul&gt;&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-2:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker commit [OPTIONS] CONTAINER_ID [REPOSITORY [TAG]]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-1:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;basic-commit:7906d5806871be907588a3a390328f7d&#34;&gt;basic commit&lt;/h4&gt;

&lt;p&gt;This will commit a container with a message and author. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker commit -m=&amp;quot;My commit message&amp;quot; -author=&amp;quot;Joe smith&amp;quot; a1bcbabsdhb323h2b
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;commit-with-repository:7906d5806871be907588a3a390328f7d&#34;&gt;commit with repository&lt;/h4&gt;

&lt;p&gt;Same as basic commit, but with a repository name :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker commit -m=&amp;quot;My commit message&amp;quot; -author=&amp;quot;Joe smith&amp;quot; a1bcbabsdhb323h2b joesmith/myrepo
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;commit-with-tag:7906d5806871be907588a3a390328f7d&#34;&gt;commit with tag&lt;/h4&gt;

&lt;p&gt;Same as basic commit, but with a repository name and tag :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker commit -m=&amp;quot;My commit message&amp;quot; -author=&amp;quot;Joe smith&amp;quot; a1bcbabsdhb323h2b joesmith/myrepo mytag
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;full-example:7906d5806871be907588a3a390328f7d&#34;&gt;Full example&lt;/h4&gt;

&lt;p&gt;An example with all parameters and options. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker commit -m=&amp;quot;My commit message&amp;quot; -author=&amp;quot;Joe smith&amp;quot; -run=&#39;{&amp;quot;Hostname&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,&amp;quot;CpuShares&amp;quot;: 0,&amp;quot;Memory&amp;quot;: 0,&amp;quot;MemorySwap&amp;quot;: 0,&amp;quot;PortSpecs&amp;quot;: [&amp;quot;22&amp;quot;, &amp;quot;80&amp;quot;, &amp;quot;443&amp;quot;],&amp;quot;Tty&amp;quot;: true,&amp;quot;OpenStdin&amp;quot;: true,&amp;quot;StdinOnce&amp;quot;: true,&amp;quot;Env&amp;quot;: [&amp;quot;FOO=BAR&amp;quot;, &amp;quot;FOO2=BAR2&amp;quot;],&amp;quot;Cmd&amp;quot;: [&amp;quot;cat&amp;quot;, &amp;quot;-e&amp;quot;, &amp;quot;/etc/resolv.conf&amp;quot;],&amp;quot;Dns&amp;quot;: [&amp;quot;8.8.8.8&amp;quot;, &amp;quot;8.8.4.4&amp;quot;]}&#39; a1bcbabsdhb323h2b joesmith/myrepo mytag
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;diff:7906d5806871be907588a3a390328f7d&#34;&gt;diff&lt;/h2&gt;

&lt;p&gt;Inspect changes on a containers filesystem&lt;/p&gt;

&lt;h3 id=&#34;parameters-3:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER_ID: The ID for the container you want to create a diff
for&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-3:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker diff CONTAINER_ID
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-2:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker diff a1bcbabsdhb323h2b
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;export:7906d5806871be907588a3a390328f7d&#34;&gt;export&lt;/h2&gt;

&lt;p&gt;Stream the contents of a container as a tar archive&lt;/p&gt;

&lt;h3 id=&#34;parameters-4:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER_ID: The ID for the container you want to export.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-4:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker export CONTAINER_ID
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-3:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker export a1bcbabsdhb323h2b &amp;gt; myfile.tar
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;history:7906d5806871be907588a3a390328f7d&#34;&gt;history&lt;/h2&gt;

&lt;p&gt;Show the history of an image&lt;/p&gt;

&lt;h3 id=&#34;parameters-5:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;IMAGE: The name of the image you want to see the history for&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-5:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker history IMAGE
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-4:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker history joesmith/myimage
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;images:7906d5806871be907588a3a390328f7d&#34;&gt;images&lt;/h2&gt;

&lt;p&gt;List the images managed by Docker&lt;/p&gt;

&lt;h3 id=&#34;parameters-6:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;NAME: A filter to limit results to only images matching the NAME&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   -a=false: show all images

&lt;ul&gt;
&lt;li&gt;-q=false: only show numeric IDs&lt;/li&gt;
&lt;li&gt;-viz=false: output in graphviz format&lt;/li&gt;
&lt;/ul&gt;&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-6:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker images [OPTIONS] [NAME]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-5:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;show-images:7906d5806871be907588a3a390328f7d&#34;&gt;Show images&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker images
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;show-images-with-name-ubuntu:7906d5806871be907588a3a390328f7d&#34;&gt;Show images with name ubuntu&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker images ubuntu
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;show-all-images:7906d5806871be907588a3a390328f7d&#34;&gt;Show all images&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker images -a
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;show-only-image-id-s:7906d5806871be907588a3a390328f7d&#34;&gt;Show only image ID&amp;rsquo;s&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker images -q
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;displaying-images-visually:7906d5806871be907588a3a390328f7d&#34;&gt;Displaying images visually&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker images -viz | dot -Tpng -o docker.png
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;import:7906d5806871be907588a3a390328f7d&#34;&gt;import&lt;/h2&gt;

&lt;p&gt;Create a new filesystem image from the contents of a tarball&lt;/p&gt;

&lt;h3 id=&#34;parameters-7:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;URL: At this time, the URL must start with http and point to a
single file archive (.tar, .tar.gz, .bzip) containing a
root filesystem. If you would like to import from a local directory
or archive, you can use the - parameter to take the data from
standard in.&lt;/li&gt;
&lt;li&gt;TAG: name of the tag you want to assign repo after import&lt;/li&gt;
&lt;li&gt;REPOSITORY: the repository to import into.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-7:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker import URL |- [REPOSITORY [TAG]]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-6:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;import-from-a-remote-location:7906d5806871be907588a3a390328f7d&#34;&gt;Import from a remote location&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker import http://example.com/exampleimage.tgz exampleimagerepo
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;import-from-a-local-file:7906d5806871be907588a3a390328f7d&#34;&gt;Import from a local file&lt;/h4&gt;

&lt;p&gt;Import to docker via pipe and standard in:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat exampleimage.tgz | docker import - exampleimagelocal
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;import-from-a-local-directory:7906d5806871be907588a3a390328f7d&#34;&gt;Import from a local directory&lt;/h4&gt;

&lt;p&gt;Note the sudo in this example  you must preserve the ownership of the
files (especially root ownership) during the archiving with tar. If you
are not root (or sudo) when you tar, then the ownerships might not get
preserved. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo tar -c . | docker import - exampleimagedir
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;info:7906d5806871be907588a3a390328f7d&#34;&gt;info&lt;/h2&gt;

&lt;p&gt;Display system-wide information.&lt;/p&gt;

&lt;h3 id=&#34;parameters-8:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;p&gt;None&lt;/p&gt;

&lt;h3 id=&#34;usage-8:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker info
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-7:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker info
Containers: 30
Images: 25
Debug mode (server): true
Debug mode (client): false
Fds: 8
Goroutines: 10
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;inspect:7906d5806871be907588a3a390328f7d&#34;&gt;inspect&lt;/h2&gt;

&lt;p&gt;Return low-level information on a container/image. The command will take
1 or more container or image ids and return all of the information
relating to those ids.&lt;/p&gt;

&lt;h3 id=&#34;parameters-9:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER: The ID for the container you want to export.&lt;/li&gt;
&lt;li&gt;IMAGE: The image name for the images you want information for.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-9:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker inspect CONTAINER|IMAGE [CONTAINER|IMAGE...]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-8:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;container-inspect:7906d5806871be907588a3a390328f7d&#34;&gt;Container inspect&lt;/h4&gt;

&lt;p&gt;Inspect one container :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker inspect a5e78640ece4
[{
    &amp;quot;ID&amp;quot;: &amp;quot;a5e78640ece4b64657b86780ebfeacf614c402cf3b30bb2226f9f8abd48a46ff&amp;quot;,
    &amp;quot;Created&amp;quot;: &amp;quot;2013-07-05T22:43:36.281232878Z&amp;quot;,
    &amp;quot;Path&amp;quot;: &amp;quot;sh&amp;quot;,
    &amp;quot;Args&amp;quot;: [],
    &amp;quot;Config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;a5e78640ece4&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: true,
        &amp;quot;AttachStdout&amp;quot;: true,
        &amp;quot;AttachStderr&amp;quot;: true,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: true,
        &amp;quot;OpenStdin&amp;quot;: true,
        &amp;quot;StdinOnce&amp;quot;: true,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: [
            &amp;quot;sh&amp;quot;
        ],
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;joffrey/busybox&amp;quot;,
        &amp;quot;Volumes&amp;quot;: {},
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: []
    },
    &amp;quot;State&amp;quot;: {
        &amp;quot;Running&amp;quot;: false,
        &amp;quot;Pid&amp;quot;: 0,
        &amp;quot;ExitCode&amp;quot;: 0,
        &amp;quot;StartedAt&amp;quot;: &amp;quot;2013-07-05T22:43:36.286163881Z&amp;quot;,
        &amp;quot;Ghost&amp;quot;: false
    },
    &amp;quot;Image&amp;quot;: &amp;quot;e74096c5172b34732c9769db5f23805cf786dffe25f25da66ebf7c0fc30d0e0b&amp;quot;,
    &amp;quot;NetworkSettings&amp;quot;: {
        &amp;quot;IPAddress&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;IPPrefixLen&amp;quot;: 0,
        &amp;quot;Gateway&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Bridge&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;PortMapping&amp;quot;: null
    },
    &amp;quot;SysInitPath&amp;quot;: &amp;quot;/usr/bin/docker&amp;quot;,
    &amp;quot;ResolvConfPath&amp;quot;: &amp;quot;/etc/resolv.conf&amp;quot;,
    &amp;quot;Volumes&amp;quot;: {},
    &amp;quot;VolumesRW&amp;quot;: {}
}]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;inspect-more-then-one-container:7906d5806871be907588a3a390328f7d&#34;&gt;Inspect more then one container&lt;/h4&gt;

&lt;p&gt;Inspect 2 containers :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker inspect a5e78640ece4 0775b219a48a
[{
    &amp;quot;ID&amp;quot;: &amp;quot;a5e78640ece4b64657b86780ebfeacf614c402cf3b30bb2226f9f8abd48a46ff&amp;quot;,
    &amp;quot;Created&amp;quot;: &amp;quot;2013-07-05T22:43:36.281232878Z&amp;quot;,
    &amp;quot;Path&amp;quot;: &amp;quot;sh&amp;quot;,
    &amp;quot;Args&amp;quot;: [],
    &amp;quot;Config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;a5e78640ece4&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: true,
        &amp;quot;AttachStdout&amp;quot;: true,
        &amp;quot;AttachStderr&amp;quot;: true,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: true,
        &amp;quot;OpenStdin&amp;quot;: true,
        &amp;quot;StdinOnce&amp;quot;: true,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: [
            &amp;quot;sh&amp;quot;
        ],
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;joffrey/busybox&amp;quot;,
        &amp;quot;Volumes&amp;quot;: {},
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: []
    },
    &amp;quot;State&amp;quot;: {
        &amp;quot;Running&amp;quot;: false,
        &amp;quot;Pid&amp;quot;: 0,
        &amp;quot;ExitCode&amp;quot;: 0,
        &amp;quot;StartedAt&amp;quot;: &amp;quot;2013-07-05T22:43:36.286163881Z&amp;quot;,
        &amp;quot;Ghost&amp;quot;: false
    },
    &amp;quot;Image&amp;quot;: &amp;quot;e74096c5172b34732c9769db5f23805cf786dffe25f25da66ebf7c0fc30d0e0b&amp;quot;,
    &amp;quot;NetworkSettings&amp;quot;: {
        &amp;quot;IPAddress&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;IPPrefixLen&amp;quot;: 0,
        &amp;quot;Gateway&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Bridge&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;PortMapping&amp;quot;: null
    },
    &amp;quot;SysInitPath&amp;quot;: &amp;quot;/usr/bin/docker&amp;quot;,
    &amp;quot;ResolvConfPath&amp;quot;: &amp;quot;/etc/resolv.conf&amp;quot;,
    &amp;quot;Volumes&amp;quot;: {},
    &amp;quot;VolumesRW&amp;quot;: {}
},{
    &amp;quot;ID&amp;quot;: &amp;quot;0775b219a48ab9bbebe841a0388f9909e996140f941585e318dbe64289392534&amp;quot;,
    &amp;quot;Created&amp;quot;: &amp;quot;2013-07-05T22:40:47.219244957Z&amp;quot;,
    &amp;quot;Path&amp;quot;: &amp;quot;sh&amp;quot;,
    &amp;quot;Args&amp;quot;: [],
    &amp;quot;Config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;0775b219a48a&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: true,
        &amp;quot;AttachStdout&amp;quot;: true,
        &amp;quot;AttachStderr&amp;quot;: true,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: true,
        &amp;quot;OpenStdin&amp;quot;: true,
        &amp;quot;StdinOnce&amp;quot;: true,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: [
            &amp;quot;sh&amp;quot;
        ],
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;joffrey/busybox&amp;quot;,
        &amp;quot;Volumes&amp;quot;: {},
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: []
    },
    &amp;quot;State&amp;quot;: {
        &amp;quot;Running&amp;quot;: false,
        &amp;quot;Pid&amp;quot;: 0,
        &amp;quot;ExitCode&amp;quot;: 127,
        &amp;quot;StartedAt&amp;quot;: &amp;quot;2013-07-05T22:40:47.224570459Z&amp;quot;,
        &amp;quot;Ghost&amp;quot;: false
    },
    &amp;quot;Image&amp;quot;: &amp;quot;e74096c5172b34732c9769db5f23805cf786dffe25f25da66ebf7c0fc30d0e0b&amp;quot;,
    &amp;quot;NetworkSettings&amp;quot;: {
        &amp;quot;IPAddress&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;IPPrefixLen&amp;quot;: 0,
        &amp;quot;Gateway&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Bridge&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;PortMapping&amp;quot;: null
    },
    &amp;quot;SysInitPath&amp;quot;: &amp;quot;/usr/bin/docker&amp;quot;,
    &amp;quot;ResolvConfPath&amp;quot;: &amp;quot;/etc/resolv.conf&amp;quot;,
    &amp;quot;Volumes&amp;quot;: {},
    &amp;quot;VolumesRW&amp;quot;: {}
}]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;image-inspect:7906d5806871be907588a3a390328f7d&#34;&gt;Image inspect&lt;/h4&gt;

&lt;p&gt;Inspect an Image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker inspect bced7ad27b98
[{
    &amp;quot;id&amp;quot;: &amp;quot;bced7ad27b98ea990fae3a7479632419109c7a14412365af379a26393ca0492b&amp;quot;,
    &amp;quot;parent&amp;quot;: &amp;quot;c7fe644d47bc05b6990fafec2f4b61fa0c9f7b248af6e754cbcd9c9507af36b1&amp;quot;,
    &amp;quot;created&amp;quot;: &amp;quot;2013-06-28T16:45:01.056208611Z&amp;quot;,
    &amp;quot;container&amp;quot;: &amp;quot;2deff3a37f8b5e1ce6e23ce420be07609df3813429909e2cfe5426c46f0a9552&amp;quot;,
    &amp;quot;container_config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;2deff3a37f8b&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: false,
        &amp;quot;AttachStdout&amp;quot;: false,
        &amp;quot;AttachStderr&amp;quot;: false,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: false,
        &amp;quot;OpenStdin&amp;quot;: false,
        &amp;quot;StdinOnce&amp;quot;: false,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: [
            &amp;quot;/bin/sh&amp;quot;,
            &amp;quot;-c&amp;quot;,
            &amp;quot;apt-get install -y curl&amp;quot;
        ],
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;c7fe644d47bc&amp;quot;,
        &amp;quot;Volumes&amp;quot;: null,
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: null
    },
    &amp;quot;docker_version&amp;quot;: &amp;quot;0.4.6&amp;quot;,
    &amp;quot;author&amp;quot;: &amp;quot;Ken \&amp;quot;ken@example.com\&amp;quot;&amp;quot;,
    &amp;quot;config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: false,
        &amp;quot;AttachStdout&amp;quot;: false,
        &amp;quot;AttachStderr&amp;quot;: false,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: false,
        &amp;quot;OpenStdin&amp;quot;: false,
        &amp;quot;StdinOnce&amp;quot;: false,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: null,
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Volumes&amp;quot;: null,
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: null
    },
    &amp;quot;architecture&amp;quot;: &amp;quot;x86_64&amp;quot;,
    &amp;quot;Size&amp;quot;: 4096
}]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;multiple-image-inspect:7906d5806871be907588a3a390328f7d&#34;&gt;Multiple Image inspect&lt;/h4&gt;

&lt;p&gt;Inspect more then one image at a time:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$  docker inspect bced7ad27b98 e74096c5172b
[{
    &amp;quot;id&amp;quot;: &amp;quot;bced7ad27b98ea990fae3a7479632419109c7a14412365af379a26393ca0492b&amp;quot;,
    &amp;quot;parent&amp;quot;: &amp;quot;c7fe644d47bc05b6990fafec2f4b61fa0c9f7b248af6e754cbcd9c9507af36b1&amp;quot;,
    &amp;quot;created&amp;quot;: &amp;quot;2013-06-28T16:45:01.056208611Z&amp;quot;,
    &amp;quot;container&amp;quot;: &amp;quot;2deff3a37f8b5e1ce6e23ce420be07609df3813429909e2cfe5426c46f0a9552&amp;quot;,
    &amp;quot;container_config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;2deff3a37f8b&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: false,
        &amp;quot;AttachStdout&amp;quot;: false,
        &amp;quot;AttachStderr&amp;quot;: false,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: false,
        &amp;quot;OpenStdin&amp;quot;: false,
        &amp;quot;StdinOnce&amp;quot;: false,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: [
            &amp;quot;/bin/sh&amp;quot;,
            &amp;quot;-c&amp;quot;,
            &amp;quot;apt-get install -y curl&amp;quot;
        ],
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;c7fe644d47bc&amp;quot;,
        &amp;quot;Volumes&amp;quot;: null,
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: null
    },
    &amp;quot;docker_version&amp;quot;: &amp;quot;0.4.6&amp;quot;,
    &amp;quot;author&amp;quot;: &amp;quot;Ken \&amp;quot;ken@example.com\&amp;quot;&amp;quot;,
    &amp;quot;config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: false,
        &amp;quot;AttachStdout&amp;quot;: false,
        &amp;quot;AttachStderr&amp;quot;: false,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: false,
        &amp;quot;OpenStdin&amp;quot;: false,
        &amp;quot;StdinOnce&amp;quot;: false,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: null,
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Volumes&amp;quot;: null,
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: null
    },
    &amp;quot;architecture&amp;quot;: &amp;quot;x86_64&amp;quot;,
    &amp;quot;Size&amp;quot;: 4096
},{
    &amp;quot;id&amp;quot;: &amp;quot;e74096c5172b34732c9769db5f23805cf786dffe25f25da66ebf7c0fc30d0e0b&amp;quot;,
    &amp;quot;parent&amp;quot;: &amp;quot;e9aa60c60128cad1&amp;quot;,
    &amp;quot;created&amp;quot;: &amp;quot;2013-05-09T09:45:26.287021-07:00&amp;quot;,
    &amp;quot;container&amp;quot;: &amp;quot;73f9f76d46cc07b3a6aa4e96c85dbabbfc4d1345697f263d5cd1741b5b05d6f2&amp;quot;,
    &amp;quot;container_config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;73f9f76d46cc&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: false,
        &amp;quot;AttachStdout&amp;quot;: true,
        &amp;quot;AttachStderr&amp;quot;: true,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: false,
        &amp;quot;OpenStdin&amp;quot;: false,
        &amp;quot;StdinOnce&amp;quot;: false,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: [
            &amp;quot;ls&amp;quot;
        ],
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;busybox&amp;quot;,
        &amp;quot;Volumes&amp;quot;: {},
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: null
    },
    &amp;quot;docker_version&amp;quot;: &amp;quot;0.3.0&amp;quot;,
    &amp;quot;Size&amp;quot;: 16391
}]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;container-and-image-inspect:7906d5806871be907588a3a390328f7d&#34;&gt;Container and Image inspect&lt;/h4&gt;

&lt;p&gt;Inspect a container and an image at the same time:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker inspect bced7ad27b98 a5e78640ece4
[{
    &amp;quot;id&amp;quot;: &amp;quot;bced7ad27b98ea990fae3a7479632419109c7a14412365af379a26393ca0492b&amp;quot;,
    &amp;quot;parent&amp;quot;: &amp;quot;c7fe644d47bc05b6990fafec2f4b61fa0c9f7b248af6e754cbcd9c9507af36b1&amp;quot;,
    &amp;quot;created&amp;quot;: &amp;quot;2013-06-28T16:45:01.056208611Z&amp;quot;,
    &amp;quot;container&amp;quot;: &amp;quot;2deff3a37f8b5e1ce6e23ce420be07609df3813429909e2cfe5426c46f0a9552&amp;quot;,
    &amp;quot;container_config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;2deff3a37f8b&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: false,
        &amp;quot;AttachStdout&amp;quot;: false,
        &amp;quot;AttachStderr&amp;quot;: false,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: false,
        &amp;quot;OpenStdin&amp;quot;: false,
        &amp;quot;StdinOnce&amp;quot;: false,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: [
            &amp;quot;/bin/sh&amp;quot;,
            &amp;quot;-c&amp;quot;,
            &amp;quot;apt-get install -y curl&amp;quot;
        ],
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;c7fe644d47bc&amp;quot;,
        &amp;quot;Volumes&amp;quot;: null,
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: null
    },
    &amp;quot;docker_version&amp;quot;: &amp;quot;0.4.6&amp;quot;,
    &amp;quot;author&amp;quot;: &amp;quot;Ken \&amp;quot;ken@dotcloud.com\&amp;quot;&amp;quot;,
    &amp;quot;config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: false,
        &amp;quot;AttachStdout&amp;quot;: false,
        &amp;quot;AttachStderr&amp;quot;: false,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: false,
        &amp;quot;OpenStdin&amp;quot;: false,
        &amp;quot;StdinOnce&amp;quot;: false,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: null,
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Volumes&amp;quot;: null,
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: null
    },
    &amp;quot;architecture&amp;quot;: &amp;quot;x86_64&amp;quot;,
    &amp;quot;Size&amp;quot;: 4096
},{
    &amp;quot;ID&amp;quot;: &amp;quot;a5e78640ece4b64657b86780ebfeacf614c402cf3b30bb2226f9f8abd48a46ff&amp;quot;,
    &amp;quot;Created&amp;quot;: &amp;quot;2013-07-05T22:43:36.281232878Z&amp;quot;,
    &amp;quot;Path&amp;quot;: &amp;quot;sh&amp;quot;,
    &amp;quot;Args&amp;quot;: [],
    &amp;quot;Config&amp;quot;: {
        &amp;quot;Hostname&amp;quot;: &amp;quot;a5e78640ece4&amp;quot;,
        &amp;quot;User&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Memory&amp;quot;: 0,
        &amp;quot;MemorySwap&amp;quot;: 0,
        &amp;quot;CpuShares&amp;quot;: 0,
        &amp;quot;AttachStdin&amp;quot;: true,
        &amp;quot;AttachStdout&amp;quot;: true,
        &amp;quot;AttachStderr&amp;quot;: true,
        &amp;quot;PortSpecs&amp;quot;: null,
        &amp;quot;Tty&amp;quot;: true,
        &amp;quot;OpenStdin&amp;quot;: true,
        &amp;quot;StdinOnce&amp;quot;: true,
        &amp;quot;Env&amp;quot;: null,
        &amp;quot;Cmd&amp;quot;: [
            &amp;quot;sh&amp;quot;
        ],
        &amp;quot;Dns&amp;quot;: null,
        &amp;quot;Image&amp;quot;: &amp;quot;joffrey/busybox&amp;quot;,
        &amp;quot;Volumes&amp;quot;: {},
        &amp;quot;VolumesFrom&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Entrypoint&amp;quot;: []
    },
    &amp;quot;State&amp;quot;: {
        &amp;quot;Running&amp;quot;: false,
        &amp;quot;Pid&amp;quot;: 0,
        &amp;quot;ExitCode&amp;quot;: 0,
        &amp;quot;StartedAt&amp;quot;: &amp;quot;2013-07-05T22:43:36.286163881Z&amp;quot;,
        &amp;quot;Ghost&amp;quot;: false
    },
    &amp;quot;Image&amp;quot;: &amp;quot;e74096c5172b34732c9769db5f23805cf786dffe25f25da66ebf7c0fc30d0e0b&amp;quot;,
    &amp;quot;NetworkSettings&amp;quot;: {
        &amp;quot;IPAddress&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;IPPrefixLen&amp;quot;: 0,
        &amp;quot;Gateway&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;Bridge&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;PortMapping&amp;quot;: null
    },
    &amp;quot;SysInitPath&amp;quot;: &amp;quot;/usr/bin/docker&amp;quot;,
    &amp;quot;ResolvConfPath&amp;quot;: &amp;quot;/etc/resolv.conf&amp;quot;,
    &amp;quot;Volumes&amp;quot;: {},
    &amp;quot;VolumesRW&amp;quot;: {}
}]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kill:7906d5806871be907588a3a390328f7d&#34;&gt;kill&lt;/h2&gt;

&lt;p&gt;Kill a running container(s). If the container won&amp;rsquo;t stop, you can brute
force it with the kill command.&lt;/p&gt;

&lt;h3 id=&#34;parameters-10:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER: The container id for the container you want to kill, can
be one or a list separated by spaces.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-10:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker kill CONTAINER [CONTAINER...]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-9:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;kill-one-container:7906d5806871be907588a3a390328f7d&#34;&gt;Kill one container&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker kill a5e78640ece4
a5e78640ece4
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;kill-more-then-one-container:7906d5806871be907588a3a390328f7d&#34;&gt;Kill more then one container&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker kill a5e78640ece4 0775b219a48a
a5e78640ece4
0775b219a48a
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;login:7906d5806871be907588a3a390328f7d&#34;&gt;login&lt;/h2&gt;

&lt;p&gt;Register or Login to the docker registry server. If you have an account
it will log you in, and cache the credentials, if you don&amp;rsquo;t have an
account it will create one for you, and automatically log you in. You
can pass in the username, email and password as command line parameters
to easily script out the login process.&lt;/p&gt;

&lt;h3 id=&#34;parameters-11:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   e: email

&lt;ul&gt;
&lt;li&gt;p: password&lt;/li&gt;
&lt;li&gt;u: username&lt;/li&gt;
&lt;/ul&gt;&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-11:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker login [OPTIONS]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-10:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;login-with-prompts:7906d5806871be907588a3a390328f7d&#34;&gt;Login with prompts&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker login
Username (): myusername
Password:
Email (): myusername@example.com
Login Succeeded
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;login-with-parameters:7906d5806871be907588a3a390328f7d&#34;&gt;Login with parameters&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker login -u myusername -p mypassword -e myusername@example.com
Login Succeeded
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;logs-1:7906d5806871be907588a3a390328f7d&#34;&gt;logs&lt;/h2&gt;

&lt;p&gt;Fetch the logs of a container&lt;/p&gt;

&lt;h3 id=&#34;parameters-12:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER: The Container ID for the Container you want to get the
logs for.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-12:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker logs CONTAINER
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-11:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker logs a5e78640ece4
some logs from my container
some logs from my container
some logs from my container
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;port:7906d5806871be907588a3a390328f7d&#34;&gt;port&lt;/h2&gt;

&lt;p&gt;Lookup the public-facing port which is NAT-ed to PRIVATE_PORT&lt;/p&gt;

&lt;h3 id=&#34;parameters-13:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER: The Container ID for the container you want to find the
port for&lt;/li&gt;
&lt;li&gt;PRIVATE_PORT: The private port, you want to find the matching
Public port for&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-13:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker port CONTAINER PRIVATE_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-12:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker port 335c587d6ad1 6379
49153
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ps:7906d5806871be907588a3a390328f7d&#34;&gt;ps&lt;/h2&gt;

&lt;p&gt;List containers&lt;/p&gt;

&lt;h3 id=&#34;parameters-14:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   -a=false: Show all containers. Only running containers are
    shown by default.

&lt;ul&gt;
&lt;li&gt;-notrunc=false: Don&amp;rsquo;t truncate output&lt;/li&gt;
&lt;li&gt;-q=false: Only display numeric IDs&lt;/li&gt;
&lt;/ul&gt;&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-14:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker ps [OPTIONS]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-13:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;show-running-containers:7906d5806871be907588a3a390328f7d&#34;&gt;Show running containers&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps
ID                  IMAGE                    COMMAND                CREATED             STATUS              PORTS
335c587d6ad1        joffrey/busybox:latest   /bin/sh -c while tru   3 minutes ago       Up 3 minutes        49153-&amp;gt;6379
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;show-all-containers:7906d5806871be907588a3a390328f7d&#34;&gt;Show all containers&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps -a
ID                  IMAGE                    COMMAND                CREATED             STATUS              PORTS
335c587d6ad1        joffrey/busybox:latest   /bin/sh -c while tru   3 minutes ago       Up 3 minutes        49153-&amp;gt;6379
1347dbb9d32f        joffrey/busybox:latest   /bin/sh -c while tru   4 minutes ago       Exit 137
db2db67170ba        joffrey/busybox:latest   /bin/echo hi           5 minutes ago       Exit 0
a5e78640ece4        joffrey/busybox:latest   sh                     6 days ago          Exit 0
0775b219a48a        joffrey/busybox:latest   sh                     6 days ago          Exit 127
1668f16b3ef4        joffrey/busybox:latest   bash                   6 days ago          Exit 127
... trimed
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;show-all-containers-full-output:7906d5806871be907588a3a390328f7d&#34;&gt;show all containers full output&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps -a -notrunc
ID                                                                 IMAGE                    COMMAND                                                         CREATED             STATUS              PORTS
335c587d6ad121519e1489b837e80a5efb748669c86a8bdd485867759fb3c9a7   joffrey/busybox:latest   /bin/sh -c while true; do echo hello world; sleep 1; done   4 minutes ago       Up 4 minutes        49153-&amp;gt;6379
1347dbb9d32fcafe922a58e6b01c56d04d35fbd3f3226e3789c30310222eceee   joffrey/busybox:latest   /bin/sh -c while true; do echo hello world; sleep 1; done   5 minutes ago       Exit 137
db2db67170ba9e1df14cadcaa6f172ad743b387eea3a9c454001279649463cdb   joffrey/busybox:latest   /bin/echo hi                                                6 minutes ago       Exit 0
... Trimmed
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;show-only-container-ids:7906d5806871be907588a3a390328f7d&#34;&gt;show only container ids&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps -q -a
335c587d6ad1
1347dbb9d32f
db2db67170ba
a5e78640ece4
0775b219a48a
... trimmed
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pull:7906d5806871be907588a3a390328f7d&#34;&gt;pull&lt;/h2&gt;

&lt;p&gt;Pull an image or a repository from the docker registry server. By
default it will always pull down the latest version, but you can also
pull by tag.&lt;/p&gt;

&lt;h3 id=&#34;parameters-15:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;NAME: the name of the repository to pull from registry&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   -t: Tag, if you want to pull down a tagged version of
    the repository.&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-15:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull NAME
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-14:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;pull-library-repository:7906d5806871be907588a3a390328f7d&#34;&gt;Pull library repository&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull base
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;pull-user-repository:7906d5806871be907588a3a390328f7d&#34;&gt;Pull User repository&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull samalba/hipache
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;pull-repository-by-tag:7906d5806871be907588a3a390328f7d&#34;&gt;Pull repository by tag&lt;/h4&gt;

&lt;p&gt;replace latest with the tag name you want to pull. :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull samalba/hipache:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or use the command line flag -t&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull -t latest samalba/hipache
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;push:7906d5806871be907588a3a390328f7d&#34;&gt;push&lt;/h2&gt;

&lt;p&gt;Push an image or a repository to the docker registry server&lt;/p&gt;

&lt;h3 id=&#34;parameters-16:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;NAME: the name of the repository to push to the registry&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-16:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker push NAME
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-15:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker push kencochrane/testrepo
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;restart:7906d5806871be907588a3a390328f7d&#34;&gt;restart&lt;/h2&gt;

&lt;p&gt;Restart one or more running containers&lt;/p&gt;

&lt;h3 id=&#34;parameters-17:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER: The Container ID for the container you want to restart&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   t: Number of seconds to try to stop for before killing
    the container. Once killed it will then be restarted&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-17:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker restart [OPTIONS] CONTAINER [CONTAINER ...]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-16:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;restart-container:7906d5806871be907588a3a390328f7d&#34;&gt;restart container&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker restart 335c587d6ad1
335c587d6ad1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;restart-multiple-containers:7906d5806871be907588a3a390328f7d&#34;&gt;restart multiple containers&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker restart 335c587d6ad1 1347dbb9d32f
335c587d6ad1
1347dbb9d32f
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;restart-container-with-15-second-timeout:7906d5806871be907588a3a390328f7d&#34;&gt;restart container with 15 second timeout&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker restart -t 15 335c587d6ad1
335c587d6ad1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;rm:7906d5806871be907588a3a390328f7d&#34;&gt;rm&lt;/h2&gt;

&lt;p&gt;Remove a container&lt;/p&gt;

&lt;h3 id=&#34;parameters-18:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER: The Container ID for the container you want to remove&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   v: Remove the volumes associated to the container&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-18:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker rm [OPTIONS] CONTAINER
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-17:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;remove-container:7906d5806871be907588a3a390328f7d&#34;&gt;Remove container&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker rm 335c587d6ad1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;remove-container-and-volume:7906d5806871be907588a3a390328f7d&#34;&gt;Remove container and volume&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker rm -v 335c587d6ad1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;rmi:7906d5806871be907588a3a390328f7d&#34;&gt;rmi&lt;/h2&gt;

&lt;p&gt;Remove one or more images&lt;/p&gt;

&lt;h3 id=&#34;parameters-19:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;IMAGE: The ID for the image you want to remove&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-19:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker rmi IMAGE [IMAGE...]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-18:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;remove-one-image:7906d5806871be907588a3a390328f7d&#34;&gt;Remove one image&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker rmi bced7ad27b98
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;remove-more-then-one-image:7906d5806871be907588a3a390328f7d&#34;&gt;Remove more then one image&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker rmi bced7ad27b98 e74096c5172b
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;run:7906d5806871be907588a3a390328f7d&#34;&gt;run&lt;/h2&gt;

&lt;p&gt;Run a command in a new container&lt;/p&gt;

&lt;h3 id=&#34;parameters-20:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;p&gt;IMAGE: The name of the image you want to create a container from
OPTIONS:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;a=map[]: Attach to stdin, stdout or stderr.&lt;/li&gt;
&lt;li&gt;c=0: CPU shares (relative weight)&lt;/li&gt;
&lt;li&gt;d=false: Detached mode: leave the container running in the
background&lt;/li&gt;
&lt;li&gt;e=[]: Set environment variables&lt;/li&gt;
&lt;li&gt;h=&amp;ldquo;&amp;rdquo;: Container host name&lt;/li&gt;
&lt;li&gt;i=false: Keep stdin open even if not attached&lt;/li&gt;
&lt;li&gt;m=0: Memory limit (in bytes)&lt;/li&gt;
&lt;li&gt;p=[]: Map a network port to the container&lt;/li&gt;
&lt;li&gt;t=false: Allocate a pseudo-tty&lt;/li&gt;
&lt;li&gt;u=&amp;ldquo;&amp;rdquo;: Username or UID&lt;/li&gt;
&lt;li&gt;d=[]: Set custom dns servers for the container&lt;/li&gt;
&lt;li&gt;v=[]: Creates a new volume and mounts it at the specified path.&lt;/li&gt;
&lt;li&gt;volumes-from=&amp;ldquo;&amp;rdquo;: Mount all volumes from the given container.&lt;/li&gt;
&lt;li&gt;b=[]: Create a bind mount with:
[host-dir]:[container-dir]:[rw|ro]&lt;/li&gt;
&lt;li&gt;entrypoint=&amp;ldquo;&amp;rdquo;: Overwrite the default entrypoint set by the image.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;usage-20:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker run [OPTIONS] IMAGE [COMMAND] [ARG...]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-19:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;run-container-in-foreground:7906d5806871be907588a3a390328f7d&#34;&gt;Run container in foreground&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h4 id=&#34;run-container-in-background:7906d5806871be907588a3a390328f7d&#34;&gt;Run container in background&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h4 id=&#34;start-container-with-memory-limit:7906d5806871be907588a3a390328f7d&#34;&gt;Start container with memory limit&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h4 id=&#34;limit-containers-cpu-shares:7906d5806871be907588a3a390328f7d&#34;&gt;Limit containers CPU shares&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h4 id=&#34;set-container-environment-variables:7906d5806871be907588a3a390328f7d&#34;&gt;Set container environment variables&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h4 id=&#34;attach-a-volume-to-a-container:7906d5806871be907588a3a390328f7d&#34;&gt;Attach a Volume to a container&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h4 id=&#34;set-custom-dbs-server-for-the-container:7906d5806871be907588a3a390328f7d&#34;&gt;Set custom DBS server for the container&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h4 id=&#34;create-bind-mount-for-container:7906d5806871be907588a3a390328f7d&#34;&gt;Create bind mount for container&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h4 id=&#34;override-the-default-entrypoint-set-by-image:7906d5806871be907588a3a390328f7d&#34;&gt;Override the default entrypoint set by image&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h2 id=&#34;search-1:7906d5806871be907588a3a390328f7d&#34;&gt;search&lt;/h2&gt;

&lt;p&gt;Search for an image in the docker index&lt;/p&gt;

&lt;h3 id=&#34;parameters-21:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;TERM: Search term&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   notrunc&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-21:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker search [OPTIONS] TERM
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-20:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;normal-search:7906d5806871be907588a3a390328f7d&#34;&gt;Normal search&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker search base
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;show-full-results:7906d5806871be907588a3a390328f7d&#34;&gt;Show full results&lt;/h4&gt;

&lt;p&gt;This will not truncate the description field for the search results :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker search -notrunc base
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;start:7906d5806871be907588a3a390328f7d&#34;&gt;start&lt;/h2&gt;

&lt;p&gt;Start one or more stopped containers&lt;/p&gt;

&lt;h3 id=&#34;parameters-22:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER: The container ID for the container you want to start&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-22:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker start CONTAINER [CONTAINER...]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-21:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;start-one-container:7906d5806871be907588a3a390328f7d&#34;&gt;Start one container&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker start 335c587d6ad1
335c587d6ad1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;start-two-containers:7906d5806871be907588a3a390328f7d&#34;&gt;Start two containers&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker start 335c587d6ad1 1347dbb9d32f
335c587d6ad1
1347dbb9d32f
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;stop:7906d5806871be907588a3a390328f7d&#34;&gt;stop&lt;/h2&gt;

&lt;p&gt;Stop a running container&lt;/p&gt;

&lt;h3 id=&#34;parameters-23:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER: The container ID for the container you want to stop&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   t=10: Number of seconds to try to stop for before killing
    the container.&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-23:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker stop [OPTIONS] CONTAINER [CONTAINER...]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-22:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;stop-one-container:7906d5806871be907588a3a390328f7d&#34;&gt;Stop one container&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker stop 335c587d6ad1
335c587d6ad1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;stop-two-containers:7906d5806871be907588a3a390328f7d&#34;&gt;Stop two containers&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker stop 335c587d6ad1 1347dbb9d32f
335c587d6ad1
1347dbb9d32f
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;stop-container-with-15-second-timeout:7906d5806871be907588a3a390328f7d&#34;&gt;Stop container with 15 second timeout&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker stop -t 15 335c587d6ad1
335c587d6ad1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tag:7906d5806871be907588a3a390328f7d&#34;&gt;tag&lt;/h2&gt;

&lt;p&gt;Tag an image into a repository&lt;/p&gt;

&lt;h3 id=&#34;parameters-24:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;IMAGE: The image to tag&lt;/li&gt;
&lt;li&gt;REPOSITORY: The repository name in the registry&lt;/li&gt;
&lt;li&gt;TAG: The tag name&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OPTIONS:&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;-   f=false: Force&lt;/dd&gt;
&lt;/dl&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-24:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker tag [OPTIONS] IMAGE REPOSITORY [TAG]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-23:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;tag-an-image:7906d5806871be907588a3a390328f7d&#34;&gt;Tag an image&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h4 id=&#34;tag-an-image-without-specifying-a-tag:7906d5806871be907588a3a390328f7d&#34;&gt;Tag an image, without specifying a Tag&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h4 id=&#34;force-setting-a-tag:7906d5806871be907588a3a390328f7d&#34;&gt;Force setting a Tag&lt;/h4&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;h2 id=&#34;version:7906d5806871be907588a3a390328f7d&#34;&gt;version&lt;/h2&gt;

&lt;p&gt;Show the docker version information&lt;/p&gt;

&lt;h3 id=&#34;parameters-25:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;p&gt;None&lt;/p&gt;

&lt;h3 id=&#34;usage-25:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker version
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-24:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker version
Client version: 0.5.0
Server version: 0.5.0
Go version: go1.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wait:7906d5806871be907588a3a390328f7d&#34;&gt;wait&lt;/h2&gt;

&lt;p&gt;Block until a container stops, then print its exit code&lt;/p&gt;

&lt;h3 id=&#34;parameters-26:7906d5806871be907588a3a390328f7d&#34;&gt;Parameters&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CONTAINER: The container ID for the container you want to wait for&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;usage-26:7906d5806871be907588a3a390328f7d&#34;&gt;Usage&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker wait CONTAINER
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples-25:7906d5806871be907588a3a390328f7d&#34;&gt;Examples&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker wait 335c587d6ad1
0
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Running Docker on Digital Ocean with Ubuntu</title>
      <link>http://www.kencochrane.net/blog/2013/06/running-docker-on-digital-ocean/</link>
      <pubDate>Fri, 07 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2013/06/running-docker-on-digital-ocean/</guid>
      <description>

&lt;p&gt;I recently wrote a post on how to get &lt;a href=&#34;http://www.docker.com&#34;&gt;Docker&lt;/a&gt; up
and &lt;a href=&#34;http://kencochrane.net/blog/2013/05/running-docker-on-rackspace-cloud/&#34;&gt;running on
Rackspace&lt;/a&gt;
and since then I have received some requests on how to get it up and
running on other hosts. One of those hosts is &lt;a href=&#34;https://www.digitalocean.com/?refcode=3313a09727d4&#34;&gt;Digital
Ocean&lt;/a&gt; a hot new
Cloud hosting provider that offers a 512MB 20GB SSD VPS for only \$5.00
/ month. A really great deal, and also a great price if you want to play
around with some new tool and not have to worry about possibly breaking
a production server. This post should guide you though the process of
getting an Ubuntu 12.04 and 13.04 VPS up and running with Docker.&lt;/p&gt;

&lt;h1 id=&#34;step-1-register:f6acbe7546ab0bafe3ff3295f5ba358a&#34;&gt;Step 1: Register&lt;/h1&gt;

&lt;p&gt;First things first, if you don&amp;rsquo;t already have a Digital Ocean account,
you will need to create one. If you &lt;a href=&#34;https://www.digitalocean.com/?refcode=3313a09727d4&#34;&gt;follow this
link&lt;/a&gt;, click sign up
and enter this promo code &lt;strong&gt;VPSERS10&lt;/strong&gt;, you will be given a $10 credit
to try out the service.&lt;/p&gt;

&lt;h1 id=&#34;step-2-billing:f6acbe7546ab0bafe3ff3295f5ba358a&#34;&gt;Step 2: Billing&lt;/h1&gt;

&lt;p&gt;To prevent abuse, Digital Ocean requires that you enter a credit card
before you can spin up a server. Go ahead and do that now. Once you put
in your information you should see a screen like this.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/digital-ocean/startup.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;h1 id=&#34;step-3-ssh-keys:f6acbe7546ab0bafe3ff3295f5ba358a&#34;&gt;Step 3 SSH keys&lt;/h1&gt;

&lt;p&gt;To make your life easier, I would add a public SSH key to your account.
If you don&amp;rsquo;t add an SSH key then you will be emailed a root password
when the server is setup. It is easier and more secure to add your
public key, and then select that key when building the server, and they
will automatically add the key to your server for you. If you don&amp;rsquo;t have
a SSH key, don&amp;rsquo;t worry they are easy to create. Just do a quick web
search, and there are a ton of different guide out there to help you get
one setup.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/digital-ocean/ssh_key.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;h1 id=&#34;step-4-create-droplet:f6acbe7546ab0bafe3ff3295f5ba358a&#34;&gt;Step 4: Create Droplet&lt;/h1&gt;

&lt;p&gt;Digital Ocean calls their servers Droplets. Lets create a droplet. Click
on the big &amp;ldquo;Create&amp;rdquo; button on the control panel.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Enter a hostname at the top.&lt;/li&gt;
&lt;li&gt;Pick your size&lt;/li&gt;
&lt;li&gt;select your region&lt;/li&gt;
&lt;li&gt;Select your image. Docker currently only runs on a &lt;strong&gt;64bit OS&lt;/strong&gt;, and
needs a fairly recent kernel (3.8+) with AUFS enabled. The only
images on Digital Ocean that will currently work with Docker are
&lt;strong&gt;Ubuntu 13.04 x64 Server&lt;/strong&gt;, and &lt;strong&gt;Ubuntu 12.04 x64 Server&lt;/strong&gt;. I&amp;rsquo;ll
cover the install instructions for those two options below.&lt;/li&gt;
&lt;li&gt;Pick your SSH key that you added previously. If you don&amp;rsquo;t pick one,
your root password will be emailed to you.&lt;/li&gt;
&lt;li&gt;Enable VirtIO&lt;/li&gt;
&lt;li&gt;Click the big &amp;ldquo;Create Droplet&amp;rdquo; button at the bottom.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/digital-ocean/select_distro_ubuntu_12_04.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;p&gt;Droplet getting created&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/digital-ocean/create_droplet.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;p&gt;After about 60 seconds you should have a cloudlet created with an IP
address. Now pick the distribution you picked below and follow the rest
of the directions.&lt;/p&gt;

&lt;h1 id=&#34;ubuntu-12-04-64bit-server:f6acbe7546ab0bafe3ff3295f5ba358a&#34;&gt;Ubuntu 12.04 64bit Server&lt;/h1&gt;

&lt;h2 id=&#34;upgrade-kernel:f6acbe7546ab0bafe3ff3295f5ba358a&#34;&gt;Upgrade kernel&lt;/h2&gt;

&lt;p&gt;The default kernel with 12.04 doesn&amp;rsquo;t work well with Docker so we are
going to upgrade to the same one that is used by 13.04. To do this you
will go into your control panel for your droplet, and go into the
settings tab and change the kernel pull down to &amp;ldquo;Ubuntu
13.04-x64-vmlinuz-3.8.0-23-generic&amp;rdquo; and click change.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/digital-ocean/change_kernel.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;p&gt;In order for the kernel change to take affect you will need to power
cycle the droplet. Click on the power tab, and then hit the &amp;ldquo;Power
Cycle&amp;rdquo; button.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/digital-ocean/power_cycle.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;h2 id=&#34;login-to-server:f6acbe7546ab0bafe3ff3295f5ba358a&#34;&gt;Login to server&lt;/h2&gt;

&lt;p&gt;Now that you have the new kernel you need to login to the server to
install the rest of the stuff.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ ssh root@&amp;lt;your_ip_address&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s check to make sure you have the right kernel. It should show a 3.8
kernel if you did everything right.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ uname -a
Linux docker-1 3.8.0-23-generic #34-Ubuntu SMP Wed May 29 20:22:58 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s install some dependencies now.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install linux-image-generic-lts-raring
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you see this, just pick the default (already selected) and hit OK.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/digital-ocean/kernel_menu.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;p&gt;Install Docker from the Docker PPA&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ sudo apt-get install python-software-properties &amp;amp;&amp;amp; sudo add-apt-repository ppa:dotcloud/lxc-docker
$ sudo apt-get update
$ sudo apt-get install lxc-docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Docker should have been installed and started up. lets test to make sure
it works.&lt;/p&gt;

&lt;p&gt;``` {.sourceCode .bash
 $ docker ps
 ID                  IMAGE               COMMAND             CREATED             STATUS              PORTS}
$ docker version
Client version: 0.4.0
Server version: 0.4.0
Go version: go1.0.3&lt;/p&gt;

&lt;p&gt;$ docker run base /bin/echo hello world
hello world&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
Hopefully it worked. If not, feel free to ask questions on \#docker on
freenode, or [submit a support
ticket](https://github.com/docker/docker/issues?labels=doc&amp;amp;state=open).

Ubuntu 13.04 64bit Server
=========================

13.04 comes with the 3.8 kernel, so we won&#39;t need to do anything kernel
related, which makes this install much simpler compared to 12.04.

Install the dependencies

``` {.sourceCode .bash}
$ sudo apt-get update
$ sudo apt-get install linux-image-extra-`uname -r`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you see this, just pick the default (already selected) and hit OK.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/digital-ocean/kernel_menu.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;p&gt;Install Docker&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ sudo apt-get install software-properties-common
$ sudo add-apt-repository ppa:dotcloud/lxc-docker
$ sudo apt-get update
$ sudo apt-get install lxc-docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Docker should have been installed and started up. lets test to make sure
it works.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ docker ps
ID                  IMAGE               COMMAND             CREATED             STATUS              PORTS

$ docker version
Client version: 0.4.0
Server version: 0.4.0
Go version: go1.0.3

$ docker run base /bin/echo hello world
hello world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hopefully it worked. If not, feel free to ask questions on #docker on
freenode, or &lt;a href=&#34;https://github.com/docker/docker/issues?labels=doc&amp;amp;state=open&#34;&gt;submit a support
ticket&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;conclusion:f6acbe7546ab0bafe3ff3295f5ba358a&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Hopefully now you have the knowledge to go and setup your own Docker
server on Digital Ocean. If you have any issues, or questions feel free
to submit the questions below or visit #docker on freenode&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting Docker up and running on a RaspberryPi</title>
      <link>http://www.kencochrane.net/blog/2013/05/running-docker-on-a-raspberrypi/</link>
      <pubDate>Fri, 17 May 2013 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2013/05/running-docker-on-a-raspberrypi/</guid>
      <description>

&lt;p&gt;This year I attended &lt;a href=&#34;https://us.pycon.org/2013/&#34;&gt;PyCon US&lt;/a&gt; and I was
lucky enough to get a FREE &lt;a href=&#34;http://www.raspberrypi.org&#34;&gt;RaspberryPi&lt;/a&gt;. At
the same conference &lt;a href=&#34;http://www.dotcloud.com&#34;&gt;dotCloud&lt;/a&gt; (The company I
work for), was giving a lightning talk for a project that we have been
working on, called Docker. &lt;a href=&#34;http://www.docker.io&#34;&gt;Docker&lt;/a&gt; is a tool that
allows you to better manage your Linux Containers
(&lt;a href=&#34;http://lxc.sourceforge.net&#34;&gt;LXC&lt;/a&gt;). Shortly after I got the
RaspberryPi, I started wondering if it would be possible to run Docker
on it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/rpi/RaspberryPi.jpg&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;p&gt;I did some digging and technically speaking the Pi should be able to run
Docker, it satisfies all of the requirements.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Linux&lt;/li&gt;
&lt;li&gt;LXC&lt;/li&gt;
&lt;li&gt;AUFS&lt;/li&gt;
&lt;li&gt;Go&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Getting it up and running isn&amp;rsquo;t going to be easy. The Linux kernels that
come with the different Linux distros for the RaspberryPi, are kind of
old, and don&amp;rsquo;t come with AUFS built in. The RaspberryPi also runs on an
ARM based chip, and it is only 32bit. Currently Docker only supports
64bit OS&amp;rsquo;s. There are plans to add 32 bit support in the future, but it
isn&amp;rsquo;t there yet.&lt;/p&gt;

&lt;p&gt;Doing some research I was able to find blog posts on how to get LXC and
AUFS up and running on the RaspberryPi. Using those guides, I was able
to make some progress but I&amp;rsquo;m not all of the way there yet. I&amp;rsquo;m hoping
to describe my steps here so that others can see what I have done, and
if they want, help me get over the hump.&lt;/p&gt;

&lt;h1 id=&#34;goals:f1d498c06f1cd77c93351132c9d7bc1e&#34;&gt;Goals&lt;/h1&gt;

&lt;p&gt;My goals for the project is to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;provide a prebuilt image that people can download that has
everything they needed in order to get started.&lt;/li&gt;
&lt;li&gt;I also want to provide a prebuilt kernel, people can download and
use without having to build their own.&lt;/li&gt;
&lt;li&gt;Port Docker to 32bit so that it will run on RaspberryPi and provide
a Debian package for easy install.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;instructions:f1d498c06f1cd77c93351132c9d7bc1e&#34;&gt;Instructions&lt;/h1&gt;

&lt;p&gt;Here are the steps that I used to make it so that my RaspberryPi could
run Docker. These are still a work in progress, so please let me know if
you have any issues, or you found a better way to do this.&lt;/p&gt;

&lt;h2 id=&#34;install-linux-os:f1d498c06f1cd77c93351132c9d7bc1e&#34;&gt;Install Linux OS&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Download &lt;a href=&#34;http://www.raspberrypi.org/downloads&#34;&gt;Raspbian&lt;/a&gt; and &lt;a href=&#34;http://elinux.org/RPi_Easy_SD_Card_Setup&#34;&gt;make
an SD card&lt;/a&gt; (I used the
2013-02-09-wheezy-raspbian.zip image)&lt;/li&gt;
&lt;li&gt;Once you have the SD card, put it in the Pi and boot it up.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;update-and-prepare-raspbian:f1d498c06f1cd77c93351132c9d7bc1e&#34;&gt;Update and Prepare Raspbian&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Switch to Root User on the Pi. These commands must be run as root.
You can also use &amp;ldquo;su&amp;rdquo; or &amp;ldquo;sudo&amp;rdquo;, what ever you prefer:&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ sudo su root
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Expand to fill SD card and reboot after entering:&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ raspi-config
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Update Raspbian&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ apt-get update

$ apt-get dist-upgrade
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Install git&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ sudo apt-get install git-core
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Update Firmware&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The clone will take a while. You might consider cloning on a desktop
machine to save time. Just transfer the firmware/boot and modules/
directories from your desktop PC to the Pi after the checkout. Be aware
that checking out on some OS&amp;rsquo;s that are case insensitive, may result in
some files being missing. If you see funky issues, this might be the
cause.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ cd /opt

$ git clone git://github.com/raspberrypi/firmware.git

$ cd firmware/boot

$ cp * /boot

$ cd ../modules

$ cp -r * /lib/modules

$ reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Increase the Swap File Size&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I found that in order to check out the source on the Pi, youll need a
swap file with the 256MB Pi, otherwise it will run out of RAM during the
checkout (with fatal: index-pack failed).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# use your favorite editor here.
$ pico /etc/dphys-swapfile

# change to 500 (MB)

$ sudo dphys-swapfile setup

$ sudo reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Prepare to Build Kernel&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We are going to use the 3.6 kernel since it is the lastest stable one.
There is an effort to get &lt;a href=&#34;http://www.raspberrypi.org/phpBB3/viewtopic.php?f=87&amp;amp;t=40664&#34;&gt;3.8
working&lt;/a&gt;,
it isn&amp;rsquo;t 100% there yet, for more info see.&lt;/p&gt;

&lt;p&gt;The clone will take a while. Again, you may consider using a desktop PC.
Of course, if you do that, youll need to issue the zcat command from
your Pi and copy the resulting .config file to the linux directory
on your desktop PC.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ cd /opt

$ mkdir raspberrypi

$ cd raspberrypi

$ git clone git://github.com/raspberrypi/linux.git

$ cd linux

$ zcat /proc/config.gz &amp;gt; .config
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Decrease the Swap Space File&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ pico /etc/dphys-swapfile

# change to 100 (MB)

$ sudo dphys-swapfile setup

$ sudo reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Install Packages for Kernel Compilation&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ apt-get install ncurses-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Adding AUFS Patches&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ cd /opt/raspberrypi/linux

git clone git://aufs.git.sourceforge.net/gitroot/aufs/aufs3-standalone.git
cd aufs3-standalone
git checkout origin/aufs3.6
cp -rp *.patch ../
cp -rp fs ../
cp -rp Documentation/ ../
cp -rp include/ ../
cd ..

patch -p1 &amp;lt; aufs3-base.patch
patch -p1 &amp;lt; aufs3-proc_map.patch
patch -p1 &amp;lt; aufs3-standalone.patch
patch -p1 &amp;lt; aufs3-kbuild.patch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you get this error&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;root@raspberrypi:/opt/raspberrypi/linux# patch -p1 &amp;lt; aufs3-kbuild.patch
patching file fs/Kconfig
patching file fs/Makefile
patching file include/linux/Kbuild
Hunk #1 FAILED at 66.
1 out of 1 hunk FAILED -- saving rejects to file include/linux/Kbuild.rej
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then you will need to manually update include/linux/Kbuild because the
patch failed.&lt;/p&gt;

&lt;p&gt;First I reverted change on the file, and manually added. the line
(below) to line 66, below audit.h&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;header-y += aufs_type.h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;here is my git diff:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;diff --git a/include/linux/Kbuild b/include/linux/Kbuild
index fa21760..ee029e3 100644
--- a/include/linux/Kbuild
+++ b/include/linux/Kbuild
@@ -66,6 +66,7 @@ header-y += atmppp.h
 header-y += atmsap.h
 header-y += atmsvc.h
 header-y += audit.h
+header-y += aufs_type.h
 header-y += auto_fs.h
 header-y += auto_fs4.h
 header-y += auxvec.h
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Configuring Kernel&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Youll now need to set some kernel options to support LXC, via the menu
config tool.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ cd /opt/raspberrypi/linx

$ make menuconfig
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You need to enable these options:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;General -&amp;gt; Control Group Support -&amp;gt; Memory Resource Controller
for Control Groups (&lt;em&gt;and its three child options&lt;/em&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/rpi/raspberrypi_kernel_config_1.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;p&gt;(this has high overhead;only enable if you really need it, or else
enable and remember to disable using the Kernel command line option
cgroup_disable=memory) (image not shown)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;General -&amp;gt; Control Group Support -&amp;gt; cpuset support&lt;/li&gt;
&lt;li&gt;Device Drivers -&amp;gt; Character Devices -&amp;gt; Support multiple
instances of devpts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/rpi/raspberrypi_kernel_config_2.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Device Drivers -&amp;gt; Network Device Support -&amp;gt; Virtual ethernet
pair device&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/rpi/raspberrypi_kernel_config_3.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;File Systems &amp;ndash;&amp;gt; Miscellaneous filesystems -&amp;gt;select &amp;ldquo;Aufs
(Advanced multi layered unification filesystem) support (NEW)&amp;rdquo; (mine
was the the very bottom)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://www.kencochrane.net/rpi/docker_rasberrypi_aufs_kernel_config.png&#34; alt=&#34;image&#34; /&gt;{.img-polaroid}&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Build Kernel&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This could take many hours if you compile on the Pi, there are ways to
&lt;a href=&#34;http://elinux.org/RPi_Kernel_Compilation#2._Cross_compiling_from_Linux&#34;&gt;compile on another
machine&lt;/a&gt;
and transfer the kernel to the Pi when completed. If you are in a hurry,
use this approach.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ make

$ make modules_install

$ cd /opt/raspberrypi

$ git clone git://github.com/raspberrypi/tools.git

$ cd tools/mkimage

$ python ./imagetool-uncompressed.py /opt/raspberrypi/linux/arch/arm/boot/Image

$ cp /boot/kernel.img /boot/kernel-old.img

$ cp kernel.img /boot/

$ reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Download Latest LXC&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The LXC tools provided with Raspbian are out-of-date, so let&amp;rsquo;s update to
the latest version.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ mkdir /opt/lxc

$ cd /opt/lxc

$ git clone https://github.com/lxc/lxc.git

$ apt-get install automake libcap-dev

$ cd lxc

$ ./autogen.sh &amp;amp;&amp;amp; ./configure &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Testing the Install&lt;/p&gt;

&lt;p&gt;Check LXC is happy with your kernel:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ lxc-checkconfig
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;User namespace should be missing (it checks for a kernel option that
no longer exists) and Cgroup namespace should say required.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Installing Go&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you install Go using the Go package that is available (apt-get
install golang). You will get a floating point issue. For more
information about the floating point issues see this page.
&lt;a href=&#34;http://www.raspberrypi.org/phpBB3/viewtopic.php?p=129647&#34;&gt;http://www.raspberrypi.org/phpBB3/viewtopic.php?p=129647&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To get it to work, we will compile Go from source. Feel free to change
the location on where we are installing it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ sudo apt-get install -y mercurial gcc libc6-dev

$ hg clone -u default https://code.google.com/p/go $HOME/go
warning: code.google.com certificate with fingerprint 9f:af:b9:ce:b5:10:97:c0:5d:16:90:11:63:78:fa:2f:37:f4:96:79 not verified (check hostfingerprints or web.cacerts config setting)
destination directory: go
requesting all changes
adding changesets
adding manifests
adding file changes
added 14430 changesets with 52478 changes to 7406 files (+5 heads)
updating to branch default
3520 files updated, 0 files merged, 0 files removed, 0 files unresolved

$ cd $HOME/go/src
$ ./all.bash

ALL TESTS PASSED

---
Installed Go for linux/arm in /home/dfc/go
Installed commands in /home/dfc/go/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If there was an error relating to out of memory, or you couldnt
configure an appropriate swap device, you can skip the test suite by
executing&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ cd $HOME/go
$ ./make.bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;as an alternative to ./all.bash.&lt;/p&gt;

&lt;p&gt;The go command needs to be added to your \$PATH, you should also edit
your profile script (.bashrc, etc) to include these changes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ export PATH=$PATH:$HOME/go/bin
$ go version
go version devel +30c566874b83 Wed May 08 16:06:25 2013 -0700 linux/arm
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Installing Docker&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ apt-get -y install wget bsdtar curl git

export GOPATH=~/docker/go/
export PATH=$GOPATH/bin:$PATH

$ mkdir -p $GOPATH/src/github.com/dotcloud
$ cd $GOPATH/src/github.com/dotcloud
$ git clone git://github.com/dotcloud/docker.git  # or clone your own fork/branch
$ cd docker

$ go get -v github.com/dotcloud/docker/...
$ go install -v github.com/dotcloud/docker/...

$ docker version
$ docker -d
The docker runtime currently only supports amd64 (not arm). This will change in the future. Aborting.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Docker is installed but due to current limitations it won&amp;rsquo;t run. It is a
start, we now have a development environment to start hacking on Docker
to get it to work with the RaspberryPi.&lt;/p&gt;

&lt;h1 id=&#34;what-s-next:f1d498c06f1cd77c93351132c9d7bc1e&#34;&gt;What&amp;rsquo;s Next&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Now we have everything up and running, we need to change docker so
that it will work on the ARM with only 32bit support.&lt;/li&gt;
&lt;li&gt;I need to take my compiled kernel and make it downloadable to others&lt;/li&gt;
&lt;li&gt;I need to make an SD card image of my setup for easy download, so
that people can get started easier.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;want-to-help:f1d498c06f1cd77c93351132c9d7bc1e&#34;&gt;Want to Help?&lt;/h1&gt;

&lt;p&gt;If you want to help me with this, please send me a message on twitter
&lt;a href=&#34;https://twitter.com/kencochrane&#34;&gt;@KenCochrane&lt;/a&gt; and also add your name
to this &lt;a href=&#34;https://github.com/dotcloud/docker/issues/636&#34;&gt;Docker issue&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;resources:f1d498c06f1cd77c93351132c9d7bc1e&#34;&gt;Resources:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;LXC:
&lt;a href=&#34;http://raspberrypicloud.wordpress.com/2013/03/12/building-an-lxc-friendly-kernel-for-the-raspberry-pi/&#34;&gt;http://raspberrypicloud.wordpress.com/2013/03/12/building-an-lxc-friendly-kernel-for-the-raspberry-pi/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;AUFS: &lt;a href=&#34;http://rpitc.blogspot.sg/p/kernel-rebuild.html&#34;&gt;http://rpitc.blogspot.sg/p/kernel-rebuild.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Go: &lt;a href=&#34;http://dave.cheney.net/tag/go-golang-raspberrypi&#34;&gt;http://dave.cheney.net/tag/go-golang-raspberrypi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Docker:
&lt;a href=&#34;http://docs.docker.io/en/latest/contributing/devenvironment.html&#34;&gt;http://docs.docker.io/en/latest/contributing/devenvironment.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Upgrading the Ubuntu linux kernel on Rackspace cloud</title>
      <link>http://www.kencochrane.net/blog/2013/05/upgrading-linux-kernel-ubuntu-rackspace-cloud/</link>
      <pubDate>Sun, 12 May 2013 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2013/05/upgrading-linux-kernel-ubuntu-rackspace-cloud/</guid>
      <description>

&lt;p&gt;Yesterday I wrote a &lt;a href=&#34;%7Cfilename%7C/content/running-docker-on-rackspace-cloud.rst&#34;&gt;blog
post&lt;/a&gt; on
how to install &lt;a href=&#34;http://www.docker.com&#34;&gt;Docker&lt;/a&gt; on to &lt;a href=&#34;http://www.rackspace.com/cloud/servers/&#34;&gt;RackSpace
Cloud&lt;/a&gt;, and one of the steps
was to upgrade the kernel to the lastest one so that Docker would be
nice and stable. The problem that I found out was that there wasn&amp;rsquo;t much
information how to upgrade the kernel on the Rackspace Cloud servers, so
I thought I would put the steps here.&lt;/p&gt;

&lt;p&gt;The goal here is to upgrade Ubuntu 12.04 and 12.10 so that it has the
same kernel as 13.04. Here are the steps.&lt;/p&gt;

&lt;h1 id=&#34;ubuntu-12-04:9b026601a6e60c4436ae1781fc686565&#34;&gt;Ubuntu 12.04&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Build an Ubuntu 12.04 server using the &amp;ldquo;Next generation cloud
servers&amp;rdquo;, with your desired size. It will give you the password,
keep that you will need it later.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When the server is up and running ssh into the server.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ ssh root@&amp;lt;server-ip&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Once you are logged in you should check what kernel version you
are running.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ uname -a
Linux docker-12-04 3.2.0-38-virtual #61-Ubuntu SMP Tue Feb 19 12:37:47 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Let&amp;rsquo;s update the server package list&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ apt-get update
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Install the 3.8.x kernel using the PPA&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# install the new kernel
$ apt-get install linux-generic-lts-raring

# update grub so it will use the new kernel after we reboot
$ update-grub

# update-grub doesn&#39;t always work so lets make sure. ``/boot/grub/menu.lst`` was updated.
$ grep 3.8.0- /boot/grub/menu.lst

# nope it wasn&#39;t lets manually update ``/boot/grub/menu.lst``  (make sure you are searching for correct kernel version, look at initial uname -a results.)
$ sed -i s/3.2.0-38-virtual/3.8.0-19-generic/ /boot/grub/menu.lst

# once again lets make sure it worked.
$ grep 3.8.0- /boot/grub/menu.lst
title          Ubuntu 12.04.2 LTS, kernel 3.8.0-19-generic
kernel          /boot/vmlinuz-3.8.0-19-generic root=/dev/xvda1 ro quiet splash console=hvc0
initrd          /boot/initrd.img-3.8.0-19-generic
title          Ubuntu 12.04.2 LTS, kernel 3.8.0-19-generic (recovery mode)
kernel          /boot/vmlinuz-3.8.0-19-generic root=/dev/xvda1 ro quiet splash  single
initrd          /boot/initrd.img-3.8.0-19-generic

# much better.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reboot server (either via command line or console)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;login again and check to make sure the kernel was updated&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ ssh root@&amp;lt;server_ip&amp;gt;
$ uname -a
Linux docker-12-04 3.8.0-19-generic #30~precise1-Ubuntu SMP Wed May 1 22:26:36 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux

# nice 3.8.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;ubuntu-12-10:9b026601a6e60c4436ae1781fc686565&#34;&gt;Ubuntu 12.10&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Build an Ubuntu 12.10 server using the &amp;ldquo;Next generation cloud
servers&amp;rdquo;, with your desired size. It will give you the password,
keep that you will need it later.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When the server is up and running ssh into the server.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ ssh root@&amp;lt;server-ip&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Once you are logged in you should check what kernel version you
are running.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ uname -a
Linux docker-12-10 3.5.0-25-generic #39-Ubuntu SMP Mon Feb 25 18:26:58 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Let&amp;rsquo;s update the server package list&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ apt-get update
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Install the 3.8.x kernel using the ubuntu-x-swat PPA&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# add the ppa to get the right kernel package
$ echo deb http://ppa.launchpad.net/ubuntu-x-swat/q-lts-backport/ubuntu quantal main &amp;gt; /etc/apt/sources.list.d/xswat.list

# add the key for the ppa
$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 3B22AB97AF1CDFA9

# update packages again
$ apt-get update

# install the new kernel
$ apt-get install linux-image-3.8.0-19-generic

# make sure grub has been updated.
$ grep 3.8.0- /boot/grub/menu.lst
title   Ubuntu 12.10, kernel 3.8.0-19-generic
kernel  /boot/vmlinuz-3.8.0-19-generic root=/dev/xvda1 ro quiet splash console=hvc0
initrd  /boot/initrd.img-3.8.0-19-generic
title   Ubuntu 12.10, kernel 3.8.0-19-generic (recovery mode)
kernel  /boot/vmlinuz-3.8.0-19-generic root=/dev/xvda1 ro quiet splash  single
initrd  /boot/initrd.img-3.8.0-19-generic

# looks good. If it doesn&#39;t work for you, look at the notes for 12.04 to fix.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reboot server (either via command line or console)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;login again and check to make sure the kernel was updated&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ ssh root@&amp;lt;server_ip&amp;gt;
$ uname -a
Linux docker-12-10 3.8.0-19-generic #29~precise2-Ubuntu SMP Fri Apr 19 16:15:35 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux

# nice 3.8.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Running Docker on Rackspace with Ubuntu</title>
      <link>http://www.kencochrane.net/blog/2013/05/running-docker-on-rackspace-cloud/</link>
      <pubDate>Sat, 11 May 2013 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2013/05/running-docker-on-rackspace-cloud/</guid>
      <description>

&lt;p&gt;I have been playing with &lt;a href=&#34;http://www.docker.com&#34;&gt;Docker&lt;/a&gt; a lot lately,
and it got me wondering how hard it would be to run Docker on the
different Cloud providers. I noticed there were already directions on
how to install on &lt;a href=&#34;http://docs.docker.com/en/latest/installation/amazon.html&#34;&gt;Amazon
EC2&lt;/a&gt; but
nothing for the Rackspace Cloud.&lt;/p&gt;

&lt;p&gt;If you would like to run &lt;a href=&#34;http://www.docker.com&#34;&gt;Docker&lt;/a&gt; on the
&lt;a href=&#34;http://www.rackspace.com/cloud/servers/&#34;&gt;RackSpace Cloud&lt;/a&gt; using
&lt;a href=&#34;http://www.ubuntu.com/&#34;&gt;Ubuntu&lt;/a&gt; you&amp;rsquo;re in luck. I just spent the
afternoon figuring out how to get it installed on Ubuntu 12.04, 12.10,
and 13.04, and I have included my notes below. 13.04 is the easiest to
get up and running since it has the most recent kernel, but the others
aren&amp;rsquo;t too bad either, they just need a few more steps, to get them up
to par.&lt;/p&gt;

&lt;p&gt;I would love to expand this to other distros on Rackspace, so if you
come up with more, send me a note, and so I can link to them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update: 05-12-2013&lt;/strong&gt; I have updated some information given some
feedback by others. Also added a troubleshooting section.&lt;/p&gt;

&lt;h1 id=&#34;ubuntu-12-04:f2623c526ea98fcfa3c30f7d4e215bfa&#34;&gt;Ubuntu 12.04&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Build an Ubuntu 12.04 server using the &amp;ldquo;Next generation cloud
servers&amp;rdquo;, with your desired size. It will give you the password,
keep that you will need it later.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When the server is up and running ssh into the server.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ ssh root@&amp;lt;server-ip&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Once you are logged in you should check what kernel version you
are running.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ uname -a
Linux docker-12-04 3.2.0-38-virtual #61-Ubuntu SMP Tue Feb 19 12:37:47 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Let&amp;rsquo;s update the server package list&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ apt-get update
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Now lets install Docker and it&amp;rsquo;s dependencies. To keep things
simple, we will use the Docker install script. It will take a couple
of minutes. (see below if you want to install via package)&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ curl get.docker.io | sudo sh -x
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Docker runs best with a new kernel, so lets use 3.8.x&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# install the new kernel
$ apt-get install linux-generic-lts-raring

# update grub so it will use the new kernel after we reboot
$ update-grub

# update-grub doesn&#39;t always work so lets make sure. ``/boot/grub/menu.lst`` was updated.
$ grep 3.8.0- /boot/grub/menu.lst

# nope it wasn&#39;t lets manually update ``/boot/grub/menu.lst``  (make sure you are searching for correct kernel version, look at initial uname -a results.)
$ sed -i s/3.2.0-38-virtual/3.8.0-19-generic/ /boot/grub/menu.lst

# once again lets make sure it worked.
$ grep 3.8.0- /boot/grub/menu.lst
title          Ubuntu 12.04.2 LTS, kernel 3.8.0-19-generic
kernel          /boot/vmlinuz-3.8.0-19-generic root=/dev/xvda1 ro quiet splash console=hvc0
initrd          /boot/initrd.img-3.8.0-19-generic
title          Ubuntu 12.04.2 LTS, kernel 3.8.0-19-generic (recovery mode)
kernel          /boot/vmlinuz-3.8.0-19-generic root=/dev/xvda1 ro quiet splash  single
initrd          /boot/initrd.img-3.8.0-19-generic

# much better.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reboot server (either via command line or console)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;login again and check to make sure the kernel was updated&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ ssh root@&amp;lt;server_ip&amp;gt;
$ uname -a
Linux docker-12-04 3.8.0-19-generic #30~precise1-Ubuntu SMP Wed May 1 22:26:36 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux

# nice 3.8.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Make sure docker is running and test it out.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ start dockerd
$ docker pull busybox
$ docker run busybox /bin/echo hello world
hello world
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;alternate-install:f2623c526ea98fcfa3c30f7d4e215bfa&#34;&gt;Alternate install&lt;/h2&gt;

&lt;p&gt;If you don&amp;rsquo;t want to run the get.docker.io script and want to use
packages instead, you can use the docker PPA. Here is how you use it.
Replace step 5 with the following 3 steps.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Add the custom package sources to your apt sources list. Copy and
paste the following lines at once.&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ sudo sh -c &amp;quot;echo &#39;deb http://ppa.launchpad.net/dotcloud/lxc-docker/ubuntu precise main&#39; &amp;gt;&amp;gt; /etc/apt/sources.list&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Update your sources. You will see a warning that GPG signatures
cannot be verified.&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ sudo apt-get update
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Now install it, you will see another warning that the package cannot
be authenticated. Confirm install.&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ apt-get install lxc-docker
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;ubuntu-12-10:f2623c526ea98fcfa3c30f7d4e215bfa&#34;&gt;Ubuntu 12.10&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Build an Ubuntu 12.10 server using the &amp;ldquo;Next generation cloud
servers&amp;rdquo;, with your desired size. It will give you the password,
keep that you will need it later.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When the server is up and running ssh into the server.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ ssh root@&amp;lt;server-ip&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Once you are logged in you should check what kernel version you
are running.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ uname -a
Linux docker-12-10 3.5.0-25-generic #39-Ubuntu SMP Mon Feb 25 18:26:58 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Let&amp;rsquo;s update the server package list&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ apt-get update
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Now lets install Docker and it&amp;rsquo;s dependencies. To keep things
simple, we will use the Docker install script. It will take a couple
of minutes.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ curl get.docker.io | sudo sh -x
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Docker runs best with a new kernel, so lets use 3.8.x&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# add the ppa to get the right kernel package
$ echo deb http://ppa.launchpad.net/ubuntu-x-swat/q-lts-backport/ubuntu quantal main &amp;gt; /etc/apt/sources.list.d/xswat.list

# add the key for the ppa
$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 3B22AB97AF1CDFA9

# update packages again
$ apt-get update

# install the new kernel
$ apt-get install linux-image-3.8.0-19-generic

# make sure grub has been updated.
$ grep 3.8.0- /boot/grub/menu.lst
title   Ubuntu 12.10, kernel 3.8.0-19-generic
kernel  /boot/vmlinuz-3.8.0-19-generic root=/dev/xvda1 ro quiet splash console=hvc0
initrd  /boot/initrd.img-3.8.0-19-generic
title   Ubuntu 12.10, kernel 3.8.0-19-generic (recovery mode)
kernel  /boot/vmlinuz-3.8.0-19-generic root=/dev/xvda1 ro quiet splash  single
initrd  /boot/initrd.img-3.8.0-19-generic

# looks good. If it doesn&#39;t work for you, look at the notes for 12.04 to fix.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reboot server (either via command line or console)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;login again and check to make sure the kernel was updated&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ ssh root@&amp;lt;server_ip&amp;gt;
$ uname -a
Linux docker-12-10 3.8.0-19-generic #29~precise2-Ubuntu SMP Fri Apr 19 16:15:35 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux

# nice 3.8.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Make sure docker is running and test it out.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ start dockerd
$ docker pull busybox
$ docker run busybox /bin/echo hello world
hello world
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;ubuntu-13-04:f2623c526ea98fcfa3c30f7d4e215bfa&#34;&gt;Ubuntu 13.04&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Build an Ubuntu 13.04 server using the &amp;ldquo;Next generation cloud
servers&amp;rdquo;, with your desired size. It will give you the password,
keep that you will need it later.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When the server is up and running ssh into the server.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ ssh root@&amp;lt;server-ip&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Once you are logged in you should check what kernel version you
are running.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ uname -a
Linux docker-1304 3.8.0-19-generic #29-Ubuntu SMP Wed Apr 17 18:16:28 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Let&amp;rsquo;s update the server package list&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ apt-get update
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Now lets install Docker and it&amp;rsquo;s dependencies. To keep things
simple, we will use the Docker install script. It will take a couple
of minutes.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ curl get.docker.io | sudo sh -x
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Make sure docker is running and test it out.&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ start dockerd
$ docker pull busybox
$ docker run busybox /bin/echo hello world
hello world
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;what-s-next:f2623c526ea98fcfa3c30f7d4e215bfa&#34;&gt;What&amp;rsquo;s Next&lt;/h1&gt;

&lt;p&gt;Now that you have Docker running on a server, you can look at the
different &lt;a href=&#34;http://docs.docker.com/en/latest/examples/&#34;&gt;Docker examples&lt;/a&gt;
in the documentation to see how it works, and then build something, and
let everyone know what you have built. If you have any issues or
suggestions, open a github issue and let everyone know. Docker is a new
project, and it is moving quick, so any suggestions that you have might
help shape the future of the project.&lt;/p&gt;

&lt;h1 id=&#34;trouble-shooting:f2623c526ea98fcfa3c30f7d4e215bfa&#34;&gt;Trouble shooting&lt;/h1&gt;

&lt;p&gt;If you are pulling a repo and you get an error like this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;Error: exit status 1: bsdtar: Linkname can&#39;t be converted from UTF-8 to current locale.
bsdtar: Linkname can&#39;t be converted from UTF-8 to current locale.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It means the the docker daemon doesn&amp;rsquo;t have the correct locales loaded
on startup. To fix it make sure your init script looks something like
this.&lt;/p&gt;

&lt;p&gt;Make sure the path to the docker binary is correct because in some
installs it might be &lt;code&gt;/usr/local/bin&lt;/code&gt; and others &lt;code&gt;/usr/local/&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;description     &amp;quot;Run docker&amp;quot;

start on runlevel [2345]
stop on starting rc RUNLEVEL=[016]
respawn

script
    test -f /etc/default/locale &amp;amp;&amp;amp; . /etc/default/locale || true
    LANG=$LANG LC_ALL=$LANG /usr/local/bin/docker -d
end script
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Python and Django Presentation</title>
      <link>http://www.kencochrane.net/blog/2013/02/intro-to-python-and-django-presentation/</link>
      <pubDate>Tue, 19 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2013/02/intro-to-python-and-django-presentation/</guid>
      <description>

&lt;p&gt;I recently gave a talk at a &lt;a href=&#34;http://www.DjangoMaine.com&#34;&gt;DjangoMaine&lt;/a&gt;
meetup introducing folks to &lt;a href=&#34;http://python.org&#34;&gt;Python&lt;/a&gt; and
&lt;a href=&#34;http://www.djangoproject.com&#34;&gt;Django&lt;/a&gt;. There wasn&amp;rsquo;t enough time to go
over everything, so I tried to pick and choose the parts that I felt
where important to go over, in order to have a good overview of what
Python and Django is all about.&lt;/p&gt;

&lt;p&gt;I hope this was useful to the folks that attended. If so, it would be
really helpful to know what parts you would like to know more about.
Then we can have some follow up talks doing a deeper dive into those
select topics.&lt;/p&gt;

&lt;h1 id=&#34;future-tutorials:4fc2b1faefdeda1197ff24a2851972b4&#34;&gt;Future Tutorials&lt;/h1&gt;

&lt;p&gt;Also, if there is a demand, I&amp;rsquo;m willing to do a half or whole day Python
and Django tutorial, where we would be able to take the time needed to
go into all the different topics, so that you would have a good
understanding of each one, when you left. Ideally I would probably break
up the sessions into beginner, intermediate, and advanced so that people
can move to the different levels as they get more familiar and
comfortable with Django.&lt;/p&gt;

&lt;p&gt;I would also like to offer a talk to local high schools. If we have
enough kids that are interested, I&amp;rsquo;d be willing to go to your high
school and give a talk and introduce these topics to the kids.&lt;/p&gt;

&lt;p&gt;If you are interested in learning more about Django, please let me know.
I don&amp;rsquo;t want to waste my time doing all the work preparing for a
tutorial, if there isn&amp;rsquo;t enough demand.&lt;/p&gt;

&lt;h1 id=&#34;slides:4fc2b1faefdeda1197ff24a2851972b4&#34;&gt;Slides&lt;/h1&gt;

&lt;p&gt;We didn&amp;rsquo;t record the talk, but you can find my slides below.&lt;/p&gt;

&lt;h1 id=&#34;download:4fc2b1faefdeda1197ff24a2851972b4&#34;&gt;Download&lt;/h1&gt;

&lt;p&gt;The slides are also available to download in pdf form: &lt;a href=&#34;https://speakerd.s3.amazonaws.com/presentations/21c679705ccf0130a3061231381a97d7/intro-to-python-django_v2.pdf&#34;&gt;Intro to Python
and Django Presentation
slides&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you have any questions, or comments, feel free to contact me via the
comments below, or on Twitter (@KenCochrane)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Pelican Based Blog</title>
      <link>http://www.kencochrane.net/blog/2012/12/new-pelican-based-blog/</link>
      <pubDate>Sun, 09 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2012/12/new-pelican-based-blog/</guid>
      <description>&lt;p&gt;I have recently changed my Django based blog to a statically generated
blog based on &lt;a href=&#34;http://getpelican.com&#34;&gt;Pelican&lt;/a&gt;, and hosted by &lt;a href=&#34;http://pages.github.com&#34;&gt;GitHub
Pages&lt;/a&gt;. This is for a couple of reasons.&lt;/p&gt;

&lt;p&gt;The first reason was because my blog is really simple, it was just a
bunch of reStructuredText documents that were converted to HTML. I
didn&amp;rsquo;t need the Django-admin features and I always felt it was a little
overkill for my blog.&lt;/p&gt;

&lt;p&gt;The second reason was because I wanted to host my blog contents on
GitHub so that others could change/update/edit my blog posts and send me
pull requests if they have something good to add. Doing this with my old
blog would have been hard, but it will be really easy with this current
setup.&lt;/p&gt;

&lt;p&gt;I was looking through all of the different static generators, and boy
there are a lot of them. I decided to pick pelican because it did what I
needed, and was real easy to setup and use.&lt;/p&gt;

&lt;p&gt;My requirements for a site generator:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Python: I wanted it python based, in case it needed any changes, I
wouldn&amp;rsquo;t need much of a learning curve learning a new language.&lt;/li&gt;
&lt;li&gt;Open Source: I wanted to have the ability to change it to add my own
features in case it doesn&amp;rsquo;t have them to start. Plus Open Source
code rules.&lt;/li&gt;
&lt;li&gt;reStructureText: I wanted to write my blog posts in ReST.&lt;/li&gt;
&lt;li&gt;Themes: I wanted some out of the box themes that I could pick from
and customize&lt;/li&gt;
&lt;li&gt;Easy: I wanted something with minimum setup and overhead to
get started.&lt;/li&gt;
&lt;li&gt;Maintain Links: I wanted to keep the same URL structure from my old
blog so I wouldn&amp;rsquo;t get lots of 404 errors once I converted.&lt;/li&gt;
&lt;li&gt;Active development: I wanted a project that is currently under
active development.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After I did some quick searches, I found Pelican, and I liked what I
saw. I wrote a simple python script that pull out my blog posts from my
old blog and generated the initial ReST docs, which got me most of the
way there.&lt;/p&gt;

&lt;p&gt;Once I got the content pulled out, I just needed to pick a theme, and
configure the settings. Then setup my github pages site, and push all
the code. The last change was to change my DNS records, and then I was
done.&lt;/p&gt;

&lt;p&gt;Now anytime I want to write a blog post, all I have to do is add a new
ReST doc and rerun the build command, and commit my changes, and push my
repo. Then github automatically updates my site. Simple as that.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll run it from github for a little while and see how I like it. I
might end up changing hosting, since github has very limited features,
and doesn&amp;rsquo;t allow you to add any rewrite rules or anything custom. I
could have just as easily hosted on AWS s3, or
&lt;a href=&#34;http://dotCloud.com&#34;&gt;dotCloud&lt;/a&gt;, but I wanted to try this out first
since it was pretty easy to setup.&lt;/p&gt;

&lt;p&gt;If you switched to a static site generator, or are thinking about doing
it, let me know what you think and what tools you are using.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploying my Django application to dotCloud: Part 2</title>
      <link>http://www.kencochrane.net/blog/2012/03/deploying-a-django-application-on-dotcloud/</link>
      <pubDate>Fri, 23 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2012/03/deploying-a-django-application-on-dotcloud/</guid>
      <description>

&lt;p&gt;As I mentioned in a &lt;a href=&#34;http://kencochrane.net/blog/2012/03/im-now-working-for-dotcloud/&#34;&gt;recent blog
post&lt;/a&gt;,
in the 11 months since I wrote my &lt;a href=&#34;http://kencochrane.net/blog/2011/04/deploying-my-django-application-to-dotcloud/&#34;&gt;first post on
dotCloud&lt;/a&gt;,
I now work there. Besides me working there, there has been a lot of
other changes at &lt;a href=&#34;http://www.dotcloud.com&#34;&gt;dotCloud&lt;/a&gt;, and I wanted to
take the time to update my original post so that it was up to date and
had all the recent information. I&amp;rsquo;m going to completely rewrite the old
blog post here, with updated information, and leave the old one around
for posterity.&lt;/p&gt;

&lt;p&gt;dotCloud&amp;rsquo;s goal is to provide a bunch of different independent services
that you can use as building blocks to build your application. If you
need a database, take your pick from one of the many they support. Need
an application that uses Django or Rails on the front end, and Java in
the backend, that is fine, you can do that too. They realize that most
developers don&amp;rsquo;t stick to one standard technology stack for all of their
applications, so this allows you the flexibility to use the best tool
for the job. It also gives you a nice playground to try out new services
and see how they run without having to install, configure and maintain
the service just for testing.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m going to go over the steps that it took to install my blog onto
dotCloud, and hopefully answer some common questions along the way.&lt;/p&gt;

&lt;h1 id=&#34;documentation:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Documentation&lt;/h1&gt;

&lt;p&gt;Before I get started with any new service the first thing I usually do
is look at the documentation. DotCloud has a nice list of documents
along with some tutorials on how to get started. These 4 documents were
the ones that I used the most.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.dotcloud.com/firststeps/platform-overview/&#34;&gt;http://docs.dotcloud.com/firststeps/platform-overview/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.dotcloud.com/tutorials/python/django/&#34;&gt;http://docs.dotcloud.com/tutorials/python/django/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.dotcloud.com/services/mysql/&#34;&gt;http://docs.dotcloud.com/services/mysql/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.dotcloud.com/services/mysql-masterslave/&#34;&gt;http://docs.dotcloud.com/services/mysql-masterslave/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;first-steps:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;First Steps:&lt;/h1&gt;

&lt;p&gt;Like all cool services these days, dotCloud uses a python based CLI, so
before we can get started we need to install the dotCloud client and
configure it so that we can start using it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# create my dotcloud virtual environment.
$ mkvirtualenv dotcloud

# install dotcloud client using pip
$ pip install dotcloud

# create our application called blog
$ dotcloud create blog

#enter api key that we got from: http://www.dotcloud.com/account/settings when prompted
#&amp;lt;key goes here&amp;gt;

# if you were not prompted to enter your key you can run this command, and it will let you enter your API key again.
$ dotcloud register
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have the client all setup, and an application created, now
we can start building our service. I have forked my blog repository on
github so that I could make dotCloud specific changes to it and not
effect my original repo.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# go into projects directory
cd ~/projects

# forked kencochranenet to kencochranenet_dotcloud, now clone that. locally
git clone git://github.com/kencochrane/kencochranenet_dotcloud.git kencochranenet_dotcloud

# go into the new directory.
cd kencochrane_dotcloud
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reading through the documentation tells me that I need to create a
wsgi.py file and put in the root of my project. Using
&lt;a href=&#34;http://docs.dotcloud.com/tutorials/python/django/#wsgi-py&#34;&gt;http://docs.dotcloud.com/tutorials/python/django/#wsgi-py&lt;/a&gt; as a
template, I created my wsgi.py file below. I had issues with the default
template and I needed to add a directory to the sys.path so that wsgi
could find my django apps correctly. Here is my finished file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;import os
import sys

# Ken added this, only thing that is different from the example template (not counting settings file name)
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),&#39;mysite&#39;)))
os.environ[&#39;DJANGO_SETTINGS_MODULE&#39;] = &#39;mysite.settings&#39;

import django.core.handlers.wsgi
djangoapplication = django.core.handlers.wsgi.WSGIHandler()
def application(environ, start_response):
    if &#39;SCRIPT_NAME&#39; in environ:
        del environ[&#39;SCRIPT_NAME&#39;]
    return djangoapplication(environ, start_response)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DotCloud uses &lt;a href=&#34;http://www.pip-installer.org/en/latest/#requirements-files&#34;&gt;PIP requirements
files&lt;/a&gt; to
manage your project dependencies. We already have our pip requirements
file where it needs to be and named correctly so we don&amp;rsquo;t need to do
anything, but if we didn&amp;rsquo;t have one, we would need to create one and put
it in the root, and call it requirements.txt&lt;/p&gt;

&lt;h2 id=&#34;services:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Services&lt;/h2&gt;

&lt;p&gt;When we add a service to our deployment stack, dotCloud gives us the
appropriate connection information in a file called
&amp;lsquo;/home/dotcloud/environment.json&amp;rsquo; that is available to us on our
deployment container. This allows us to not have to hard code
username/password and server urls in our settings.py file, and it also
makes it a little more secure for us since we don&amp;rsquo;t have to have that
info in our source repository.&lt;/p&gt;

&lt;p&gt;This is how we use it. At the top of your settings.py file you will need
to add the following. snippet.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;import json
with open(&#39;/home/dotcloud/environment.json&#39;) as f:
  env = json.load(f)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once we have that added to the settings.py file, we now have a variable
env that has all of the env settings we need.&lt;/p&gt;

&lt;p&gt;You could go a little further add some custom code to check if the
environment.json file exists, and if it does, you know you are in
production, so use that setup, or if not, then you must be in local
mode, so use your local settings. If you want to get really cool, you
can have your own json file that has a similar setup for local
development, and if it doesn&amp;rsquo;t find the dotcloud one, it could look for
your own, and load your settings from that. This will allow you to use
the same settings file for both production and dev, with only a little
bit of code at the top to load the correct env file.&lt;/p&gt;

&lt;h2 id=&#34;database:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Database&lt;/h2&gt;

&lt;p&gt;Most applications need a database, and this blog is no different. This
is how we setup our database to work with our blog on dotcloud. We are
going to be using mysql for our database. With Django you need to set
your database settings in your settings.py. This is how we setup a mysql
database connection inside of our settings.py. Notice that the name of
the database doesn&amp;rsquo;t come from the env, you pick that yourself.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;DATABASES = {
    &#39;default&#39;: {
        &#39;ENGINE&#39;: &#39;django.db.backends.mysql&#39;,
        &#39;NAME&#39;: &#39;blogdb&#39;,
        &#39;USER&#39;: env[&#39;DOTCLOUD_DB_MYSQL_LOGIN&#39;],
        &#39;PASSWORD&#39;: env[&#39;DOTCLOUD_DB_MYSQL_PASSWORD&#39;],
        &#39;HOST&#39;: env[&#39;DOTCLOUD_DB_MYSQL_HOST&#39;],
        &#39;PORT&#39;: int(env[&#39;DOTCLOUD_DB_MYSQL_PORT&#39;]),
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;create-the-database:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Create the Database&lt;/h2&gt;

&lt;p&gt;dotCloud gives you your own dedicated database, with full root access.
With great power comes great responsibilities. One of those
responsibilities is that you need to create your own database schemas,
and users yourself. Which means you normally need to do something like
this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# connect to dotcloud mysql server instance
$ dotcloud run blog.db -- mysql -u root -p

# mysql -u root -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 34
Server version: 5.1.41-3ubuntu12.10 (Ubuntu)

# create the user and database and give user permissions to database.

Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.

mysql&amp;gt; create database blogdb;
Query OK, 1 row affected (0.00 sec)

mysql&amp;gt; create user &#39;blog_username&#39; identified by &#39;strong_password&#39;;
Query OK, 0 rows affected (0.05 sec)

mysql&amp;gt; grant all on blogdb.* to &#39;blog_user&#39;@&#39;%&#39;;
Query OK, 0 rows affected (0.04 sec)

mysql&amp;gt; flush privileges;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; exit;Bye
Shared connection to database closed.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Does that look familiar? I have it here in case you want to do it the
long way.&lt;/p&gt;

&lt;p&gt;To make things easier, we are going to create a small python script that
will check to see if we have our database created, and if not, it will
create it for us. This will make it so that we don&amp;rsquo;t have to login into
our database and do it by hand before we deploy. The file is called
createdb.py and this is what it looks like. This script is for mysql. If
you want a postgreSQL database, you can use this as a template and
change it so that it will work with postgreSQL.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;import MySQLdb
import os
from wsgi import *

def create_dbs(names):
    print(&amp;quot;create_dbs: let&#39;s go.&amp;quot;)
    django_settings = __import__(os.environ[&#39;DJANGO_SETTINGS_MODULE&#39;], fromlist=&#39;DATABASES&#39;)
    print(&amp;quot;create_dbs: got settings.&amp;quot;)
    databases = django_settings.DATABASES
    for name, db in databases.iteritems():
        if name in names and db[&#39;ENGINE&#39;].endswith(&#39;mysql&#39;):
            host = db[&#39;HOST&#39;]
            user = db[&#39;USER&#39;]
            password = db[&#39;PASSWORD&#39;]
            port = db[&#39;PORT&#39;]
            db_name = db[&#39;NAME&#39;]
            print &#39;creating database %s on %s&#39; % (db_name, host)
            db = MySQLdb.connect(user=user,
                                passwd=password,
                                host=host,
                                port=port)
            cur = db.cursor()
            print(&amp;quot;Check if database is already there.&amp;quot;)
            cur.execute(&amp;quot;&amp;quot;&amp;quot;SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA
                         WHERE SCHEMA_NAME = %s&amp;quot;&amp;quot;&amp;quot;, (db_name,))
            results = cur.fetchone()
            if not results:
                print(&amp;quot;Database %s doesn&#39;t exist, lets create it.&amp;quot; % db_name)
                sql = &amp;quot;&amp;quot;&amp;quot;CREATE DATABASE IF NOT EXISTS %s &amp;quot;&amp;quot;&amp;quot; % (db_name,)
                print(&amp;quot;&amp;gt; %s&amp;quot; % sql)
                cur.execute(sql)
                print(&amp;quot;.....&amp;quot;)
            else:
                print(&amp;quot;database already exists, moving on to next step.&amp;quot;)


if __name__ == &#39;__main__&#39;:
    import sys
    print(&amp;quot;create_dbs start&amp;quot;)
    create_dbs(sys.argv[1:])
    print(&amp;quot;create_dbs all done&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;adding-a-cache:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Adding a cache&lt;/h2&gt;

&lt;p&gt;Since most of the blog content doesn&amp;rsquo;t change much, it is a great
candidate for caching. So we are going to take advantage of Django&amp;rsquo;s
built in caching abilities and add some caching to our blog. Normally I
use &lt;a href=&#34;http://memcached.org&#34;&gt;memcached&lt;/a&gt; for my caching, but dotCloud&amp;rsquo;s
memcached support is limited right now. The reason why it is limited is
because memcached doesn&amp;rsquo;t have any built in authentication mechanism,
and in order to make sure it is secure, you need to run a special
version of memcached that supports
&lt;a href=&#34;http://code.google.com/p/memcached/wiki/SASLAuthProtocol&#34;&gt;SASL&lt;/a&gt;, and
most of the memcached clients don&amp;rsquo;t support this. So instead of
deploying an insecure service, they decided to not support it fully.
There are ways to use it, but it involves all kind of complicated
firewall rules and running something like stunnel. So it is possible,
but it isn&amp;rsquo;t very clean.&lt;/p&gt;

&lt;p&gt;Instead they recommend that you use &lt;a href=&#34;http://redis.io&#34;&gt;redis&lt;/a&gt; instead,
redis has the same caching abilities that memcached has, plus a lot
more, including authentication. So we are going to use redis for our
cache. In order to use redis, we will need to add the redis library
because redis caching support isn&amp;rsquo;t built into Django. In your
requirements.txt file you will need to add &lt;code&gt;django-redis==1.4.5&lt;/code&gt; so that
the libraries will be available for Django to use.&lt;/p&gt;

&lt;p&gt;Once you have the library installed, you will need to add these settings
to your settings.py file so that django knows which redis server and
password to use.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;CACHES = {
    &#39;default&#39;: {
        &#39;BACKEND&#39;: &#39;redis_cache.cache.RedisCache&#39;,
        &#39;LOCATION&#39;: env[&#39;DOTCLOUD_CACHE_REDIS_HOST&#39;]+&#39;:&#39;+env[&#39;DOTCLOUD_CACHE_REDIS_PORT&#39;],
        &#39;OPTIONS&#39;: {
            &#39;DB&#39;: 1,
            &#39;PASSWORD&#39;: env[&#39;DOTCLOUD_CACHE_REDIS_PASSWORD&#39;],
            &#39;PARSER_CLASS&#39;: &#39;redis.connection.HiredisParser&#39;
        },
    },
}

# we also are going to use redis for our session cache as well.
SESSION_ENGINE = &#39;django.contrib.sessions.backends.cached_db&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For more information about using redis as your cache for Django, check
out these links.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/niwibe/django-redis&#34;&gt;https://github.com/niwibe/django-redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://pypi.python.org/pypi/django-redis/1.4.5&#34;&gt;http://pypi.python.org/pypi/django-redis/1.4.5&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.djangoproject.com/en/1.3/topics/cache/&#34;&gt;https://docs.djangoproject.com/en/1.3/topics/cache/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://answers.dotcloud.com/question/213/redis-cache-settings-for-django&#34;&gt;http://answers.dotcloud.com/question/213/redis-cache-settings-for-django&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;django-admin:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Django Admin&lt;/h2&gt;

&lt;p&gt;We also need an easy way to create our django admin account for us. In
order to do that I have this mkadmin.py script. This will default the
password to &amp;lt;&amp;lsquo;P@s$w0rd1&amp;rsquo;&amp;gt;, once you have your code installed, you will
need to login to the admin account and change your password to something
more secure.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;#!/usr/bin/env python
from wsgi import *
from django.contrib.auth.models import User
u, created = User.objects.get_or_create(username=&#39;admin&#39;)
if created:
    u.set_password(&#39;P@s$w0rd1&#39;)
    u.is_superuser = True
    u.is_staff = True
    u.save()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;media:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Media&lt;/h2&gt;

&lt;p&gt;We need to put our static and media files in the following locations:
&lt;code&gt;static=/home/dotcloud/data/static/&lt;/code&gt; and
&lt;code&gt;media=/home/dotcloud/data/media/&lt;/code&gt;. Because of this we need to make sure
we change our settings.py file, and setup an nginx.conf file to map to
the correct locations. Here are the settings.py file changes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;# media settings
MEDIA_ROOT = &#39;/home/dotcloud/data/media/&#39;
MEDIA_URL = &#39;/media/&#39;

# static settings
STATIC_ROOT = &#39;/home/dotcloud/data/static/&#39;
STATIC_URL = &#39;/static/&#39;

# admin prefix
ADMIN_MEDIA_PREFIX = &#39;/static/admin/&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is the nginx.conf&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode nginx&#34;&gt;location /media/ { root /home/dotcloud/data ; }
location /static/ { root /home/dotcloud/data ; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;post-install:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Post Install&lt;/h2&gt;

&lt;p&gt;We are going to create a
&lt;a href=&#34;http://docs.dotcloud.com/guides/postinstall/&#34;&gt;postinstall&lt;/a&gt; script to
handle all of the tasks we need to do after we install our code on the
server. This is what will call our createdb.py, and mkadmin.py files
from above, as well as syncing our database, running migrations and
running collectstatic to move all static files into the right locations.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;#!/bin/sh
python createdb.py default
python mysite/manage.py syncdb --noinput
python mysite/manage.py migrate
python mkadmin.py
mkdir -p /home/dotcloud/data/media /home/dotcloud/data/static
python mysite/manage.py collectstatic --noinput
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Don&amp;rsquo;t forget to make sure your postinstall, createdb.py and mkadmin.py
scripts are executable.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# make the script executable.
$ chmod +x postinstall createdb.py mkadmin.py
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;dotcloud-yml:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;dotcloud.yml&lt;/h2&gt;

&lt;p&gt;Now that we have our application&amp;rsquo;s project structure all setup and
configured the way dotCloud wants it, we can configure our deployment
stack. This is done with a file called dotcloud.yml. For more
information about the dotcloud.yml file check out this link:
&lt;a href=&#34;http://docs.dotcloud.com/guides/build-file/&#34;&gt;http://docs.dotcloud.com/guides/build-file/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode yaml&#34;&gt;www:
  type: python
db:
  type: mysql
cache:
  type: redis
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is telling us that we want 3 services, a python www service, a
mysql db service, and a redis cache service. This is a very basic setup,
and you can get a lot more complicated depending on what you want to
achieve. Notice that this isn&amp;rsquo;t setup for high availability because none
of the instances are scaled. See the section about scaling below for
more information. If you are running in a production app on dotCloud it
is recommended that you scale all of your services so that they can
withstand EC2 server crashes, and other unforeseen issues.&lt;/p&gt;

&lt;h2 id=&#34;deployment:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Deployment&lt;/h2&gt;

&lt;p&gt;Now we are ready to deploy our Django app, but before I go any further
it is important to know the following. Dotcloud will pay attention to
your .gitignore files. If you have a settings file in your .gitignore
file so that it doesn&amp;rsquo;t get saved in the repo, it will not push those
changes up to the cloud. You will need to remove it from the .gitignore
in order to get those files out there. It is also import to remember
that only changes that are committed are pushed, so don&amp;rsquo;t forget to
commit your changes. If you wanted to be tricky you could use a post
install script to pull down the file from a secure location and install
it that way, if you want to make things super secure.&lt;/p&gt;

&lt;p&gt;Everything is all setup, so all we have to do is push our application to
dotCloud.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# push out your changes to the server
$ dotcloud push blog .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;service-info:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Service info&lt;/h2&gt;

&lt;p&gt;Once you push your code to dotCloud you can see what it looks like by
running the info command.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# get the information about our new services
$ dotcloud info blog
cache:
    config:
        redis_password: &amp;lt;password&amp;gt;
        redis_replication: true
    instances: 1
    type: redis
db:
    config:
        mysql_masterslave: true
        mysql_password: &amp;lt;password&amp;gt;
    instances: 1
    type: mysql
www:
    config:
        static: static
        uwsgi_processes: 4
    instances: 1
    type: python
    url: &amp;lt;url was here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;scaling:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Scaling&lt;/h2&gt;

&lt;p&gt;Scaling is the ability to grow your application so that it can handle
more traffic, or possible failures that might occur. With a normal non
PaaS setup, scaling an application can be quite painful and time
consuming, but with a PaaS it can be as easy as running a few commands.
There are three types of scaling, Vertical, Horizontal, High
Availability.&lt;/p&gt;

&lt;p&gt;Vertical scaling, means growing the service you have now so that it can
get bigger. This is popular with databases, the bigger a database gets
the more space and memory it needs.&lt;/p&gt;

&lt;p&gt;Horizontal scaling means creating more then one instance of a service so
it spread the work between the different services, giving you greater
capacity.&lt;/p&gt;

&lt;p&gt;High Availability means that you have more then one service running at a
time, so that if one of the services has an issue, the other one will
pick up the slack. This will help avoid downtime, when failures occur
(EC2 instance crashes). Ideally when running in production, all of your
services should be scaled for High Availability.&lt;/p&gt;

&lt;p&gt;There are two kinds of services, stateful, and stateless. Stateful
services are services that holds persistent data. Examples of stateful
services are mysql, redis, postgresql, solr, MongoDB and RabbitMQ.&lt;/p&gt;

&lt;p&gt;Horizontally High availability scaling a stateful service on dotCloud
means creating a master/slave setup, which can switch the slave with the
master automatically if the master has any issues. dotCloud supports HA
scaling on MySQL, redis, and MongoDB.&lt;/p&gt;

&lt;p&gt;Stateful services scale like this&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;mysql : 2 (master/slave)&lt;/li&gt;
&lt;li&gt;redis : 2 (master/slave)&lt;/li&gt;
&lt;li&gt;mongodb : 3 or 5 (using replica sets)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Scaling a stateless and one of the supported stateful services is the
same. You would just run the scale command line command.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ dotcloud scale app db=2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For stateless applications, you are limited to a set number of scaling
units, unless you are on the enterprise plan. If you need to have an
application with lots of scale units, you should contact dotCloud, and
let them know what you are planning to do, and they will advise you on
how best to accomplish your goals.&lt;/p&gt;

&lt;p&gt;Link: &lt;a href=&#34;http://docs.dotcloud.com/guides/scaling/&#34;&gt;http://docs.dotcloud.com/guides/scaling/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;database-backups:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Database Backups&lt;/h2&gt;

&lt;p&gt;Just because you are hosting your application on dotCloud doesn&amp;rsquo;t mean
you shouldn&amp;rsquo;t backup your data. The most important data to backup is
your database. Luckily dotCloud makes it easy to back up your database.
There is a very helpful guide on how to setup your database backups
here: &lt;a href=&#34;http://docs.dotcloud.com/guides/backups/&#34;&gt;http://docs.dotcloud.com/guides/backups/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;email:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Email&lt;/h2&gt;

&lt;p&gt;If you need to send or receive email from your application, you can do
that to. Because dotCloud runs on EC2, and EC2 is a popular place where
SPAMMERS send SPAM from, it is best to use a 3rd party email provider to
send your emails for you. Popular ones are
&lt;a href=&#34;http://mailgun.net/&#34;&gt;MailGun&lt;/a&gt;, &lt;a href=&#34;http://sendgrid.com/&#34;&gt;SendGrid&lt;/a&gt;,
&lt;a href=&#34;http://www.critsend.com/&#34;&gt;CritSend&lt;/a&gt;, and &lt;a href=&#34;http://aws.amazon.com/ses/&#34;&gt;Amazon
SES&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can set this up a couple of different ways. The first way is the
easiest way possible, it allows you to configure the SMTP settings for
each service. You would do it like this (see below). You can manually
set the smtp settings for that service, and when your application needs
to send an email it will use those settings. This is the most simple
setup, but there are downsides to this approach. You would need to set
this for each service, if you have more then one that will be duplicated
everywhere. Also if you want to change your settings, you will need to
destroy your service and recreate it, since those configs can only be
set once when the service is created.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode yaml&#34;&gt;www:
  type: python
  config:
    smtp_server: smtp.mailgun.org
    smtp_port: 25
    smtp_username: postmaster@company.com
    smtp_password: YourMailGunPassword
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A better approach would be to use dotCloud&amp;rsquo;s SMTP service. The SMTP
service is built to receive emails from your services and forward them
to the appropriate location. It is best to use a 3rd party email
provider, but you can also use the typical poor mans solution, where you
use gmail to send your emails. Be careful when using gmail, because you
aren&amp;rsquo;t aloud to send a lot of emails via gmail, once you hit your daily
limit you will be blocked, so this is fine for a few emails a day, don&amp;rsquo;t
trust it for everyday stuff. Also, the emails will always be coming from
your gmail address, fine for system emails, but not if you are trying to
run a legit business.&lt;/p&gt;

&lt;p&gt;Here is an example using mailgun.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode yaml&#34;&gt;mailer:
  type: smtp
  config:
    smtp_relay_server: smtp.mailgun.org
    smtp_relay_port: 587
    smtp_relay_username: postmaster@yourmailgundomain.com
    smtp_relay_password: YourMailgunPassword
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is an example using gmail.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode yaml&#34;&gt;mailer:
  type: smtp
  config:
    smtp_relay_server: smtp.gmail.com
    smtp_relay_port: 587
    smtp_relay_username: your_gmail_username@gmail.com
    smtp_relay_password: Your_Gmail_Password
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once you have these all setup, they will be available in your
environment.json file.&lt;/p&gt;

&lt;p&gt;If you want to receive email, it is best to use a service like
&lt;a href=&#34;http://mailgun.net/&#34;&gt;MailGun&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;Links:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.dotcloud.com/guides/emails/&#34;&gt;http://docs.dotcloud.com/guides/emails/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.dotcloud.com/services/smtp/&#34;&gt;http://docs.dotcloud.com/services/smtp/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cron-jobs:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Cron jobs&lt;/h2&gt;

&lt;p&gt;If your app needs to run cron jobs, follow the steps in this guide:
&lt;a href=&#34;http://docs.dotcloud.com/guides/periodic-tasks/&#34;&gt;http://docs.dotcloud.com/guides/periodic-tasks/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;celery:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Celery&lt;/h2&gt;

&lt;p&gt;This blog doesn&amp;rsquo;t really have a need for celery, but dotCloud does
support it. For more information follow this link:
&lt;a href=&#34;http://docs.dotcloud.com/tutorials/python/django-celery/&#34;&gt;http://docs.dotcloud.com/tutorials/python/django-celery/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;s3fs:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;S3FS&lt;/h2&gt;

&lt;p&gt;If you store data on s3 you can mount your s3 bucket so that you can
have access to s3 from your application, just like it was a local
directory on your container. This is helpful for storing files that are
uploaded by your visitors, or to share files between different web
processes. Follow these instructions to set it up:
&lt;a href=&#34;http://docs.dotcloud.com/guides/s3fs/&#34;&gt;http://docs.dotcloud.com/guides/s3fs/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;logs:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Logs&lt;/h2&gt;

&lt;p&gt;If you need to look at the logs to see how it is going you can do it two
ways. The first way will tail your logs for you to your console.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# look at logs of your service, it will tail them to your console. ctrl-c to stop.
$ dotcloud logs blog.www
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or login via ssh and look at your logs.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# Open up a shell
$ dotcloud ssh blog.www
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here are the ones you most likely care about.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# nginx access and error logs.
/var/log/nginx/&amp;lt;app_name&amp;gt;.{access,error}.log

# wsgi error logs
/var/log/supervisor/uswgi.log
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;restart-service:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Restart Service&lt;/h2&gt;

&lt;p&gt;If you need to restart your service just issue this command.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;# restart the service
dotcloud restart blog.www
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;links:8d0e410e0ddddb0ed1940349f9f087b6&#34;&gt;Links&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Read how this service stacks up against other services like it in my
&lt;a href=&#34;http://kencochrane.net/blog/2011/06/django-hosting-roundup-who-wins/&#34;&gt;Django hosting
roundup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.dotCloud.com&#34;&gt;http://www.dotCloud.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>I&#39;m now working for dotCloud</title>
      <link>http://www.kencochrane.net/blog/2012/03/im-now-working-for-dotcloud/</link>
      <pubDate>Fri, 23 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2012/03/im-now-working-for-dotcloud/</guid>
      <description>&lt;p&gt;A lot has happened in the 11 months since I wrote my &lt;a href=&#34;http://kencochrane.net/blog/2011/04/deploying-my-django-application-to-dotcloud/&#34;&gt;first blog article
on
dotCloud&lt;/a&gt;.
There was an Egyptian revolution, a royal wedding, a new iPhone and
iPad, Osama bin Laden was killed, and on a more personal note, I left my
job at CashStar and I now work for &lt;a href=&#34;http://www.dotCloud.com&#34;&gt;dotCloud&lt;/a&gt;.
In the grand scheme of things, my job change was nothing compared to
those big events of the past 11 months, but it was pretty big for me.&lt;/p&gt;

&lt;p&gt;I had worked for CashStar.com for over 3.5 years, and I was there from
pretty much the beginning, so it was hard for me to walk away. When I
started doing research on PaaS&amp;rsquo;s over a year ago, I did it so that I
could learn more about how these systems were built, so that I could
take that knowledge and bring it to CashStar to improve our
infrastructure there.&lt;/p&gt;

&lt;p&gt;A funny thing happened as I was doing my research, I started to really
love the technology that went into making a PaaS, and over time, I
thought that it was such a cool concept, that I wanted to know
everything there was to know about them, so that I could build my own.
After trying out all of the PaaS&amp;rsquo;s that I could find, and learning and
blogging about them. I decided I would see what it would take to build
my own PaaS. The first thing I realized is that there is a lot more
going on under the covers then one might imagine, and this wasn&amp;rsquo;t going
to be an easy problem to solve. If it was easy, then everyone and their
brother would have one, but they don&amp;rsquo;t. There are a lot of PaaS&amp;rsquo;s out
there now, but if you think about it, that is nothing compared to the
number of web hosting companies.&lt;/p&gt;

&lt;p&gt;After realizing that this isn&amp;rsquo;t something I was going to be able to
build in a weekend, I kind of lost motivation. I have 2 kids and a job
that was making me work a ton of hours, so the few extra hours I had in
a day where spent hanging out with my family, and what ever was left
over was spent playing one of my many sports, or getting some much
needed sleep. So, for a while my dream of making my own PAAS faded for a
little while, but it never disappeared.&lt;/p&gt;

&lt;p&gt;As fate would have it, a few months later I ended up talking with the
dotCloud guys, and next thing you know they made me an offer to join
their company. After talking it over with my wife, I decided to go for
it. Since dotCloud is based in San Francisco, I&amp;rsquo;ll be working from home
in Maine, and telecommuting to work each day from my home office. I have
been working for dotCloud for about 5 weeks so far, and it has been
awesome. I have learned so many new and cool things in the past month,
it has been great. The dotCloud team is top notch and I can&amp;rsquo;t wait to
learn even more from them.&lt;/p&gt;

&lt;p&gt;My title at dotCloud is Site Reliability Engineer. You might have never
heard about that title before. To be honest I had never heard of it
before myself. My primary goal is to make sure that the dotCloud
platform is as stable and reliable as it could be. One of our goals is
to automate everything, so that if something fails, we have a process
that will notice this, and auto correct it for us. Since dotCloud is
build on top of Amazon EC2, things can happen at anytime, and they do.
So when they happen, we need a self healing platform that will fix
itself when things break in the middle of the night. If it doesn&amp;rsquo;t fix
it self, someone will need to be woken up to fix it, and no one wants
that.&lt;/p&gt;

&lt;p&gt;Another one of my goals is to make sure that dotCloud is the best
developers platform available. I want to make it so that developers can
do what ever they want to do, and if they have any issues, give them the
tools they need to solve their own problems. If they get stuck, we will
be there to help them through their problems, via IRC, or email support.&lt;/p&gt;

&lt;p&gt;Every developer writes code with bugs, and if you find one that tells
you otherwise, they are lying. dotCloud allows developers to see all of
their application and system logs easily, and also gives them direct SSH
access to the containers where their code is running so that they have
the ability to see why something isn&amp;rsquo;t working. Most PaaS&amp;rsquo;s don&amp;rsquo;t
provide this, which makes it harder to figure out why the code that you
wrote isn&amp;rsquo;t working the way that you had planned.&lt;/p&gt;

&lt;p&gt;One of the cool things that dotCloud does is that they are heavy
believers in &lt;a href=&#34;http://en.wikipedia.org/wiki/Eating_your_own_dog_food&#34;&gt;dog
fooding&lt;/a&gt;. They
encourage employees to use the platform as much as possible, and it is
amazing to know that a lot of dotCloud runs on dotCloud. This helps
smooth out all of the different developer pain points, and makes for a
better platform overall.&lt;/p&gt;

&lt;p&gt;They also listen to what their users have to say, and take it to heart.
If you have used dotCloud in the past, and were turned off for some
reason, you should come back and try it again, it has changed a ton, and
the issue that you might have had a while ago, might no longer be there.
If you are still having issues, please tell us, because if we don&amp;rsquo;t know
that it is an issue for you, there is no way we can fix it.&lt;/p&gt;

&lt;p&gt;One of the first things that I noticed when I joined was the support
that they offer, it is unbelievable. I get an email for every single
support ticket that is created, and the responses. I have learned a lot
just by reading those emails. We get tickets for everything from sticker
requests all the way to &amp;ldquo;my website is having issues, can you help&amp;rdquo;.
Each day there is at least one engineer dedicated to answering support
tickets, and that is all they do for the day, everything else takes a
back seat. The same people who are building dotCloud are the ones
answering your questions, so when you get an answer you know it is
coming directly from the source. Most tickets are responded to and
closed really quickly. It wasn&amp;rsquo;t always this good, but it is something
they work on improving all of the time, because they realize, that it is
important to have a quick and helpful support staff around to solve your
problems when you have them.&lt;/p&gt;

&lt;p&gt;Now that I&amp;rsquo;m on the inside, I can see and hear about all of the cool new
things they are working on for the future, and I&amp;rsquo;m really excited. If
you are a developer and you haven&amp;rsquo;t tried dotCloud yet, or if you have
tried them a while ago and you haven&amp;rsquo;t tried them recently you should
check them out. What are you waiting for it, is FREE, it won&amp;rsquo;t cost you
anything to try it out, and you never know it might change your life.&lt;/p&gt;

&lt;p&gt;One of the sad things about working for dotCloud will mean that I won&amp;rsquo;t
be able to blog about the PaaS industry that much anymore. I&amp;rsquo;m going to
try and avoid doing it, due to the conflict of interest. I will keep
around my old blog post so that everyone can benefit, and I&amp;rsquo;ll try to
keep them up to date, but besides that I won&amp;rsquo;t be writing about anything
unless it is really cool.&lt;/p&gt;

&lt;p&gt;If you have tried out dotCloud, let me know what you think, and let me
know if there is anything we can do to make it better for you.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Running sentry on DotCloud</title>
      <link>http://www.kencochrane.net/blog/2012/01/running-sentry-on-dotcloud/</link>
      <pubDate>Sat, 28 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2012/01/running-sentry-on-dotcloud/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/dcramer/sentry&#34;&gt;Sentry&lt;/a&gt; is a realtime event logging
and aggregation platform. At its core it specializes in monitoring
errors and extracting all the information needed to do a proper
post-mortum without any of the hassle of the standard user feedback
loop.&lt;/p&gt;

&lt;p&gt;The main feature of sentry and the ability to send all of your
application logs to one place, and then aggregate them, so that you only
get one error email for the same error. This will keep your mailbox from
flooding, when something goes wrong.&lt;/p&gt;

&lt;p&gt;Putting your logging server on a different server or network then your
production servers is a good idea. If something goes wrong, and you
can&amp;rsquo;t access your servers, you can still see what errors were getting
thrown before the servers started having problems.&lt;/p&gt;

&lt;p&gt;Follow these easy steps to get sentry up and running on DotCloud.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create a place to store your project&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ mkdir -p ~/projects
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Go into the projects directory&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ cd ~/projects
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Clone git repo from github, requires git client&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ git clone git://github.com/kencochrane/sentry-on-dotcloud.git
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Go into the new project directory&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ cd sentry-on-dotcloud
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Creating the virtualenv (using virtualenvwrapper, virtualenv,
and pip)&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ mkvirtualenv --no-site-packages --distribute sentry-on-dotcloud
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Install all of the Sentry requirements via pip and the
requirements.txt file.&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Installing the dotCloud client
&lt;a href=&#34;http://docs.dotcloud.com/firststeps/install/&#34;&gt;http://docs.dotcloud.com/firststeps/install/&lt;/a&gt; (here are the steps
for Linux and Mac OSX)&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ sudo pip install -U dotcloud
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Sign up for a dotcloud account
&lt;a href=&#34;https://www.dotcloud.com/accounts/register/&#34;&gt;https://www.dotcloud.com/accounts/register/&lt;/a&gt; if you
haven&amp;rsquo;t already.&lt;/li&gt;
&lt;li&gt;The first time you use the dotCloud account you will need to add
your api key. So type dotcloud and follow the steps. You can find
your API key at &lt;a href=&#34;http://www.dotcloud.com/account/settings&#34;&gt;http://www.dotcloud.com/account/settings&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ dotcloud
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Create your dotcloud application&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ dotcloud create sentry
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Change the SENTRY_KEY settings in these files, to the same
unique value.

&lt;ul&gt;
&lt;li&gt;sentry_conf.py&lt;/li&gt;
&lt;li&gt;sentryproj/settings.py&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here is an example on how to generate a good unique key that you can use
in the files above.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; import base64
&amp;gt;&amp;gt;&amp;gt; import os
&amp;gt;&amp;gt;&amp;gt; KEY_LENGTH = 40
&amp;gt;&amp;gt;&amp;gt; base64.b64encode(os.urandom(KEY_LENGTH))
&#39;6+tSEh1qYwDuTaaQRcxUjMDkvlj4z9BU/caCFV5QKtvnH7ZF3i0knA==&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Add your email address to SENTRY_ADMINS in sentryproj/settings.py .
This will send you emails when an error occurs.&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;SENTRY_ADMINS = (&#39;youremail@example.com&#39;,)
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Push your code into dotcloud&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ dotcloud push sentry .
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Find out your application url&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ dotcloud url sentry
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Open url in your browser and start using sentry on dotcloud.&lt;/li&gt;
&lt;li&gt;First things first you should change the admin password from the
default one that was created on deployment. The default username and
password are found in the mkadmin.py file.&lt;/li&gt;
&lt;li&gt;Test out sentry using the raven client to make sure it is working as
it should. Open up a python shell on your local machine and do
the following.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Replace the server_url with your sentry url you found out in step 14.
Make sure it ends in /store/ . Also make sure you replace my_key with
your sentry key&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from raven import Client
&amp;gt;&amp;gt;&amp;gt; server_url = &amp;quot;http://sentry-username.dotcloud.com/store/&amp;quot;
&amp;gt;&amp;gt;&amp;gt; my_key=&#39;1234-CHANGEME-WITH-YOUR-OWN-KEY-567890&#39;
&amp;gt;&amp;gt;&amp;gt; client = Client(servers=[server_url], key=my_key)
&amp;gt;&amp;gt;&amp;gt; client.create_from_text(&#39;My event just happened!&#39;)
(&#39;48ba88039e0f425399118f82173682dd&#39;, &#39;3313fc5636650cccaee55dfc2f2ee7dd&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you go to the sentry webpage you should see your test message. If
not, double check everything, and see if there was any errors during the
send.&lt;/p&gt;

&lt;p&gt;Once this is all up and running you can install the raven client in your
applications, and start sending your logs to sentry.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Optional: If you don&amp;rsquo;t like the URL they gave you, you can use your
custom domain. Assuming your application was sentry.www and your
domain was www.example.com you would do the following&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ dotcloud alias add sentry.www www.example.com
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once you get comfortable with how things work, don&amp;rsquo;t forget to change
your DEBUG setting to False. Go ahead and fork my project and get
started today.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;For more info about dotcloud, sentry, and Raven and what you can do with with it. Check out their docs&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;Sentry on DotCloud GitHub repo :
&lt;a href=&#34;https://github.com/kencochrane/sentry-on-dotcloud&#34;&gt;https://github.com/kencochrane/sentry-on-dotcloud&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul&gt;
&lt;li&gt;DotCloud overview:
&lt;a href=&#34;http://docs.dotcloud.com/firststeps/platform-overview/&#34;&gt;http://docs.dotcloud.com/firststeps/platform-overview/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Sentry Documentation:
&lt;a href=&#34;http://sentry.readthedocs.org/en/latest/index.html&#34;&gt;http://sentry.readthedocs.org/en/latest/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Raven Documentation:
&lt;a href=&#34;http://raven.readthedocs.org/en/latest/index.html&#34;&gt;http://raven.readthedocs.org/en/latest/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/dd&gt;
&lt;dt&gt;Links:&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;Virtualenv : &lt;a href=&#34;http://pypi.python.org/pypi/virtualenv&#34;&gt;http://pypi.python.org/pypi/virtualenv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul&gt;
&lt;li&gt;pip : &lt;a href=&#34;http://www.pip-installer.org/&#34;&gt;http://www.pip-installer.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;virtualenvwrapper :
&lt;a href=&#34;http://www.doughellmann.com/projects/virtualenvwrapper/&#34;&gt;http://www.doughellmann.com/projects/virtualenvwrapper/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;git : &lt;a href=&#34;http://git-scm.com/&#34;&gt;http://git-scm.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/dd&gt;
&lt;/dl&gt;
</description>
    </item>
    
    <item>
      <title>The Developers Guide to PCI Compliant Web applications</title>
      <link>http://www.kencochrane.net/blog/2012/01/developers-guide-to-pci-compliant-web-applications/</link>
      <pubDate>Wed, 25 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2012/01/developers-guide-to-pci-compliant-web-applications/</guid>
      <description>

&lt;p&gt;&lt;em&gt;last updated: 12-07-2012 by Ken Cochrane&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update: 12-07-2012&lt;/strong&gt; I have added the youtube video and slides from a
recent talk I did on Building PCI Complaint Django Applications.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update: 04-05-2012&lt;/strong&gt; This article has been &lt;a href=&#34;http://www.ituring.com.cn/article/1372&#34;&gt;translated into
chinese&lt;/a&gt; , by Wujun Shen
()&lt;/p&gt;

&lt;p&gt;When I first started working at &lt;a href=&#34;http://CashStar.com&#34;&gt;CashStar.com&lt;/a&gt;
three and a half years ago, I had heard about PCI before, but I didn&amp;rsquo;t
really know what that meant. Since we were building an ecommerce
platform that was going to be accepting credit cards over the internet,
I knew we needed to make sure we were fully PCI compliant. We were a
startup, we didn&amp;rsquo;t have much money, and any mistake could kill the
company. Since I didn&amp;rsquo;t want to be the one to make the mistake, I spent
a lot of time doing research on PCI, and what it took to make sure your
web application was secure.&lt;/p&gt;

&lt;p&gt;The first thing that I did was a simple web search, and I was surprised
to find out that there really wasn&amp;rsquo;t much information available. Most of
the information that was available, wasn&amp;rsquo;t easily understandable, and
was a little vague. There were companies that you could hire, that would
guide you through the process, but since we didn&amp;rsquo;t have much money, they
weren&amp;rsquo;t an option for us. So I did what any geek in my situation would
do, I spent a bunch of my time reading and researching as much as I
could on PCI, and figured my way through the PCI hell, until we were
fully PCI compliant.&lt;/p&gt;

&lt;p&gt;My goal with this blog post is write all of my information down, so that
I can hopefully help others through the process, and also to serve as a
reminder to me, so that when I need to do this again in the future, I
will remember every last detail. I hoping to keep this as a sort of live
document, and I&amp;rsquo;ll try to keep it up to date as time goes forward and
things change. If you notice something is incorrect or I&amp;rsquo;m missing
something, please leave a comment and I&amp;rsquo;ll do my best to update the post
as soon as I can.&lt;/p&gt;

&lt;h1 id=&#34;what-is-pci:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;What is PCI?&lt;/h1&gt;

&lt;p&gt;The first thing most people ask is &amp;ldquo;What is PCI?&amp;rdquo;. PCI is short for the
Payment Card Industry Security Standards Council. PCI consists of
American Express, Discover Financial Services, JCB, MasterCard, and
Visa, and was formed on Sept 7th, 2006.&lt;/p&gt;

&lt;p&gt;The main purpose of creating the PCI SSC, was to come up with a common
set of security standards that merchants could use to better protect
themselves against hackers. The PCI SSC came up with the Payment Card
Industry Data Security Standard (PCI DSS), which consists of 12
requirements, and many sub-requirements that merchants would need to
follow in order to accept debit, credit, prepaid, ATM or POS cards from
the PCI SSC members.&lt;/p&gt;

&lt;h1 id=&#34;why-was-pci-created:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Why was PCI created?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;It was created in response to a spike in data security breaches.&lt;/li&gt;
&lt;li&gt;It gives merchants a guide to help them make sure they are following
best security practices when it comes to card holder data.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;does-pci-affect-me:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Does PCI affect me?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Do you accept payment online or over the phone with credit/debit
cards?&lt;/li&gt;
&lt;li&gt;Is the credit card information posted to YOUR server?&lt;/li&gt;
&lt;li&gt;Do you store credit card information, encrypted or not?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you said yes to any of those, then PCI affects you in one way or
another.&lt;/p&gt;

&lt;h1 id=&#34;pci-dss-requirements:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;PCI DSS Requirements&lt;/h1&gt;

&lt;p&gt;Here is the list of 12 requirements. As you look them over, you will
notice that most of them aren&amp;rsquo;t that complicated, and you might already
be doing thing already. Most of them are just common sense, but it is
amazing how many people still don&amp;rsquo;t do things, even if it is common
sense.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Install and maintain a firewall configuration to protect cardholder
data&lt;/li&gt;
&lt;li&gt;Do not use vendor-supplied defaults for system passwords and other
security parameters&lt;/li&gt;
&lt;li&gt;Protect stored cardholder data&lt;/li&gt;
&lt;li&gt;Encrypt transmission of cardholder data across open, public networks&lt;/li&gt;
&lt;li&gt;Use and regularly update anti-virus software on all systems commonly
affected by malware&lt;/li&gt;
&lt;li&gt;Develop and maintain secure systems and applications&lt;/li&gt;
&lt;li&gt;Restrict access to cardholder data by business need-to-know&lt;/li&gt;
&lt;li&gt;Assign a unique ID to each person with computer access&lt;/li&gt;
&lt;li&gt;Restrict physical access to cardholder data&lt;/li&gt;
&lt;li&gt;Track and monitor all access to network resources and cardholder
data&lt;/li&gt;
&lt;li&gt;Regularly test security systems and processes&lt;/li&gt;
&lt;li&gt;Maintain a policy that addresses information security&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;pci-in-layman-s-terms:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;PCI in Layman&amp;rsquo;s Terms&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;All Merchants, regardless if credit card data is stored, must
achieve and maintain compliance at all times.&lt;/li&gt;
&lt;li&gt;Merchants cannot store certain credit card information including
CVV, track data, magnetic strip or PIN data&lt;/li&gt;
&lt;li&gt;If you store permitted credit card data, you need to store it in a
secure way following the PCI security standards.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;how-does-pci-certification-work:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;How does PCI Certification work?&lt;/h1&gt;

&lt;p&gt;PCI Certification works like this. If you want to accept credit or debit
cards you need to agree that you will maintain PCI certification at all
times. There are a couple of ways to confirm that you are certified. You
need to either fill out a Self-Assessment Questionnaire (SAQ) or a
Report on Compliance (RoC). I&amp;rsquo;ll go over the difference in a little bit,
but the important part to remember is that you need to fill out some
paper work, and then usually submit that paperwork to whomever requests
it, usually the company that processes your credit cards and handles
your merchant account.&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Fill out a Self-Assessment Questionnaire (SAQ) and Find out what
level you are&lt;/li&gt;
&lt;li&gt;Make sure you follow all recommendations for that level&lt;/li&gt;
&lt;li&gt;Fix any issues&lt;/li&gt;
&lt;li&gt;Attestation of Compliance (if self assessing)&lt;/li&gt;
&lt;li&gt;External Auditor (if needed)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;how-to-get-started:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;How to get started?&lt;/h1&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Identify the individuals that will be responsible for PCI
compliance in your organization and assemble a team that includes
members from each area.&lt;/li&gt;
&lt;li&gt;Determine your merchant level (1-4).&lt;/li&gt;
&lt;li&gt;Determine which SAQ your organization will need to complete.&lt;/li&gt;
&lt;li&gt;Evaluate whether your organization will try to achieve compliance
internally or engage with aQualified Security Assessor (QSA).&lt;/li&gt;
&lt;li&gt;Engage with an Approved Scanning Vendor (ASV) to start the
required external IP vulnerability scans.&lt;/li&gt;
&lt;li&gt;Make sure that your organization has an Information Security
Policy and that it is being enforced.&lt;/li&gt;
&lt;li&gt;Immediately address any significant deficiencies discovered during
the assessment or scan.&lt;/li&gt;
&lt;li&gt;Retain record of self-assessments, scans, and
follow-up activities. Be prepared to provide these documents
upon request.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;what-pci-level-am-i:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;What PCI Level am I?&lt;/h1&gt;

&lt;p&gt;There are 4 PCI compliance level&amp;rsquo;s, and how many transactions you
process a year will determine which level you are in.&lt;/p&gt;

&lt;h2 id=&#34;merchant-level:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Merchant Level&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Level 1&lt;/strong&gt; : Merchants processing over 6 million Visa transactions
annually (all channels) or Global merchants identified as Level 1 by any
Visa region&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Level 2&lt;/strong&gt; : Merchants processing 1 million to 6 million Visa
transactions annually (all channels)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Level 3&lt;/strong&gt; : Merchants processing 20,000 to 1 million Visa e-commerce
transactions annually&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Level 4&lt;/strong&gt; : Merchants processing less than 20,000 Visa e-commerce
transactions annually and all other merchants processing up to 1 million
Visa transactions annually&lt;/p&gt;

&lt;h2 id=&#34;requirements:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Requirements&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Level 1&lt;/strong&gt; : Onsite Security Assessment Required Annually, Network
Vulnerability Scan required Quarterly&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Level 2&lt;/strong&gt; : Onsite Security Assessment at Merchants Discretion,
Self-Assessment Questionnaire Required Annually, Network Vulnerability
Scan Required Quarterly&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Level 3&lt;/strong&gt; : Self-Assessment Questionnaire Required Annually, Network
Vulnerability Scan Required Quarterly&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Level 4&lt;/strong&gt; : Self-Assessment Questionnaire Required Annually, Network
Vulnerability Scan Required Quarterly&lt;/p&gt;

&lt;h1 id=&#34;roc-or-saq:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;RoC or SAQ?&lt;/h1&gt;

&lt;p&gt;If you are a Level 1 then you need to fill out a RoC, if you are level
2, 3 or 4, then you can fill out an SAQ. There are some exceptions to
these rules, for example, if you have had a security breach in the past,
the credit card companies might require that you complete a RoC even if
you aren&amp;rsquo;t a level 1.&lt;/p&gt;

&lt;h1 id=&#34;report-on-compliance-roc:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Report on Compliance (RoC)&lt;/h1&gt;

&lt;p&gt;If you process more than six million credit cards per year (Level 1),
you are required to have an on-site PCI assessment and Report on
Compliance (RoC) issued by a Qualified Security Assessor (QSA). Other
Level 2 organizations may also be required to submit a RoC or choose to
do so in anticipation of becoming a Level 1 merchant.&lt;/p&gt;

&lt;p&gt;QSAs can be engaged to provide this annual review. It includes a review
of established processes and procedures for networks, servers and
databases in scope for PCI compliance. The engagement involves
interviews with stakeholders in your organization, a review of
supporting documentation, validation of compliance initiatives and
completion of the report itself.&lt;/p&gt;

&lt;p&gt;QSAs usually encourage their PCI Customers to use a PCI compliance
management solution throughout the year. This will assist them with
maintaining compliance and should make the on-site engagement and the
completion of the RoC faster and smoother.&lt;/p&gt;

&lt;h1 id=&#34;self-assement-questionnaire:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Self-Assement Questionnaire&lt;/h1&gt;

&lt;p&gt;There are 5 SAQ categories, depending on which category that you fall
into, the paper work might be real easy, it might take a lot longer.
Here are the 5 categories.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SAQ-A&lt;/strong&gt; : Card-not-present (e-commerce or mail/telephone-order)
merchants, all cardholder data functions outsourced. This would never
apply to face-to-face merchants.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SAQ-B&lt;/strong&gt; : Imprint-only merchants with no electronic cardholder data
storage, or standalone, dial- out terminal merchants with no electronic
cardholder data storage&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SAQ-C-VT&lt;/strong&gt; : Merchants using only web-based virtual terminals, no
electronic cardholder data storage&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SAQ-C&lt;/strong&gt; : Merchants with payment application systems connected to the
Internet, no electronic cardholder data storage&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SAQ-D&lt;/strong&gt; : All other merchants not included in descriptions for SAQ
types A through C above, and all service providers defined by a payment
brand as eligible to complete an SAQ.&lt;/p&gt;

&lt;p&gt;Since we are only talking about web applications here, you will most
likely only fall into either A, C, or D. Once you know your level you
will need to fill out the SAQ for that category. Once you are done you
need an Attestation of compliance as well.&lt;/p&gt;

&lt;p&gt;Here is a helpful guide to help you figure out what category you a fall
into.&lt;/p&gt;

&lt;h2 id=&#34;saq-a:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;SAQ-A&lt;/h2&gt;

&lt;p&gt;There are a lot of different parts to A, but the big one, is that the
credit card data never touches your servers. The easiest way to do this
is to redirect people to someone else&amp;rsquo;s servers when you want them to
enter credit card data. This is common with Paypal, google checkout and
Amazon payments.&lt;/p&gt;

&lt;p&gt;Another way around this is to have your payment page hosted by your
credit card gateway. An example of this is authorize.net&amp;rsquo;s &lt;a href=&#34;http://www.authorize.net/solutions/merchantsolutions/merchantservices/simplecheckout/&#34;&gt;Simple
Checkout&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A third way of doing this is what is called &amp;ldquo;transparent redirect&amp;rdquo; or
&amp;ldquo;Direct Post&amp;rdquo;,
&lt;a href=&#34;http://www.braintreepayments.com/services/pci-compliance&#34;&gt;BrainTreePayments&lt;/a&gt;
was the first to make this popular, but since then
&lt;a href=&#34;http://developer.authorize.net/api/dpm&#34;&gt;Authorize.net&lt;/a&gt; has also added
it.&lt;/p&gt;

&lt;p&gt;And finally the last way, is basically similar to the third way, but it
uses javascript to encrypt the credit card data, send it to the credit
card processor, and then populate the form with unique tokens, which
will be used later on. This approach is used by
&lt;a href=&#34;http://stripe.com&#34;&gt;stripe&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;BrainTree + livingsocial talk about this new approach of &lt;a href=&#34;http://www.braintreepayments.com/devblog/end-to-end-encryption&#34;&gt;end to end
encryption of credit card
data&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;saq-c:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;SAQ-C&lt;/h2&gt;

&lt;p&gt;If you are hosting the payment form on your own server, and when you hit
submit on that form it goes to your server, where you parse the form,
get the credit card details out of the fields, build up your request and
then send it to the credit card processor yourself. Then you are at
least a C. Even if you aren&amp;rsquo;t storing the data, because it is available
in your computer memory, and you are touching it with your code, there
is risk that something could happen and you would be able to get access
to the credit card data.&lt;/p&gt;

&lt;h2 id=&#34;saq-d:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;SAQ-D&lt;/h2&gt;

&lt;p&gt;If you don&amp;rsquo;t fall into the other categories then you are a D. SAQ D is
sometimes referred to as ROC light, because any organization that has to
fill out SAQ D is essentially going through all 12 PCI DSS requirements,
albeit on a reduced scale.&lt;/p&gt;

&lt;h1 id=&#34;how-much-does-pci-cost:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;How much does PCI Cost?&lt;/h1&gt;

&lt;p&gt;It is really hard to get an accurate value for this because it will be
different for everyone, but according to BrainTree here is a chart on
&lt;a href=&#34;http://www.braintreepayments.com/blog/what-does-it-cost-to-become-pci-compliant&#34;&gt;how much it costs to become PCI
Compliant&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Level   # of Trans   Scope    Compliance   Audit type&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;1       6M+           \$125K   \$586K       onsite
  2       1M-6M         \$105K   \$267K       SAQ
  3       20K-1M        \$44K    \$81K        SAQ
  4       &amp;lt; 20K      ?        ?            SAQ&lt;/p&gt;

&lt;h1 id=&#34;external-audits:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;External Audits&lt;/h1&gt;

&lt;p&gt;Level     Cost Per Year&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Low End   \$20K-\$30K
  Average   \$225K
  Top 10%   \$500K+&lt;/p&gt;

&lt;p&gt;If you are big enough or unlucky enough to require an external audit, it
isn&amp;rsquo;t going to be cheap. Audits last a few weeks or more onsite, and
cost anywhere from \$20K-\$30K on the low end. They average around
\$225K a year, and about 10% of the audits cost over \$500K. As you can
see this is a really expensive annual cost, and should be avoided if
possible.&lt;/p&gt;

&lt;p&gt;It is also important to point out that this is just the cost of the
audit itself, if they find anything wrong in the audit, you will need to
pay to fix any of the issues before they will certify you.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;Here are some links where I got my data.&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.networkworld.com/news/2010/030110-pci-compliance-audit-cost.html&#34;&gt;http://www.networkworld.com/news/2010/030110-pci-compliance-audit-cost.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.elementps.com/element_payment_solutions/2009/02/pci-compliance-costs.html&#34;&gt;http://blog.elementps.com/element_payment_solutions/2009/02/pci-compliance-costs.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infosecisland.com/blogview/12356-Five-Questions-to-Ask-Your-PCI-Auditor-Before-You-Hire-Them.html&#34;&gt;https://www.infosecisland.com/blogview/12356-Five-Questions-to-Ask-Your-PCI-Auditor-Before-You-Hire-Them.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;h1 id=&#34;pci-2-0:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;PCI 2.0&lt;/h1&gt;

&lt;p&gt;On October 26th 2010, PCI DSS version 2.0 was released. Here are some of
the highlights.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;132 changes, 2 new ones, the rest are clarifications or additional
guidelines&lt;/li&gt;
&lt;li&gt;Added more guidelines around virtualization, and how it affects PCI&lt;/li&gt;
&lt;li&gt;Amazon web services (AWS) is now a Level 1 PCI compliant
data center.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;nitty-gritty:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Nitty Gritty&lt;/h1&gt;

&lt;p&gt;Now that you know what PCI is all about, lets get down to the nitty
gritty. The most common questions I&amp;rsquo;m asked is what is the easiest way
to become PCI certified. Here is what I tell people.&lt;/p&gt;

&lt;p&gt;First off, avoid handling credit card data if you can help it. It has
become a lot easier lately with Braintree and stripe. Years ago before
these solutions were available, the only way to do it was to use an ugly
hosted payment page on your credit card gateway, and it wasn&amp;rsquo;t very
good, and hard to integrate, so most people didn&amp;rsquo;t use those solutions.&lt;/p&gt;

&lt;p&gt;Now you have no excuse, let the credit card processor handle all of the
credit card data, and it will make your life easier. If you want to see
how much easier, go to the &lt;a href=&#34;https://www.pcisecuritystandards.org&#34;&gt;PCI security
standards&lt;/a&gt; website and download
the &lt;a href=&#34;https://www.pcisecuritystandards.org/documents/pci_saq_a_v2.doc&#34;&gt;SAQ
A&lt;/a&gt; and
the &lt;a href=&#34;https://www.pcisecuritystandards.org/documents/pci_saq_c_v2.doc&#34;&gt;SAQ
C&lt;/a&gt;
docs. You will notice that the SAQ A is much easier, and a lot less of a
hassle.&lt;/p&gt;

&lt;p&gt;As great as the Briantree and stripe solutions are they can&amp;rsquo;t solve all
problems. One common problem is accepting credit card data over an API,
more and more common these days with mobile applications. If you can&amp;rsquo;t
use one of the other solutions for one reason or another, you can check
out &lt;a href=&#34;http://www.akamai.com/html/solutions/security/edge_tokenization.html&#34;&gt;Edge
Tokenization&lt;/a&gt;
from Akamai, it will work for both API and web based payment forms. It
is pretty expensive, but if you are already using some of akamai&amp;rsquo;s other
solutions then this might not be as big of an issue.&lt;/p&gt;

&lt;p&gt;If you still need/want to accept credit card data on your own server
after everything that I said above, then you are going to need to know
about some other things. For example, here are a list of common mistakes
that most people make.&lt;/p&gt;

&lt;h1 id=&#34;common-pci-mistakes:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Common PCI Mistakes&lt;/h1&gt;

&lt;p&gt;Here is a list of common mistakes most people make. I&amp;rsquo;m listing them
here so that you can catch these mistakes before it is too late. If I
missed any, let me know.&lt;/p&gt;

&lt;h2 id=&#34;storing-credit-card-information-in-plain-text:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Storing credit card information in plain text&lt;/h2&gt;

&lt;p&gt;Ideally, you should never store credit card information, but if you have
to, you should always encrypt the data, so that if someone gets ahold of
your data, they won&amp;rsquo;t be able to see it unless they put in a lot of
effort.&lt;/p&gt;

&lt;h2 id=&#34;default-passwords-not-changed:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Default passwords not changed&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m always surprised to here how weak peoples passwords are, and how
most of the time they are still using the first one that was given to
them when they started. That is why if you are the one generating a
password, make it a secure one, so that if the people don&amp;rsquo;t change the
password like you told them too, it will at least be a secure one to
begin with.&lt;/p&gt;

&lt;p&gt;There are really good password management tools on the market today, I
recommend using one of them. One of my favorites is
&lt;a href=&#34;https://agilebits.com/onepassword&#34;&gt;1password&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;remove-all-programs-not-needed-from-your-servers:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Remove all programs not needed from your servers&lt;/h2&gt;

&lt;p&gt;There are a couple reasons why you would want to remove any
programs/software from your computer if you are not using it. The first
one, it will take up less space, and if it isn&amp;rsquo;t running it will free up
processor and RAM, a faster system is always good. The second reason is
so that you don&amp;rsquo;t have to maintain the security patches for something
you aren&amp;rsquo;t using. So, the first step you should do when you bring a new
server online is to remove all of the stuff you aren&amp;rsquo;t using. You can
always add it back later.&lt;/p&gt;

&lt;h2 id=&#34;use-a-firewall:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Use a Firewall&lt;/h2&gt;

&lt;p&gt;You should always use a firewall, it doesn&amp;rsquo;t matter if it is a hardware
firewall or a software firewall, use it, and never turn it off. In some
of my production systems I run both a hardware firewall coming into my
private network and then a software firewall on each system. Some people
think this is overkill, but I would rather be safer then sorry.&lt;/p&gt;

&lt;p&gt;Just running the firewall is only part of it, you need to know how the
firewall is setup, and why. You should always have a document around
with a list of which ports are open and why. This will be very helpful
later on, when you get audited and they want to know what ports are
open, and the reasons for it.&lt;/p&gt;

&lt;p&gt;You should do a quarterly review of your firewalls to make sure they
match your documentation, and to see if any of the ports that were
previously open still need to be open. Systems change over time, and
sometimes you will remove a service that isn&amp;rsquo;t needed anymore, and when
that happens you should also block the port.&lt;/p&gt;

&lt;p&gt;You could also use a service like &lt;a href=&#34;http://cloudflare.com&#34;&gt;CloudFlare&lt;/a&gt;
that protect your website from a range of online threats from spammers
to SQL injection to DDOS. It is easy to setup, and your code changes
should be minimal at most.&lt;/p&gt;

&lt;h2 id=&#34;poorly-coded-websites:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Poorly coded websites&lt;/h2&gt;

&lt;p&gt;If the programmers who are writing your web application aren&amp;rsquo;t careful,
and don&amp;rsquo;t know what they are doing, they could write bad code which
could result in SQL injection and other vulnerabilities.&lt;/p&gt;

&lt;p&gt;Cross Site Scripting (XSS) is becoming a more and more common way of
attacking websites these days, so make sure you are careful of that as
well.&lt;/p&gt;

&lt;p&gt;Make sure you always conduct code reviews, and use application
penetration testing before you put your code into production.&lt;/p&gt;

&lt;h2 id=&#34;lack-of-monitoring-and-logging:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Lack of monitoring and logging&lt;/h2&gt;

&lt;p&gt;It is amazing how many companies have no system or application
monitoring, it is like they are running blind, they have no idea when
something is going wrong until their customers tell them. You should
have as much monitoring and logging as possible, so that you know what
is happening with your system at all times. If you don&amp;rsquo;t log when things
are going well, then when stuff starts going bad you will have no idea
what things are suppose to look like when things are good.&lt;/p&gt;

&lt;p&gt;Here is a list of tools that will help you with your logging and
monitoring.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pingdom.com&#34;&gt;Pingdom&lt;/a&gt; Is a website monitoring tool, they
will tell you when your site is down.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.nagios.org/&#34;&gt;Nagios&lt;/a&gt; offers complete monitoring and
alerting for servers, switches, applications, and services.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cacti.net/&#34;&gt;Cacti&lt;/a&gt; is a complete network graphing
solution designed to harness the power of RRDTool&amp;rsquo;s data storage and
graphing functionality.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dcramer/sentry&#34;&gt;Sentry&lt;/a&gt; Open Source realtime
event logging and aggregation platform&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://loggly.com/&#34;&gt;Loggly&lt;/a&gt; Log management cloud service for
centralized log search and analysis, time series data.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://graphite.wikidot.com/&#34;&gt;graphite&lt;/a&gt; Scalable Realtime Graphing
server&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://collectd.org/&#34;&gt;collectd&lt;/a&gt; is a daemon which collects system
performance statistics periodically and provides mechanisms to store
the values in a variety of ways, for example in RRD files.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mmonit.com/&#34;&gt;monit&lt;/a&gt; Easy, proactive monitoring of Linux/Unix
systems, network and cloud services.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://munin-monitoring.org/&#34;&gt;munin&lt;/a&gt; Munin is a networked resource
monitoring tool that can help analyze resource trends.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://NewRelic.com&#34;&gt;New Relic&lt;/a&gt; is the only tool you need to
pinpoint and solve performance issues in your Ruby, Java, .NET, PHP
and Python apps.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://PagerDuty.com&#34;&gt;Pager Duty&lt;/a&gt; Phone &amp;amp; SMS alerting and on-call
scheduling for Nagios, Zenoss, Munin, Monit, and most other IT
monitoring tools.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;missing-security-patches:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Missing security patches&lt;/h2&gt;

&lt;p&gt;It is important that you regularly schedule applying all security
patches on all of your systems. This is a no brainer but it is amazing
how much this doesn&amp;rsquo;t happen.&lt;/p&gt;

&lt;p&gt;You should also subscribe to all of the security alert email lists for
any of the products that you are using, as well as paying attention the
following list of websites below. The sooner you get notified of a
potential problem the sooner you can fix it before it effects you.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.us-cert.gov/cas/&#34;&gt;http://www.us-cert.gov/cas/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://seclists.org/&#34;&gt;http://seclists.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sans.org/newsletters/&#34;&gt;http://www.sans.org/newsletters/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;not-using-ssl-for-payment-page:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Not using SSL for payment page&lt;/h2&gt;

&lt;p&gt;Another no brainer, but sometimes it happens. You should add code to
your web applications that check to make sure that the payment pages are
served over SSL, if not, do a redirect to the SSL version of the page.&lt;/p&gt;

&lt;p&gt;An easy way to do this is to serve the whole site over SSL all of the
time, and then do a simple redirect with your web server from port 80
(http) over to port 443(https). This will guarantee that all traffic is
served over SSL all of the time.&lt;/p&gt;

&lt;h2 id=&#34;logging-payment-information:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Logging payment information&lt;/h2&gt;

&lt;p&gt;One of the most common mistakes that I see is when someone has their
logging setup to print out data from the payment form to the logs. This
is great for debugging purposes but bad for PCI. You should always strip
out the important information out of the request before logging it. You
can replace the credit card number with **last4 and get the same
result.&lt;/p&gt;

&lt;p&gt;Another common mistake that is similar is dumping all of the data when
there is an error and emailing it to the developers. If you do this as
well, make sure you strip out the credit card info first or else that
person&amp;rsquo;s credit card information is now emailed all over the place,
which isn&amp;rsquo;t good at all.&lt;/p&gt;

&lt;h1 id=&#34;credit-card-data-that-can-be-stored:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Credit card data that can be stored&lt;/h1&gt;

&lt;p&gt;It is important that you NEVER EVER store credit card information in the
database, even if it is encrypted. It isn&amp;rsquo;t worth the hassle, risk and
the cost of handling an external audit. But if you absolutely insist,
here is something you need to know.&lt;/p&gt;

&lt;p&gt;If for some reason you ignore my advice and decide to store credit card
data anyway, here is a little chart that will show you which data is
allowed to be stored, and If it needs to be encrypted or not.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;According to 3.3 Mask PAN when displayed (the first six and last
four digits are the maximum number of digits to be displayed). That
means, you need to do something like this *****1234 Visa instead
of the actual credit card number. This is pretty common these days.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;According to 3.4 : Render PAN unreadable anywhere it is stored
(including on portable digital media, backup media, and in logs) by
using any of the following approaches:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;One-way hashes based on strong cryptography (hash must be of
the entire PAN) [ One-way hash functions such as the Secure
Hash Algorithm (SHA) based on strong cryptography can be used
to render cardholder data unreadable. Hash functions are
appropriate when there is no need to retrieve the original
number (one-way hashes are irreversible) To complicate the
creation of rainbow tables it is recommended, but not a
requirement, that a salt value be input to the hash function
in addition to the PAN.]&lt;/li&gt;
&lt;li&gt;Truncation (hashing cannot be used to replace the truncated
segment of PAN)&lt;/li&gt;
&lt;li&gt;Index tokens and pads (pads must be securely stored)&lt;/li&gt;
&lt;li&gt;Strong cryptography with associated key-management processes
and procedures&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+
|                     | Storage Permitted    | Protection Required      |
+=====================+======================+==========================+
|                     | &lt;strong&gt;Cardholder Data&lt;/strong&gt;  |                          |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+
| Account Number      | &amp;gt; Y                  | &amp;gt; Y                      |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+
| Cardholder data     | &amp;gt; Y                  | &amp;gt; N                      |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+
| Expiration Date     | &amp;gt; Y                  | &amp;gt; N                      |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+
| Service Code        | &amp;gt; Y                  | &amp;gt; N                      |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+
|                     | **Authentication   | ta**                   |
|                     | Da                   |                          |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+
| Magnetic Strip      | &amp;gt; N                  | &amp;gt; n/a                    |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+
| CVV                 | &amp;gt; N                  | &amp;gt; n/a                    |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+
| Pin Data            | &amp;gt; N                  | &amp;gt; n/a                    |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&lt;/p&gt;

&lt;h1 id=&#34;tokenization:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Tokenization&lt;/h1&gt;

&lt;p&gt;If you need to store credit card information, it is best to use a
&lt;a href=&#34;http://en.wikipedia.org/wiki/Tokenization_(data_security&#34;&gt;tokenization&lt;/a&gt;)
service instead of storing it yourself. You store the credit card
information in their system. They give you a unique token that you use
for all future transactions against that credit card. These types of
service are pretty common these days, just ask your credit card
processor if they have such a service. Here are a couple of credit card
processors that provide this sort of service.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.authorize.net/solutions/merchantsolutions/merchantservices/cim/&#34;&gt;Authorize.net
CIM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.braintreepayments.com/services/payment-gateway&#34;&gt;BrainTree
Vault&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stripe.com/docs/stripe.js&#34;&gt;Stripe.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://recurly.com&#34;&gt;Recurly.com subscription based billing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;data-centers:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Data Centers&lt;/h1&gt;

&lt;p&gt;When you are dealing with PCI compliance you need to worry about the
full stack, not just your application, but also the server the
application lives on, the network your server is connected to, and the
data center your server lives in. The first thing you will want to do is
contact your your hosting provider to see if they are PCI compliant, and
if so, you might want to request a copy of their PCI documents for your
records (you might need them later). Usually hosting providers that are
PCI compliant brag about it on their web pages, so that is usually a
good place to start.&lt;/p&gt;

&lt;p&gt;The smaller the hosting company that you deal with the smaller the
chance you will be PCI compliant. If you are just using a shared hosting
plan, and paying \$20/month, most likely you are not compliant. You
might get lucky, but I doubt it. If you are using a PAAS or a cloud
provider, you will also most likely be out of luck.&lt;/p&gt;

&lt;h1 id=&#34;hosting-in-the-cloud:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Hosting in the Cloud&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com&#34;&gt;Amazon Web Services&lt;/a&gt; (AWS) has recently had
their data centers meet PCI compliance, but what is important to note is
that just because the data center in compliant, doesn&amp;rsquo;t mean that your
application is going to be. If you put your application on EC2, and you
accept credit card data that is getting processed on those EC2
instances, you will need to make sure that you also have an Intrusion
Detection System (IDS) amongst other things in place or else you aren&amp;rsquo;t
PCI compliant. All of the good IDS&amp;rsquo;s are hardware based, and have
someone monitoring the traffic at all times. You can&amp;rsquo;t install those
systems in AWS, so you will need to rely on a software based solution,
which isn&amp;rsquo;t as good, and adds another layer of complexity to your
network stack.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://Rackspace.com&#34;&gt;RackSpace&lt;/a&gt; offers a &lt;a href=&#34;http://www.rackspace.com/hosting_solutions/hybrid_hosting/&#34;&gt;hybrid cloud
hosting&lt;/a&gt;
setup, which allows you to have hardware firewall, IDS, Load balancers,
cloud web servers and hardware database servers. But even in this setup,
it isn&amp;rsquo;t PCI compliant, at least I haven&amp;rsquo;t been able to get RackSpace to
tell me it is yet.&lt;/p&gt;

&lt;p&gt;There are other cloud providers that might be able to offer you a
complete PCI compliant solution, but I&amp;rsquo;m guessing they are going to cost
more money. If you know of one, please let me know and I&amp;rsquo;ll update this.
&lt;a href=&#34;http://www.terremark.com/services/security-services/governance-risk-compliance-management/pci-compliance.aspx&#34;&gt;Terremark&lt;/a&gt;
might have something.&lt;/p&gt;

&lt;h1 id=&#34;security-scanners:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Security Scanners&lt;/h1&gt;

&lt;p&gt;A key part of the PCI certification is the 3rd party security scanning
requirement. Basically you have to pay one of the certified and approved
security scanning companies to scan you network, server, application
every so often, and if it finds any issues, you will need to fix those,
and scan again until you pass their tests. Once you pass the scans they
will give you a certificate that you can attach to the rest of your PCI
documentation.&lt;/p&gt;

&lt;p&gt;I have used a company called &lt;a href=&#34;http://www.controlscan.com&#34;&gt;ControlScan&lt;/a&gt;
in the past, and I have also used &lt;a href=&#34;http://www.qualys.com&#34;&gt;Qualys&lt;/a&gt;, but
I&amp;rsquo;m sure there are a ton of others out there. Pick the one that looks
the best for you. Here is a link to a list of &lt;a href=&#34;https://www.pcisecuritystandards.org/approved_companies_providers/approved_scanning_vendors.php&#34;&gt;PCI approved scanning
vendors&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;intrusion-detection-systems:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Intrusion Detection Systems&lt;/h1&gt;

&lt;p&gt;Intrusion Detection Systems (IDS) basically sit in front of your network
and watch all of the network traffic coming into your network. It looks
to see if it notices anything out of the ordinary, of if people are
trying to use known attacks, and if it finds something it will let you
know. They have hard ware and software based solutions. They range in
price from free to thousands of dollars a month. They all have different
features and abilities, it is best to pick one that has what you need,
that you are comfortable maintaining.&lt;/p&gt;

&lt;p&gt;I have used &lt;a href=&#34;http://www.alertlogic.com&#34;&gt;AlertLogic&amp;rsquo;s&lt;/a&gt; hardware based
IDS, and it works well. They have a pool of on call people who monitor
the devices and if something gets triggered they look it over, and act
accordingly.&lt;/p&gt;

&lt;h1 id=&#34;hashing-credit-card-numbers:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Hashing credit card numbers&lt;/h1&gt;

&lt;p&gt;Here is a great example on why hashing credit card numbers isn&amp;rsquo;t a good
idea. I&amp;rsquo;m borrowing some of this from these two links.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://en.oreilly.com/rails2011/public/schedule/detail/19466&#34;&gt;http://en.oreilly.com/rails2011/public/schedule/detail/19466&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.integrigy.com/security-resources/whitepapers/Integrigy_Hashing_Credit_Card_Numbers_Unsafe_Practices.pdf&#34;&gt;http://www.integrigy.com/security-resources/whitepapers/Integrigy_Hashing_Credit_Card_Numbers_Unsafe_Practices.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Just because you are following PCI rules doesnt mean you are
invincible, you still have to use your common sense.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;PCI DSS section 3.4
&lt;a href=&#34;http://www.pcisecuritystandards.org/pdfs/pci_audit_procedures_v1-1.pdf&#34;&gt;[pdf]&lt;/a&gt;:
Render PAN, at minimum, unreadable anywhere it is stored .. by using
any of the following approaches: Strong one-way hash functions (hashed
indexes)&lt;/p&gt;

&lt;p&gt;Verify that data is rendered unreadable using one of the following
methods: one-way hashes (hashed indexes) such as SHA-1&lt;/p&gt;

&lt;p&gt;Basically what this is saying is that you are allowed to store the
first 6 digits of a credit card (BIN) as well as the last 4 digits of
the credit card. Credit cards are between 13-16 digits in length and
the last digit is the check digit (&lt;a href=&#34;http://en.wikipedia.org/wiki/Luhn_algorithm&#34;&gt;Luhn
algorithm&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s see how hard it would be to figure out this credit card number.
4012888888881881&lt;/p&gt;

&lt;p&gt;If we start with a full 16 digits that means that we have 10\^16 or
10,000,000,000,000,000 (10 Quadrillion) Possible Card Numbers, if we
didn&amp;rsquo;t know anything about the card.&lt;/p&gt;

&lt;p&gt;Since we are storing the credit card type, we know this is a visa, visa
credit cards all start with a 4 so that means that is could be
4XXXXXXXXXXXXXXX or 4,000,000,000,000,000 (4 Quadrillion) Possible Card
Numbers, we just cut the number of possible cards in more then half.&lt;/p&gt;

&lt;p&gt;If we also store the bin (first 6 digits) and the last 4 digits, then it
would look like this. 401288*&lt;em&gt;*&lt;/em&gt;**1881 or 1,000,000 (1 million)
possible card numbers.&lt;/p&gt;

&lt;p&gt;Starting with that lets try to write a simple cracker (Ruby)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode ruby&#34;&gt;hashed_card_number = &#39;62163a017b168ad4a229c64ae1bed6ffd5e8fb2d&#39;
masked_card_number = &#39;401288******1881&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Code&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode ruby&#34;&gt;require &#39;digest/sha1&#39;

def reverse_hashed_card_number( hashed_card_number, first_six, last_four)
    0.upto(999_999) do |i|
        card_number_to_test = &amp;quot;#{first_six}%06d#{last_four}&amp;quot; % i
        hashed_to_test = Digest::SHA1.hexdigest(card_number_to_test)
        if hashed_card_number == hashed_card_number_to_test
          return card_number_to_test
        end
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s run it&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode ruby&#34;&gt;Benchmark.measure do
  puts reverse_hashed_card_number(
    &#39;62163a017b168ad4a229c64ae1bed6ffd5e8fb2d&#39;,
    &#39;401288&#39;,
    &#39;1881&#39;
) end.real
4012888888881881
=&amp;gt; 5.33522081375122
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In 5.3 seconds it was able to crack the hash, if you use only a SHA-1
hash. We could possibly make it even faster if we did a luhn check on
the number before we ran the hash, and if the luhn check fails then we
know the number isn&amp;rsquo;t valid and there is no need to run the hash. Since
the hash function is going to be slower then the luhn check it should
speed things up.&lt;/p&gt;

&lt;h1 id=&#34;rainbow-tables-salts:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Rainbow Tables + Salts&lt;/h1&gt;

&lt;p&gt;Since we know that there is a finite number of credit cards, we could
pre-calculate the hash code for every single one of the 10 Quadrillion
possible card values, and store those in a lookup table. Then when ever
I wanted to crack a credit card hash, all i would need is the credit
card hash, and I would be able to figure out the value of that card,
very quickly. Storing all of the known values in a table like this is
called a &lt;a href=&#34;http://en.wikipedia.org/wiki/Rainbow_tables&#34;&gt;Rainbow table&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ideally if you are going to hash a credit card, don&amp;rsquo;t use SHA-1, or MD5,
use one of the newer SHA versions, SHA-256 or above, and also use a
&lt;a href=&#34;http://en.wikipedia.org/wiki/Salt_(cryptography&#34;&gt;salt&lt;/a&gt;). A salt is
basically a second unique value that you always use when hashing, to
generate a different salt then you would normally get with just the
credit card number.&lt;/p&gt;

&lt;p&gt;Since I won&amp;rsquo;t have your salt when I generate my rainbow table, my
rainbow table will be no good. It adds yet another layer of security.
Make sure you don&amp;rsquo;t lose your SALT or else you will have to start over
from scratch. Treat your salt like a password, and keep it safe.&lt;/p&gt;

&lt;h1 id=&#34;do-i-really-have-to-worry-about-being-hacked:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Do I really have to worry about being hacked?&lt;/h1&gt;

&lt;p&gt;Here is a short list of companies that have been hacked recently. If
they can get hacked, so could you.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/T.K._Maxx#2007_credit_card_fraud&#34;&gt;TJ
Maxx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bank of America&lt;/li&gt;
&lt;li&gt;Citigroup&lt;/li&gt;
&lt;li&gt;BJ&amp;rsquo;s wholesale club&lt;/li&gt;
&lt;li&gt;Hotels.com&lt;/li&gt;
&lt;li&gt;LexisNexis&lt;/li&gt;
&lt;li&gt;Polo Ralph Lauren&lt;/li&gt;
&lt;li&gt;Wachovoa&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Heartland_Payment_Systems#Security_breach&#34;&gt;Heartland Payment
Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hannaford&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;what-could-happen-if-you-were-hacked:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;What could happen if you were Hacked?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Banned from accepting credit cards&lt;/li&gt;
&lt;li&gt;Loss of reputation and customers&lt;/li&gt;
&lt;li&gt;Fines up to \$500,000 per incident&lt;/li&gt;
&lt;li&gt;Litigation (you could be sued)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;what-if-i-was-breached:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;What if I was breached?&lt;/h1&gt;

&lt;p&gt;In the event of a security incident, merchants must take immediate
action to:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Contain and limit the exposure. Conduct a thorough investigation of
the suspected or confirmed loss or theft of account information
within 24 hours of the compromise&lt;/li&gt;
&lt;li&gt;Alert all necessary parties. Be sure to notify: * Merchant Account
Provider * Visa Fraud Control Group at (650) 432-2978 * Local FBI
Office * U.S. Secret Service (if Visa payment data is compromised)&lt;/li&gt;
&lt;li&gt;Provide the compromised Visa accounts to Visa Fraud Control Group
within 24 hours.&lt;/li&gt;
&lt;li&gt;Within four business days of the reported compromise, provide Visa
with an incident report.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;build-pci-complaint-django-applications:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Build PCI Complaint Django Applications&lt;/h1&gt;

&lt;p&gt;I recently gave a talk on Build PCI Complaint Django Applications, at
DjangoCon US 2012 in Washington D.C. Here are my slides and the video of
my talk.&lt;/p&gt;

&lt;h2 id=&#34;slides:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Slides&lt;/h2&gt;

&lt;h2 id=&#34;video:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Video&lt;/h2&gt;

&lt;h1 id=&#34;links:4cd0f426c80b0e9aa5a827b6b948214b&#34;&gt;Links:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.akamai.com/html/solutions/security/edge_tokenization.html&#34;&gt;Akamai edge
tokenization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pcisecuritystandards.org&#34;&gt;PCI Security Standards&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.americanexpress.com/datasecurity&#34;&gt;American Express PCI
pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.discovernetwork.com/fraudsecurity/disc.html&#34;&gt;Discover Financial Services PCI
pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.jcb-global.com/english/pci/index.html&#34;&gt;JCB International PCI
pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.mastercard.com/sdp&#34;&gt;MasterCard Worldwide PCI pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.visa.com/cisp&#34;&gt;Visa Inc PCI pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.visaeurope.com/ais&#34;&gt;Visa Europe PCI pages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Getting DjangoCMS up and running on ActiveState&#39;s Stackato</title>
      <link>http://www.kencochrane.net/blog/2012/01/getting-djangocms-up-and-running-on-stackato/</link>
      <pubDate>Sun, 15 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2012/01/getting-djangocms-up-and-running-on-stackato/</guid>
      <description>

&lt;p&gt;ActiveState has recently started their own PAAS based on
&lt;a href=&#34;http://cloudfoundry.org/&#34;&gt;CloudFoundry&lt;/a&gt; this blog post is to help you
get up and running quickly with a Django CMS installation, and hopefully
give you enough information to get your own applications on there as
well.&lt;/p&gt;

&lt;p&gt;To keep things simple, I&amp;rsquo;ll just go through the steps that are required
in order to get this up and running and add some comments along the way.
If I missed anything or if you have any questions, please ask in the
comments.&lt;/p&gt;

&lt;h1 id=&#34;running-on-stackato:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Running on Stackato&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Register for an account
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Go to &lt;a href=&#34;http://community.activestate.com/stackato&#34;&gt;http://community.activestate.com/stackato&lt;/a&gt; and register for your
account. They are currently in beta, and you need to be approved before
they will give you access.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Install the client
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are a few different options, follow the steps outlined here.
&lt;a href=&#34;http://docs.stackato.com/quick-start.html#stackato-client-setup&#34;&gt;http://docs.stackato.com/quick-start.html#stackato-client-setup&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I tried the option where you download the file, and rename it and put it
in your path. It wasn&amp;rsquo;t complicated, but it wasn&amp;rsquo;t clean either. I chose
this option because I didn&amp;rsquo;t want to install
&lt;a href=&#34;http://code.activestate.com/pypm/&#34;&gt;pypm&lt;/a&gt;, so I&amp;rsquo;m not sure if that way
is easier or not.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Register your client to the cloud
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now that you have the client installed you need to tell it which cloud
to deploy too. With Stackato, you can run your own local cloud as well
as using the sandbox that ActiveState provided. To make things simple,
I&amp;rsquo;m going to use the sandbox. If you want to use the local cloud you
will need to &lt;a href=&#34;http://docs.stackato.com/quick-start.html#accesssing-the-micro-cloud&#34;&gt;read the
directions&lt;/a&gt;
on how to use the local cloud option.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato target api.sandbox.activestate.com
&amp;gt; Successfully targeted to [https://api.sandbox.activestate.com]
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Login to stackato
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once you point your client in the correct location, you will need to
login to the cloud. You can find your login information on your
&lt;a href=&#34;https://account.activestate.com/&#34;&gt;activestate account page&lt;/a&gt;. Type the
following and answer the questions when prompted.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato login
&amp;gt; Successfully logged into [https://api.sandbox.activestate.com]
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Download this github repo
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To make things easier, I have made a simple django project that has all
of the configuration information setup so that you don&amp;rsquo;t need to do
anything if you want to use djangoCMS. Look at my &lt;a href=&#34;https://github.com/kencochrane/django-cms-stackato&#34;&gt;github
repo&lt;/a&gt;, and see how I
did things if you want to get your own application up and running. If
you want to use djangoCMS, then all you have to do is follow these
steps.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ cd ~/projects
$ git clone git://github.com/kencochrane/django-cms-stackato.git
$ cd django-cms-stackato
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Deploy the project to stackato
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once you have your application ready, you can push the application to
the cloud. When you do this it will prompt you for a bunch of questions,
answer them and keep track of what you picked for a website url, because
you will need that later. My application is called myblog, but you can
put whatever you want, just change myblog with your name.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato push myblog
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Initialize the database (optional)
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I have set this up so that it should happen automatically at deployment
see the stackato.yml file for more details. If you want to run the
commands outside of deployments this is what you can do.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato run myblog python mycms/manage.py syncdb --noinput
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Run south migrations (optional)
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I have set this up so that it should happen automatically at deployment
see the stackato.yml file for more details. If you want to run the
commands outside of deployments this is what you can do. It is important
to note &lt;em&gt;I had to run more then once since it was killed the first time.
Maybe it took too long?&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato run myblog python mycms/manage.py migrate --noinput
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Collect the static files (optional)
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I have set this up so that it should happen automatically at deployment
see the stackato.yml file for more details. If you want to run the
commands outside of deployments this is what you can do.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato run myblog python mycms/manage.py collectstatic --noinput
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Create the django admin account
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now that you have your application installed and you have your database
setup, you need to create the django admin, you can do that with ths
django management command. Make sure you replace the variables with your
values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato run myblog python mycms/manage.py createsuperuser --username=admin --email=admin@example.com --noinput
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Change the password for the admin user
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;You need to set a password for the admin account so that you can login.
Pick a more secure password then the example I have here. &lt;em&gt;(notice it is
changepassword2 not changepassword)&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato run myblog python mycms/manage.py changepassword2 admin secret123P@ssw0rd!
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Open up the url in your browser
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;When you open up the URL that you picked when you deployed in your
browser you should find the DjangoCMS pony welcome page. If not, try
debugging using some of the tips below.&lt;/p&gt;

&lt;h1 id=&#34;conclusion:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;That is it, I did all the hard work, so you should be able to follow
those simple steps and get djangoCMS up and running in no time. Once you
get that working, play around with it, and let me know what you think.
Have you tried the other PAAS options yet, if not check those out as
well, and then let me know which ones you like better and why. I have
written blog posts about most of them at this point, so feel free to
check those out (links below), and have fun playing around.&lt;/p&gt;

&lt;h2 id=&#34;other-useful-information:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Other Useful Information&lt;/h2&gt;

&lt;h3 id=&#34;starting-an-application-if-it-isn-t-running:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Starting an application if it isn&amp;rsquo;t running&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato start myblog
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;restarting-an-application:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Restarting an application&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato restart myblog
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;stopping-an-application:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Stopping an application&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato stop myblog
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;updating-application-after-it-is-already-deployed:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Updating application after it is already deployed&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato update myblog
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;find-out-how-many-instances-you-have-running:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Find out how many instances you have running&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$  stackato stats myblog
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;find-out-which-apps-you-have-installed-and-their-status:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Find out which apps you have installed, and their status&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato apps
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;find-out-what-logs-you-have-for-your-applications:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Find out what logs you have for your applications&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato files myblog logs
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;viewing-logs-for-your-app:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Viewing logs for your app&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato logs myblog --all
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;running-cat-on-a-particular-log-file:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Running cat on a particular log file&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ stackato run myblog cat ../logs/myapp-err.log
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;links:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;My github repo for this blog post:
&lt;a href=&#34;https://github.com/kencochrane/django-cms-stackato&#34;&gt;https://github.com/kencochrane/django-cms-stackato&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stackato Client command reference:
&lt;a href=&#34;http://docs.stackato.com/commands.html#command-ref-client&#34;&gt;http://docs.stackato.com/commands.html#command-ref-client&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;stackato.yml reference:
&lt;a href=&#34;http://docs.stackato.com/client.html#configure-stackato-yml&#34;&gt;http://docs.stackato.com/client.html#configure-stackato-yml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stackato quick start guide:
&lt;a href=&#34;http://docs.stackato.com/quick-start.html&#34;&gt;http://docs.stackato.com/quick-start.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stackato Sandbox Ground Rules, Content Policy and Quotas:
&lt;a href=&#34;http://docs.stackato.com/sandbox.html&#34;&gt;http://docs.stackato.com/sandbox.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ActiveState Account page: &lt;a href=&#34;https://account.activestate.com/&#34;&gt;https://account.activestate.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;pip : &lt;a href=&#34;http://www.pip-installer.org/&#34;&gt;http://www.pip-installer.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;git : &lt;a href=&#34;http://git-scm.com/&#34;&gt;http://git-scm.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;my-other-articles-related-to-paas:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;My other articles related to PAAS:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/04/my-experiences-with-epio/&#34;&gt;My Experiences with
ep.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/05/apphosted-com-django-hosting-review/&#34;&gt;AppHosted.com Django Hosting Service
Review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/04/my-day-gondorio/&#34;&gt;My Day in
Gondor.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/04/deploying-my-django-application-to-dotcloud/&#34;&gt;Deploying my Django application to
DotCloud.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://DjangoZoom.com&#34;&gt;DjangoZoom.com Review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/06/django-hosting-roundup-who-wins/&#34;&gt;Django hosting
roundup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/12/installing-djangocms-on-heroku-in-13-easy-steps/&#34;&gt;Installing DjangoCMS on Heroku in 13 easy
steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/12/installing-djangocms-dotcloud-12-easy-steps/&#34;&gt;Installing DjangoCMS on dotCloud in 12 easy
steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/11/developers-guide-for-running-django-apps-on-heroku/&#34;&gt;Developers guide to Running Django Applications on
Heroku&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2012/01/installing-django-application-on-openshift/&#34;&gt;Installing a Django application on Red Hat&amp;rsquo;s OpenShift
PAAS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;update:55e1c02ded8c9fbb4411836cd601d2c4&#34;&gt;Update&lt;/h2&gt;

&lt;p&gt;2/16/2012: Full disclosure. On Feb 16th 2012, I accepted a job with
dotCloud a competitor to Stackato. I plan on keeping this blog post up
to date and impartial. If you think there are any errors, please let me
know in the comments.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Installing a Django application on Red Hat&#39;s OpenShift PAAS</title>
      <link>http://www.kencochrane.net/blog/2012/01/installing-django-application-on-openshift/</link>
      <pubDate>Sat, 14 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>http://www.kencochrane.net/blog/2012/01/installing-django-application-on-openshift/</guid>
      <description>

&lt;p&gt;It seems like everyone has their own
&lt;a href=&#34;http://en.wikipedia.org/wiki/Platform_as_a_service&#34;&gt;PAAS&lt;/a&gt; solution
these days, and if they don&amp;rsquo;t have one yet, it is just a matter of time
before they will. Red Hat has recently joined in on the fun with their
&lt;a href=&#34;https://openshift.redhat.com&#34;&gt;OpenShift&lt;/a&gt; platform.&lt;/p&gt;

&lt;p&gt;I decided to take it for a test drive, and share my results with you.
This service is still in beta and things are changing all of the time,
so these notes might not work in the future, take that into
consideration when using it as a guide.&lt;/p&gt;

&lt;p&gt;There really isn&amp;rsquo;t much python documentation for this platform, and what
documentation there is, is either a little out of date, or missing some
important steps. Hopefully this guide will help you get your application
up and running.&lt;/p&gt;

&lt;p&gt;OpenShift is divided into two parts, Flex and Express.&lt;/p&gt;

&lt;h1 id=&#34;flex-https-openshift-redhat-com-app-flex:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;&lt;a href=&#34;https://openshift.redhat.com/app/flex&#34;&gt;Flex&lt;/a&gt;:&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Dedicated cloud solution. Get more control over your apps, or move
your existing applications to the cloud with ease! Flex is a dedicated
cloud solution that provides everything you need to easily scale,
provision, deploy, and monitor your applications.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Flex runs on top of your amazon EC2 account, and currently only supports
Java and PHP. It is targeting the enterprise crowd and has more features
compared to Express.&lt;/p&gt;

&lt;h1 id=&#34;express-https-openshift-redhat-com-app-express:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;&lt;a href=&#34;https://openshift.redhat.com/app/express&#34;&gt;Express&lt;/a&gt;:&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Shared cloud solution. Express is a free, cloud-based application
platform for Java, Perl, PHP, Python, and Ruby applications. It&amp;rsquo;s
super-simpleyour development environment is also your deployment
environment: git push, and you&amp;rsquo;re in the cloud!&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Express runs on Red Hat&amp;rsquo;s servers, and currently supports Java, Ruby,
PHP, Perl and Python apps. It doesn&amp;rsquo;t have the same features of Flex,
but if you don&amp;rsquo;t need those advanced features, then express might be
fine for you. Since I&amp;rsquo;m interested in deploying python apps, and Express
is the only one that supports python apps, that is the one I&amp;rsquo;ll show you
today.&lt;/p&gt;

&lt;p&gt;To make things easier to show you how things work, I&amp;rsquo;ll create a simple
django application and walk you through the steps to deploying it. I&amp;rsquo;m
going to deploy a djangoCMS to express that will connect to a mysql
database.&lt;/p&gt;

&lt;h2 id=&#34;steps:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;Steps:&lt;/h2&gt;

&lt;h3 id=&#34;1-create-an-account:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;1. Create an account&lt;/h3&gt;

&lt;p&gt;Create an account by filling out the form at
&lt;a href=&#34;http://openshift.redhat.com/&#34;&gt;http://openshift.redhat.com/&lt;/a&gt; and don&amp;rsquo;t forget your username and
password, you will need that later.&lt;/p&gt;

&lt;h3 id=&#34;2-install-perquisites:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;2. Install Perquisites:&lt;/h3&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://git-scm.com/&#34;&gt;git&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://python.org&#34;&gt;python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;openshift client&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;**&lt;a href=&#34;Git:**&#34;&gt;Git:**&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m not going to go over the steps to install git, for more info, you
can get it from the git website. &lt;a href=&#34;http://git-scm.com/download&#34;&gt;http://git-scm.com/download&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Python:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If you are using a Mac or linux, it most likely already has python
installed, if you are using windows, you you don&amp;rsquo;t have python
installed. Goto the python website and you will find instructions on
how to install python on your system. &lt;a href=&#34;http://python.org/download/&#34;&gt;http://python.org/download/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;OpenShift client:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For instructions on how to Install the client go to this page.
&lt;a href=&#34;https://openshift.redhat.com/app/express#mac&#34;&gt;https://openshift.redhat.com/app/express#mac&lt;/a&gt; Here are my steps for
Mac OSX&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ sudo gem install json_pure
$ sudo gem install rhc
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-create-a-domain:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;3. Create a domain.&lt;/h3&gt;

&lt;p&gt;Now that you have everything installed, your first step is to create a
domain. Run the following command and replace \$mydoman and \$loginemail
with your own domain and the login email you used when creating an
account.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ rhc-create-domain -n $mydomain -l $loginemail
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-create-an-application:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;4. Create an application&lt;/h3&gt;

&lt;p&gt;Now that you have a domain, you need to create an application that you
can deploy to that domain. Running the following command will create a
new wsgi application called &amp;lsquo;blog&amp;rsquo;. You can name your application
anything you want, within reason. We pick wsgi, because our python
application will be wsgi compatible.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ rhc-create-app -a blog -t wsgi-3.2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-add-mysql-to-your-app:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;5. Add mysql to your app&lt;/h3&gt;

&lt;p&gt;We want to use mysql as our database backend for this blog, so we need
to add mysql to our application using the command below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ rhc-ctl-app -a blog -e add-mysql-5.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;6-add-phpmyadmin-to-help-you-manage-your-database:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;6. Add phpmyadmin to help you manage your database&lt;/h3&gt;

&lt;p&gt;OpenShift doesn&amp;rsquo;t give you direct access to your database, so you will
need a way to manage your database a different way. They provide the
ability to add PHPMyAdmin to your app so that you can get to your data.
This step is optional, but recommended.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ rhc-ctl-app -a blog -e add-phpmyadmin-3.4
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;7-add-this-upstream-repo-from-github:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;7. Add this upstream repo from github&lt;/h3&gt;

&lt;p&gt;When you create your application, it will create a directory with a
bunch of other files and directories in it. If you were starting from
scratch and building up your application you would start from here. To
make things easier I created a project on github that will allow you to
get up and running with DjangoCMS much faster. In order to use my
project you will need to run the following commands so that it will pull
down the code into your project.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ cd blog
$ git remote add upstream -m master git://github.com/kencochrane/django-cms-openshift.git
$ git pull -s recursive -X theirs upstream master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the code is downloaded, you can take a look at the code, change
anything you want and when you are ready you can deploy the app.&lt;/p&gt;

&lt;h3 id=&#34;8-deploying-the-app:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;8. Deploying the app&lt;/h3&gt;

&lt;p&gt;To deploy all you need to do is push the repo upstream into open shift.
To this, you just need to run the following command.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ git push
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When it pushes you application into open shift it will do the following.
(without jenkins add-on installed)&lt;/p&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;stop app&lt;/li&gt;
&lt;li&gt;*pre_build&lt;/li&gt;
&lt;li&gt;*build&lt;/li&gt;
&lt;li&gt;start_dbs&lt;/li&gt;
&lt;li&gt;*deploy&lt;/li&gt;
&lt;li&gt;start_app&lt;/li&gt;
&lt;li&gt;*post_deploy&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;The steps marked with a * are scripts that are located in
&lt;em&gt;.openshift/action_hooks/&amp;lt;script_name&amp;gt;&lt;/em&gt; if you have something in
those files it will run them, and if not, it will pass right by. These
are very helpful if you want something to happen at points of the
deployment process. For example, in the deploy script you will notice
that I have some code to kick off the django syncdb, migrate, and
collect static commands. These will run every time I deploy the app.&lt;/p&gt;

&lt;p&gt;I have also created a django management command that will check to see
if there is a django admin account created and if not, it will create
one and set the default password. I had to do this because there is
currently no way that I know of where you can kick off django management
commands after the deployment is finished. It will only create the admin
account once, and every other time it will just get ignored.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IMPORTANT:&lt;/strong&gt; It is important to note that if you want to do anything
related to the database, you can&amp;rsquo;t do it in the &lt;em&gt;pre_build&lt;/em&gt; or &lt;em&gt;build&lt;/em&gt;
scripts, because the database isn&amp;rsquo;t available yet. This one thing caused
me lots of pain, because I couldn&amp;rsquo;t figure out by my migrations were not
working. If you do make the mistake of trying to do something database
related in the &lt;em&gt;build&lt;/em&gt; script you will see an error like this.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;remote: ERROR 2003 (HY000): Can&amp;rsquo;t connect to MySQL server on
&amp;lsquo;xxx.x.xx.x&amp;rsquo; (111)&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That&amp;rsquo;s it, you can now checkout your application at (default admin
account is admin/&amp;lt;password given at deploy time&amp;gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://blog-$yourdomain.rhcloud.com&#34;&gt;http://blog-$yourdomain.rhcloud.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Once you visit the page you should see the djangoCMS default page. First
things first, login to the django admin, and change the password from
the default password to something secure. Then get started building your
own app.&lt;/p&gt;

&lt;h2 id=&#34;helpful-tips:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;Helpful tips:&lt;/h2&gt;

&lt;h3 id=&#34;viewing-logs:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;Viewing logs:&lt;/h3&gt;

&lt;p&gt;If you would like to view your logs to see what is going on with your
application you just need to run this command.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ rhc-tail-files -a blog
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;application-information:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;Application information:&lt;/h3&gt;

&lt;p&gt;If you would like more information about your application you can run
this command.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ rhc-user-info
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also checkout the README file they add when you create an application,
it is pretty helpful, and might answer some common questions.&lt;/p&gt;

&lt;h3 id=&#34;application-dependencies:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;Application dependencies:&lt;/h3&gt;

&lt;p&gt;OpenShift uses virtualenv but it doesn&amp;rsquo;t use pip, it depends on the
dependencies be listed in the setup.py file. During the deploy process I
did notice that it installed pip, so it might be possible to add a
requirements.txt file, and then in your build action_hook script call
pip install -r &amp;lt;path&amp;gt;/requirements.txt but I&amp;rsquo;m not sure if this is
supported, or if it will cause problems, so it might be best to stick
with what they have for now.&lt;/p&gt;

&lt;h3 id=&#34;static-media:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;Static media:&lt;/h3&gt;

&lt;p&gt;If you look in wsgi/static/.htaccess there a rewrite rule to get the
media to work correctly, you can use this trick for other apache tricks
if you want. For more information on this checkout the README file.&lt;/p&gt;

&lt;h3 id=&#34;what-is-it-open-shift-running:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;What is it open shift running:&lt;/h3&gt;

&lt;p&gt;Red Hat linux with Apache / mod_wsgi, and mysql 5.1&lt;/p&gt;

&lt;h3 id=&#34;what-type-of-apps-do-they-support:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;What type of apps do they support?&lt;/h3&gt;

&lt;p&gt;Here is the current link which can be found if you run this commands and
look at the types.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ rhc-create-app -h

raw-0.1, php-5.3, jbossas-7.0, rack-1.1, jenkins-1.4, perl-5.10, wsgi-3.2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;what-else-does-it-support:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;What else does it support?&lt;/h3&gt;

&lt;p&gt;Things are changing all of the time, but if you run this command you
will get a list of the current supported addons.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode bash&#34;&gt;$ rhc-ctl-app -L

List of supported embedded cartridges:

Obtaining list of cartridges (please excuse the delay)...

    - metrics-0.1
    - mysql-5.1
    - jenkins-client-1.4
    - 10gen-mms-agent-0.1
    - phpmyadmin-3.4
    - rockmongo-1.1
    - mongodb-2.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;web-based-control-panel:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;Web based control panel:&lt;/h3&gt;

&lt;p&gt;They offer a web based control panel to do some of the things you can do
with the command line, which will be nice, but it doesn&amp;rsquo;t work right
now. It doesn&amp;rsquo;t display the correct information, and it doesn&amp;rsquo;t even
show the applications I have created, so I don&amp;rsquo;t trust it. Hopefully
these issues will get fixed in the future, and this tool will make it
easier for less technical people to get started.&lt;/p&gt;

&lt;h3 id=&#34;conclusion:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;Conclusion:&lt;/h3&gt;

&lt;p&gt;It is nice to see another platform on the market, it is still pretty
rough, and there isn&amp;rsquo;t much documentation, but I found it usable. I&amp;rsquo;m
sure once they stabilize things, they will spend more time on the
documentation side of things.&lt;/p&gt;

&lt;h3 id=&#34;other-helpful-openshift-links:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;Other Helpful OpenShift links:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kencochrane/django-cms-openshift&#34;&gt;My GitHub repo for this
article&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openshift/django-example&#34;&gt;https://github.com/openshift/django-example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.ianweller.org/2011/05/12/openshift-express-first-thoughts/&#34;&gt;http://blog.ianweller.org/2011/05/12/openshift-express-first-thoughts/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;my-other-articles-related-to-paas:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;My other articles related to PAAS:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/04/my-experiences-with-epio/&#34;&gt;My Experiences with
ep.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/05/apphosted-com-django-hosting-review/&#34;&gt;AppHosted.com Django Hosting Service
Review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/04/my-day-gondorio/&#34;&gt;My Day in
Gondor.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/04/deploying-my-django-application-to-dotcloud/&#34;&gt;Deploying my Django application to
DotCloud.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://DjangoZoom.com&#34;&gt;DjangoZoom.com Review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/06/django-hosting-roundup-who-wins/&#34;&gt;Django hosting
roundup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/12/installing-djangocms-on-heroku-in-13-easy-steps/&#34;&gt;Installing DjangoCMS on Heroku in 13 easy
steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/12/installing-djangocms-dotcloud-12-easy-steps/&#34;&gt;Installing DjangoCMS on dotCloud in 12 easy
steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kencochrane.net/blog/2011/11/developers-guide-for-running-django-apps-on-heroku/&#34;&gt;Developers guide to Running Django Applications on
Heroku&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;update:7691e8103b37fb8a7e415dbcd78d4931&#34;&gt;Update&lt;/h3&gt;

&lt;p&gt;2/16/2012: Full disclosure. On Feb 16th 2012, I accepted a job with
dotCloud a competitor to openShift. I plan on keeping this blog post up
to date and impartial. If you think there are any errors, please let me
know in the comments.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>